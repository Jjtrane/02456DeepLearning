{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAva8TnYFtFu"
   },
   "source": [
    "# Contents and why we need this lab\n",
    "\n",
    "This lab is about implementing neural networks yourself before we start using other frameworks that hide some of the computation from you. It builds on the first lab, where you derived the equations for neural network forward and backward propagation and gradient descent parameter updates. \n",
    "\n",
    "All the frameworks for deep learning you will meet from now on use automatic differentiation (autodiff), so you do not have to code the backward step yourself. In this version of this lab, you will develop your own autodif implementation. We also have an optional [version](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/2_Feedforward_Python/2.2-FNN-NumPy.ipynb) of this lab where you have to code the backward pass explicitly in Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCa7HzwpFtFy"
   },
   "source": [
    "# External sources of information\n",
    "\n",
    "1. Jupyter notebook. You can find more information about Jupyter notebooks [here](https://jupyter.org/). It will come as part of the [Anaconda](https://www.anaconda.com/) Python installation. \n",
    "2. [NumPy](https://numpy.org/). Part of Anaconda distribution.  If you already know how to program, most things about Python and NumPy can be found with Google searches.\n",
    "3. [Nanograd](https://github.com/rasmusbergpalm/nanograd) is a minimalistic version of autodiff developed by Rasmus Berg Palm that we use for our framework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SjiIp-TFtF0"
   },
   "source": [
    "# This notebook will follow the next steps:\n",
    "\n",
    "1. Nanograd automatic differentiation framework\n",
    "2. Finite difference method\n",
    "3. Data generation\n",
    "4. Defining and initializing the network\n",
    "5. Forward pass\n",
    "6. Training loop \n",
    "7. Testing your model\n",
    "8. Further extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyXeAA-HuT7s"
   },
   "source": [
    "# Nanograd automatic differention framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6UWKCLKubgA"
   },
   "source": [
    "The [Nanograd](https://github.com/rasmusbergpalm/nanograd) framework defines a class Var which both holds a value and gradient value that we can use to store the intermediate values when we apply the chain rule of differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Jd4CoEBNzNWS"
   },
   "outputs": [],
   "source": [
    "# Copy and pasted from https://github.com/rasmusbergpalm/nanograd/blob/3a1bf9e9e724da813bfccf91a6f309abdade9f39/nanograd.py\n",
    "\n",
    "from math import exp, log\n",
    "\n",
    "class Var:\n",
    "    \"\"\"\n",
    "    A variable which holds a float and enables gradient computations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, val: float, grad_fn=lambda: []):\n",
    "        assert type(val) == float\n",
    "        self.v = val\n",
    "        self.grad_fn = grad_fn\n",
    "        self.grad = 0.0\n",
    "\n",
    "    def backprop(self, bp):\n",
    "        self.grad += bp\n",
    "        for input, grad in self.grad_fn():\n",
    "            input.backprop(grad * bp)\n",
    "\n",
    "    def backward(self):\n",
    "        self.backprop(1.0)\n",
    "\n",
    "    def __add__(self: 'Var', other: 'Var') -> 'Var':\n",
    "        return Var(self.v + other.v, lambda: [(self, 1.0), (other, 1.0)])\n",
    "\n",
    "    def __mul__(self: 'Var', other: 'Var') -> 'Var':\n",
    "        return Var(self.v * other.v, lambda: [(self, other.v), (other, self.v)])\n",
    "\n",
    "    def __pow__(self, power):\n",
    "        assert type(power) in {float, int}, \"power must be float or int\"\n",
    "        return Var(self.v ** power, lambda: [(self, power * self.v ** (power - 1))])\n",
    "\n",
    "    def __neg__(self: 'Var') -> 'Var':\n",
    "        return Var(-1.0) * self\n",
    "\n",
    "    def __sub__(self: 'Var', other: 'Var') -> 'Var':\n",
    "        return self + (-other)\n",
    "\n",
    "    def __truediv__(self: 'Var', other: 'Var') -> 'Var':\n",
    "        return self * other ** -1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Var(v=%.4f, grad=%.4f)\" % (self.v, self.grad)\n",
    "\n",
    "    def relu(self):\n",
    "        return Var(self.v if self.v > 0.0 else 0.0, lambda: [(self, 1.0 if self.v > 0.0 else 0.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDX67D6jzcte"
   },
   "source": [
    "A few examples illustrate how we can use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xk6PeLc3zwPT",
    "outputId": "47e431b2-07ba-4cb1-ea21-997769641c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var(v=3.0000, grad=5.0000)\n",
      "Var(v=5.0000, grad=3.0000)\n",
      "Var(v=15.0000, grad=1.0000)\n"
     ]
    }
   ],
   "source": [
    "a = Var(3.0)\n",
    "b = Var(5.0)\n",
    "f = a * b\n",
    "\n",
    "f.backward()\n",
    "\n",
    "for v in [a, b, f]:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmKhYgsY0g_o",
    "outputId": "06c1b1df-c33c-40d3-922a-624612a591c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var(v=3.0000, grad=14.0000)\n",
      "Var(v=5.0000, grad=3.0000)\n",
      "Var(v=15.0000, grad=1.0000)\n",
      "Var(v=9.0000, grad=3.0000)\n",
      "Var(v=27.0000, grad=1.0000)\n",
      "Var(v=42.0000, grad=1.0000)\n"
     ]
    }
   ],
   "source": [
    "a = Var(3.0)\n",
    "b = Var(5.0)\n",
    "c = a * b\n",
    "d = Var(9.0)\n",
    "e = a * d\n",
    "f = c + e\n",
    "\n",
    "f.backward()\n",
    "for v in [a, b, c, d, e, f]:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fe3B6uEH140p"
   },
   "source": [
    "## Exercise a) What is being calculated?\n",
    "\n",
    "Explain briefly the output of the code? What is the expression we differentiate and with respect to what variables?\n",
    "\n",
    "$$\n",
    "f = c + e \\\\\n",
    "f = a \\cdot b + a \\cdot e\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8_Q0t2I3Ruj"
   },
   "source": [
    "## Exercise b) How does the backward function work?\n",
    "\n",
    "You need to understand how the backward function calculates the gradients. We can use the two examples above to help with that.\n",
    "\n",
    "Go through the following four steps and answer the questions on the way:\n",
    "\n",
    "1. We represent the two expressions as graphs as shown below. Fill in the missing expressions for the different derivatives.\n",
    "\n",
    "2. In the remainder consider the first expression. Make a schematic of the data structure which is generated when we define the expression for f. \n",
    "\n",
    "3. Then execute the backward function by hand to convince yourself that it indeed calculates the gradients with respect to the variables. \n",
    "\n",
    "4. Write down the sequence of calls to backprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "idGr71jYXl26"
   },
   "outputs": [],
   "source": [
    "# import logging\n",
    "import graphviz\n",
    "\n",
    "#logging.basicConfig(format='[%(levelname)s@%(name)s] %(message)s', level=logging.DEBUG)\n",
    "\n",
    "#graphviz.__version__, graphviz.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152
    },
    "id": "KPe30Q2QXzeG",
    "outputId": "7fa002cd-a018-4dbb-ddf1-28ed5e99ee19"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 3.0.0 (0)\n",
       " -->\n",
       "<!-- Title: first expression Pages: 1 -->\n",
       "<svg width=\"160pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 160.00 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>first expression</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-94 156,-94 156,4 -4,4\"/>\n",
       "<!-- a -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>a</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-72\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"18\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "</g>\n",
       "<!-- f -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>f</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"134\" cy=\"-45\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"134\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">f</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;f -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>a&#45;&gt;f</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.82,-68.02C54.34,-63.63 84.38,-56.51 106.17,-51.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107.19,-54.71 116.11,-49 105.57,-47.9 107.19,-54.71\"/>\n",
       "<text text-anchor=\"middle\" x=\"76\" y=\"-66.8\" font-family=\"Times,serif\" font-size=\"14.00\">df/da=5</text>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>b</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-18\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"18\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
       "</g>\n",
       "<!-- b&#45;&gt;f -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>b&#45;&gt;f</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M36.07,-20.92C52.15,-23.8 76.86,-28.55 98,-34 100.89,-34.74 103.9,-35.59 106.88,-36.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.13,-39.9 116.72,-39.49 108.19,-33.21 106.13,-39.9\"/>\n",
       "<text text-anchor=\"middle\" x=\"76\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">df/db=3</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x10400ee50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = graphviz.Digraph('first expression', filename='fsm.gv')\n",
    "\n",
    "e1.attr(rankdir='LR', size='8,5')\n",
    "\n",
    "e1.attr('node', shape='circle')\n",
    "e1.edge('a', 'f', label='df/da=5')\n",
    "e1.edge('b', 'f', label='df/db=3')\n",
    "\n",
    "e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "0nittR-mZFeX",
    "outputId": "fa3656a3-732c-4abe-8084-98a492b0d6be"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 3.0.0 (0)\n",
       " -->\n",
       "<!-- Title: second expression Pages: 1 -->\n",
       "<svg width=\"277pt\" height=\"158pt\"\n",
       " viewBox=\"0.00 0.00 277.00 158.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 154)\">\n",
       "<title>second expression</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-154 273,-154 273,4 -4,4\"/>\n",
       "<!-- a -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>a</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-75\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"18\" y=\"-71.3\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "</g>\n",
       "<!-- c -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>c</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"136\" cy=\"-102\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-98.3\" font-family=\"Times,serif\" font-size=\"14.00\">c</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;c -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>a&#45;&gt;c</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.62,-78.87C54.66,-83.3 86.1,-90.62 108.52,-95.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107.88,-99.28 118.41,-98.14 109.46,-92.46 107.88,-99.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"77\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">dc/da=5</text>\n",
       "</g>\n",
       "<!-- e -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>e</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"136\" cy=\"-48\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-44.3\" font-family=\"Times,serif\" font-size=\"14.00\">e</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;e -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>a&#45;&gt;e</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.28,-69.48C41.14,-67.6 47.83,-65.57 54,-64 71.83,-59.45 92.15,-55.44 107.97,-52.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"108.89,-55.97 118.13,-50.78 107.67,-49.07 108.89,-55.97\"/>\n",
       "<text text-anchor=\"middle\" x=\"77\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\">de/da=9</text>\n",
       "</g>\n",
       "<!-- f -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>f</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"251\" cy=\"-75\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"251\" y=\"-71.3\" font-family=\"Times,serif\" font-size=\"14.00\">f</text>\n",
       "</g>\n",
       "<!-- c&#45;&gt;f -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>c&#45;&gt;f</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M153.67,-98.02C172.03,-93.63 201.81,-86.51 223.4,-81.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224.35,-84.73 233.26,-79 222.72,-77.92 224.35,-84.73\"/>\n",
       "<text text-anchor=\"middle\" x=\"193.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">df/dc=1</text>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>b</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-132\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"18\" y=\"-128.3\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
       "</g>\n",
       "<!-- b&#45;&gt;c -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>b&#45;&gt;c</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.62,-127.7C54.66,-122.78 86.1,-114.65 108.52,-108.85\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109.61,-112.18 118.41,-106.29 107.85,-105.41 109.61,-112.18\"/>\n",
       "<text text-anchor=\"middle\" x=\"77\" y=\"-125.8\" font-family=\"Times,serif\" font-size=\"14.00\">dc/db=3</text>\n",
       "</g>\n",
       "<!-- e&#45;&gt;f -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>e&#45;&gt;f</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M153.85,-50.94C169.73,-53.83 194.12,-58.59 215,-64 217.89,-64.75 220.9,-65.59 223.88,-66.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"223.13,-69.9 233.72,-69.5 225.19,-63.21 223.13,-69.9\"/>\n",
       "<text text-anchor=\"middle\" x=\"193.5\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\">df/de=1</text>\n",
       "</g>\n",
       "<!-- d -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>d</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-18\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"18\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">d</text>\n",
       "</g>\n",
       "<!-- d&#45;&gt;e -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>d&#45;&gt;e</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.93,-20.8C52.45,-23.7 78.19,-28.7 100,-35 103.18,-35.92 106.48,-36.99 109.72,-38.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"108.54,-41.4 119.14,-41.54 110.94,-34.83 108.54,-41.4\"/>\n",
       "<text text-anchor=\"middle\" x=\"77\" y=\"-38.8\" font-family=\"Times,serif\" font-size=\"14.00\">de/dd=3</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x104023580>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2 = graphviz.Digraph('second expression', filename='fsm.gv')\n",
    "\n",
    "e2.attr(rankdir='LR', size='8,5')\n",
    "\n",
    "e2.attr('node', shape='circle')\n",
    "e2.edge('a', 'c', label='dc/da=5')\n",
    "e2.edge('b', 'c', label='dc/db=3')\n",
    "e2.edge('a', 'e', label='de/da=9')\n",
    "e2.edge('d', 'e', label='de/dd=3')\n",
    "e2.edge('c', 'f', label='df/dc=1')\n",
    "e2.edge('e', 'f', label='df/de=1')\n",
    "\n",
    "e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5oi21W4gpeM"
   },
   "source": [
    "## Exercise c) What happens if we run backward again?\n",
    "\n",
    "Try to execute the code below. Explain what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCtpJyr-gyX1",
    "outputId": "d014bcfa-c9ae-49c3-d268-91cc6ca94ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var(v=3.0000, grad=28.0000)\n",
      "Var(v=5.0000, grad=6.0000)\n",
      "Var(v=15.0000, grad=2.0000)\n",
      "Var(v=9.0000, grad=6.0000)\n",
      "Var(v=27.0000, grad=2.0000)\n",
      "Var(v=42.0000, grad=2.0000)\n"
     ]
    }
   ],
   "source": [
    "f.backward()\n",
    "\n",
    "for v in [a, b, c, d, e, f]:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer suggestion:\n",
    "the gradients are recalculated. for the variables which have not been multiplied with another vatiable, the gradient increases by one, The variables which have been multiplied with other variables, the values they have been multiplied with, are added to the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8bPVq2VhsP-"
   },
   "source": [
    "## Exercise d) Zero gradient\n",
    "\n",
    "We can zero the gradient by backpropagating a -1.0 as is shown in the example below. (If you have run backward multiple time then you also have to run the cell below an equal amount of times.) Explain what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnyPDQx9lJe0",
    "outputId": "7a125fdc-60c4-4340-a580-8b82aea5b0db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var(v=2.0000, grad=0.0000)\n",
      "Var(v=5.0000, grad=6.0000)\n",
      "Var(v=15.0000, grad=2.0000)\n",
      "Var(v=9.0000, grad=6.0000)\n",
      "Var(v=27.0000, grad=2.0000)\n",
      "Var(v=42.0000, grad=2.0000)\n",
      "\n",
      "Var(v=2.0000, grad=0.0000)\n",
      "Var(v=5.0000, grad=3.0000)\n",
      "Var(v=15.0000, grad=1.0000)\n",
      "Var(v=9.0000, grad=3.0000)\n",
      "Var(v=27.0000, grad=1.0000)\n",
      "Var(v=42.0000, grad=1.0000)\n",
      "\n",
      "Var(v=2.0000, grad=0.0000)\n",
      "Var(v=5.0000, grad=0.0000)\n",
      "Var(v=15.0000, grad=0.0000)\n",
      "Var(v=9.0000, grad=0.0000)\n",
      "Var(v=27.0000, grad=0.0000)\n",
      "Var(v=42.0000, grad=0.0000)\n",
      "\n",
      "Var(v=2.0000, grad=0.0000)\n",
      "Var(v=5.0000, grad=-3.0000)\n",
      "Var(v=15.0000, grad=-1.0000)\n",
      "Var(v=9.0000, grad=-3.0000)\n",
      "Var(v=27.0000, grad=-1.0000)\n",
      "Var(v=42.0000, grad=-1.0000)\n"
     ]
    }
   ],
   "source": [
    "a = Var(2.0)\n",
    "\n",
    "for v in [a, b, c, d, e, f]:\n",
    "    print(v)\n",
    "\n",
    "f.backprop(-1.0)\n",
    "print('')\n",
    "\n",
    "for v in [a, b, c, d, e, f]:\n",
    "    print(v)\n",
    "    \n",
    "f.backprop(-1.0)\n",
    "print('')\n",
    "\n",
    "for v in [a, b, c, d, e, f]:\n",
    "    print(v)\n",
    "\n",
    "f.backprop(-1.0)\n",
    "print('')\n",
    "\n",
    "for v in [a, b, c, d, e, f]:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer suggestion:\n",
    "The gradient of a is reset to zero. Each time backprop(-1) the gradient of a single backward pass is subtracted from the accumulated gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4057_ljNvWB"
   },
   "source": [
    "## Exercise e) Test correctness of derivatives with the finite difference method\n",
    "\n",
    "Write a small function that uses [the finite difference method](https://en.wikipedia.org/wiki/Finite_difference_method) to numerically test that backpropation implementation is working. In short we will use\n",
    "$$\n",
    "\\frac{\\partial f(a)}{\\partial a} \\approx \\frac{f(a+da)-f(a)}{da}\n",
    "$$\n",
    "for $da \\ll 1$.\n",
    "\n",
    "As an example, we could approximate the derivative of the function $f(a)=a^2$ in e.g. the value $a=4$ using the finite difference method. This amounts to inserting the relevant values and approximating the gradient $f'(4)$ with the fraction above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9TGil92lSXDN",
    "outputId": "7ef5489b-b525-4132-ab08-0b1109c07f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var(v=3.0000, grad=5.0000)\n",
      "Var(v=5.0000, grad=3.0000)\n",
      "Var(v=15.0000, grad=1.0000)\n",
      "1.000000082740371\n"
     ]
    }
   ],
   "source": [
    "# f function - try to change the code to test other types of functions as well (such as different polynomials etc.)\n",
    "def f_function(a):\n",
    "    a = Var(a)\n",
    "    b = Var(5.0)\n",
    "    f = a * b\n",
    "    f.backward()\n",
    "    return a,b,f\n",
    "\n",
    "for v in f_function(3.0):\n",
    "    print(v)\n",
    "\n",
    "# Insert your finite difference code here\n",
    "def finite_difference(da=1e-10):\n",
    "    \"\"\"\n",
    "    This function compute the finite difference between\n",
    "    \n",
    "    Input:\n",
    "    da:          The finite difference                           (float)\n",
    "    \n",
    "    Output:\n",
    "    finite_difference: numerical approximation to the derivative (float) \n",
    "    \"\"\"\n",
    "    \n",
    "    fa_da = f_function(1.0+da)[0]           # <- Insert correct expression\n",
    "    fa = f_function(1.0)[0]               # <- Insert correct expression\n",
    "\n",
    "    finite_difference = (fa_da.v - fa.v) / da\n",
    "    \n",
    "    return finite_difference\n",
    "\n",
    "print(finite_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pZar5RKaUkg"
   },
   "source": [
    "# Create an artificial dataset to play with\n",
    "\n",
    "We create a non-linear 1d regression task. The generator supports various noise levels and it creates train, validation and test sets. You can modify it yourself if you want more or less challenging tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Y6yfMAQ8aduj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4YabfD43ajNh"
   },
   "outputs": [],
   "source": [
    "def data_generator(noise=0.1, n_samples=300, D1=True):\n",
    "    # Create covariates and response variable\n",
    "    if D1:\n",
    "        X = np.linspace(-3, 3, num=n_samples).reshape(-1,1) # 1-D\n",
    "        np.random.shuffle(X)\n",
    "        y = np.random.normal((0.5*np.sin(X[:,0]*3) + X[:,0]), noise) # 1-D with trend\n",
    "    else:\n",
    "        X = np.random.multivariate_normal(np.zeros(3), noise*np.eye(3), size = n_samples) # 3-D\n",
    "        np.random.shuffle(X)    \n",
    "        y = np.sin(X[:,0]) - 5*(X[:,1]**2) + 0.5*X[:,2] # 3-D\n",
    "\n",
    "    # Stack them together vertically to split data set\n",
    "    data_set = np.vstack((X.T,y)).T\n",
    "    \n",
    "    train, validation, test = np.split(data_set, [int(0.35*n_samples), int(0.7*n_samples)], axis=0)\n",
    "    \n",
    "    # Standardization of the data, remember we do the standardization with the training set mean and standard deviation\n",
    "    train_mu = np.mean(train, axis=0)\n",
    "    train_sigma = np.std(train, axis=0)\n",
    "    \n",
    "    train = (train-train_mu)/train_sigma\n",
    "    validation = (validation-train_mu)/train_sigma\n",
    "    test = (test-train_mu)/train_sigma\n",
    "    \n",
    "    x_train, x_validation, x_test = train[:,:-1], validation[:,:-1], test[:,:-1]\n",
    "    y_train, y_validation, y_test = train[:,-1], validation[:,-1], test[:,-1]\n",
    "\n",
    "    return x_train, y_train,  x_validation, y_validation, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "u1oDngHLapIz"
   },
   "outputs": [],
   "source": [
    "D1 = True\n",
    "x_train, y_train,  x_validation, y_validation, x_test, y_test = data_generator(noise=0.5, D1=D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "Ysfa3FsBavlm",
    "outputId": "399e5382-ae7d-48f6-9774-7ea4c73e7d95"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if D1:\n",
    "    plt.scatter(x_train[:,0], y_train);\n",
    "    plt.scatter(x_validation[:,0], y_validation);\n",
    "    plt.scatter(x_test[:,0], y_test);\n",
    "else:\n",
    "    plt.scatter(x_train[:,1], y_train);\n",
    "    plt.scatter(x_validation[:,1], y_validation);\n",
    "    plt.scatter(x_test[:,1], y_test);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zac2HHNlgbpm"
   },
   "outputs": [],
   "source": [
    "# convert from nparray to Var\n",
    "def nparray_to_Var(x):\n",
    "    if x.ndim==1:\n",
    "        y = [[Var(float(x[i]))] for i in range(x.shape[0])] # always work with list of list\n",
    "    else:\n",
    "        y = [[Var(float(x[i,j])) for j in range(x.shape[1])] for i in range(x.shape[0])]\n",
    "    return y\n",
    "   \n",
    "x_train = nparray_to_Var(x_train)\n",
    "y_train = nparray_to_Var(y_train)\n",
    "x_validation = nparray_to_Var(x_validation)\n",
    "y_validation = nparray_to_Var(y_validation)\n",
    "x_test = nparray_to_Var(x_test)\n",
    "y_test = nparray_to_Var(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbjrqcpVFtGe"
   },
   "source": [
    "# Defining and initializing the network\n",
    "\n",
    "The steps to create a feed forward neural network are the following:\n",
    "\n",
    "1. **Number of hidden layer and hidden units**. We have to define the number of hidden units in each layer. The number of features in X and the output dimensionality (the size of Y) are given but the numbers in between are set by the researcher. Remember that for each unit in each layer beside in the input has a bias term.\n",
    "2. **Activation functions** for each hidden layer. Each hidden layer in your list must have an activation function (it can also be the linear activation which is equivalent to identity function). The power of neural networks comes from non-linear activation functions that learn representations (features) from the data allowing us to learn from it. \n",
    "3. **Parameter initialization**. We will initialize the weights to have random values. This is done in practice by drawing pseudo random numbers from a Gaussian or uniform distribution. It turns out that for deeper models we have to be careful about how we scale the random numbers. This will be the topic of the exercise below. For now we will just use unit variance Gaussians.  \n",
    "\n",
    "In order to make life easier for ourselves we define a DenseLayer class that takes care of initialization and the forward pass. We can also extend it later with print and advanced initialization capabilities. For the latter we have introduced a Initializer class.\n",
    "\n",
    "Note that we use Sequence in the code below. A Sequence is an ordered list. This means the order we insert and access items are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ij_ieRsAt7Xt"
   },
   "outputs": [],
   "source": [
    "class Initializer:\n",
    "    def init_weights(self, n_in, n_out):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def init_bias(self, n_out):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eb18N5phuIha"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class NormalInitializer(Initializer):\n",
    "\n",
    "    def __init__(self, mean=0, std=0.1):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def init_weights(self, n_in, n_out):\n",
    "        return [[Var(random.gauss(self.mean, self.std)) for _ in range(n_out)] for _ in range(n_in)]\n",
    "\n",
    "    def init_bias(self, n_out):\n",
    "        return [Var(0.0) for _ in range(n_out)]\n",
    "\n",
    "class ConstantInitializer(Initializer):\n",
    "\n",
    "    def __init__(self, weight=1.0, bias=0.0):\n",
    "        self.weight = weight\n",
    "        self.bias = bias\n",
    "\n",
    "    def init_weights(self, n_in, n_out):\n",
    "        return [[Var(self.weight) for _ in range(n_out)] for _ in range(n_in)]\n",
    "\n",
    "    def init_bias(self, n_out):\n",
    "        return [Var(self.bias) for _ in range(n_out)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jOLYGnZKuM6W"
   },
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, n_in: int, n_out: int, act_fn, initializer = NormalInitializer()):\n",
    "        self.weights = initializer.init_weights(n_in, n_out)\n",
    "        self.bias = initializer.init_bias(n_out)\n",
    "        self.act_fn = act_fn\n",
    "    \n",
    "    def __repr__(self):    \n",
    "        return 'Weights: ' + repr(self.weights) + ' Biases: ' + repr(self.bias)\n",
    "\n",
    "    def parameters(self) -> Sequence[Var]:\n",
    "        params = []\n",
    "        for r in self.weights:\n",
    "            params += r\n",
    "\n",
    "        return params + self.bias\n",
    "\n",
    "    def forward(self, single_input: Sequence[Var]) -> Sequence[Var]:\n",
    "        # self.weights is a matrix with dimension n_in x n_out. We check that the dimensionality of the input \n",
    "        # to the current layer matches the number of nodes in the current layer\n",
    "        assert len(self.weights) == len(single_input), \"weights and single_input must match in first dimension\"\n",
    "        weights = self.weights\n",
    "        out = []\n",
    "        # For some given data point single_input, we now want to calculate the resulting value in each node in the current layer\n",
    "        # We therefore loop over the (number of) nodes in the current layer:\n",
    "        for j in range(len(weights[0])): \n",
    "            # Initialize the node value depending on its corresponding parameters.\n",
    "            node = self.parameters()[j] # <- Insert code\n",
    "            # We now finish the linear transformation corresponding to the parameters of the currently considered node.\n",
    "            for i in range(len(single_input)):\n",
    "                node += single_input[i] * weights[0][j]  # <- Insert code\n",
    "            node = self.act_fn(node)\n",
    "            out.append(node)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpIZPBpNI0pO"
   },
   "source": [
    "## Exercise f) Add more activation functions\n",
    "\n",
    "To have a full definition of the neural network, we must define an activation function for every layer. Several activation functions have been proposed and have different characteristics. In the Var class we have already defined the rectified linear init (relu). \n",
    " \n",
    "Implement the following activation functions in the Var class:\n",
    "\n",
    "* Identity: $$\\mathrm{identity}(x) = x$$\n",
    "* Hyperbolic tangent: $$\\tanh(x)$$\n",
    "* Sigmoid (or logistic function): $$\\mathrm{sigmoid}(x) = \\frac{1}{1.0 + \\exp(-x ) }$$  Hint: $\\mathrm{sigmoid}'(x)= \\mathrm{sigmoid}(x)(1-\\mathrm{sigmoid}(x))$.  \n",
    "\n",
    "Hint: You can seek inspiration in the relu method in the Var class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Answer suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def relu(self):\n",
    "    return Var(self.v if self.v > 0.0 else 0.0, lambda: [(self, 1.0 if self.v > 0.0 else 0.0)])\n",
    "\n",
    "def identity(self):\n",
    "    return self\n",
    "\n",
    "def tanh(self):\n",
    "    return Var(1 - 2/(math.exp(2*self.v)+1), lambda: [(self, 1.0)])\n",
    "\n",
    "def sigmoid(self):\n",
    "    return Var(1/(1+math.exp(-self.v)), lambda: [(self, 1.0)])\n",
    "\n",
    "Var.identity = identity\n",
    "Var.tanh = tanh\n",
    "Var.sigmoid = sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_8n_SKnIW2F"
   },
   "source": [
    "## Exercise g) Complete the forward pass\n",
    "\n",
    "In the code below we initialize a 1-5-1 network and pass the training set through it. *The forward method in DenseLayer is **not** complete*. It just outputs zeros right now. The method forward should perform an [affine transformation](https://en.wikipedia.org/wiki/Affine_transformation) on the input followed by an application of the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "xDEjtePxE7Mv",
    "outputId": "753406cd-d8a1-4282-ce03-25ad959b0e11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Var(v=0.0620, grad=0.0000)], [Var(v=0.0667, grad=0.0000)], [Var(v=0.0581, grad=0.0000)], [Var(v=0.0548, grad=0.0000)], [Var(v=0.0642, grad=0.0000)], [Var(v=0.0637, grad=0.0000)], [Var(v=0.0614, grad=0.0000)], [Var(v=0.0549, grad=0.0000)], [Var(v=0.0551, grad=0.0000)], [Var(v=0.0599, grad=0.0000)], [Var(v=0.0645, grad=0.0000)], [Var(v=0.0510, grad=0.0000)], [Var(v=0.0631, grad=0.0000)], [Var(v=0.0516, grad=0.0000)], [Var(v=0.0604, grad=0.0000)], [Var(v=0.0633, grad=0.0000)], [Var(v=0.0684, grad=0.0000)], [Var(v=0.0626, grad=0.0000)], [Var(v=0.0578, grad=0.0000)], [Var(v=0.0591, grad=0.0000)], [Var(v=0.0526, grad=0.0000)], [Var(v=0.0552, grad=0.0000)], [Var(v=0.0654, grad=0.0000)], [Var(v=0.0655, grad=0.0000)], [Var(v=0.0545, grad=0.0000)], [Var(v=0.0519, grad=0.0000)], [Var(v=0.0678, grad=0.0000)], [Var(v=0.0689, grad=0.0000)], [Var(v=0.0585, grad=0.0000)], [Var(v=0.0646, grad=0.0000)], [Var(v=0.0541, grad=0.0000)], [Var(v=0.0590, grad=0.0000)], [Var(v=0.0527, grad=0.0000)], [Var(v=0.0534, grad=0.0000)], [Var(v=0.0629, grad=0.0000)], [Var(v=0.0557, grad=0.0000)], [Var(v=0.0549, grad=0.0000)], [Var(v=0.0535, grad=0.0000)], [Var(v=0.0515, grad=0.0000)], [Var(v=0.0522, grad=0.0000)], [Var(v=0.0537, grad=0.0000)], [Var(v=0.0524, grad=0.0000)], [Var(v=0.0682, grad=0.0000)], [Var(v=0.0512, grad=0.0000)], [Var(v=0.0525, grad=0.0000)], [Var(v=0.0515, grad=0.0000)], [Var(v=0.0643, grad=0.0000)], [Var(v=0.0639, grad=0.0000)], [Var(v=0.0551, grad=0.0000)], [Var(v=0.0641, grad=0.0000)], [Var(v=0.0602, grad=0.0000)], [Var(v=0.0575, grad=0.0000)], [Var(v=0.0647, grad=0.0000)], [Var(v=0.0524, grad=0.0000)], [Var(v=0.0690, grad=0.0000)], [Var(v=0.0676, grad=0.0000)], [Var(v=0.0540, grad=0.0000)], [Var(v=0.0536, grad=0.0000)], [Var(v=0.0611, grad=0.0000)], [Var(v=0.0534, grad=0.0000)], [Var(v=0.0641, grad=0.0000)], [Var(v=0.0512, grad=0.0000)], [Var(v=0.0550, grad=0.0000)], [Var(v=0.0606, grad=0.0000)], [Var(v=0.0597, grad=0.0000)], [Var(v=0.0529, grad=0.0000)], [Var(v=0.0536, grad=0.0000)], [Var(v=0.0660, grad=0.0000)], [Var(v=0.0509, grad=0.0000)], [Var(v=0.0607, grad=0.0000)], [Var(v=0.0548, grad=0.0000)], [Var(v=0.0562, grad=0.0000)], [Var(v=0.0640, grad=0.0000)], [Var(v=0.0612, grad=0.0000)], [Var(v=0.0564, grad=0.0000)], [Var(v=0.0679, grad=0.0000)], [Var(v=0.0529, grad=0.0000)], [Var(v=0.0530, grad=0.0000)], [Var(v=0.0517, grad=0.0000)], [Var(v=0.0684, grad=0.0000)], [Var(v=0.0590, grad=0.0000)], [Var(v=0.0583, grad=0.0000)], [Var(v=0.0539, grad=0.0000)], [Var(v=0.0560, grad=0.0000)], [Var(v=0.0527, grad=0.0000)], [Var(v=0.0553, grad=0.0000)], [Var(v=0.0556, grad=0.0000)], [Var(v=0.0521, grad=0.0000)], [Var(v=0.0542, grad=0.0000)], [Var(v=0.0547, grad=0.0000)], [Var(v=0.0613, grad=0.0000)], [Var(v=0.0543, grad=0.0000)], [Var(v=0.0518, grad=0.0000)], [Var(v=0.0635, grad=0.0000)], [Var(v=0.0523, grad=0.0000)], [Var(v=0.0541, grad=0.0000)], [Var(v=0.0602, grad=0.0000)], [Var(v=0.0578, grad=0.0000)], [Var(v=0.0673, grad=0.0000)], [Var(v=0.0518, grad=0.0000)], [Var(v=0.0638, grad=0.0000)], [Var(v=0.0519, grad=0.0000)], [Var(v=0.0528, grad=0.0000)], [Var(v=0.0605, grad=0.0000)], [Var(v=0.0666, grad=0.0000)]]\n"
     ]
    }
   ],
   "source": [
    "NN = [\n",
    "    DenseLayer(1, 5, lambda x: x.relu()),\n",
    "    DenseLayer(5, 1, lambda x: x.identity())\n",
    "]\n",
    "\n",
    "def forward(input, network):\n",
    "\n",
    "    def forward_single(x, network):\n",
    "        for layer in network:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    output = [ forward_single(input[n], network) for n in range(len(input))]\n",
    "    return output\n",
    "print(forward(x_train, NN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLrGJytZFtGm"
   },
   "source": [
    "## Exercise h) Print all network parameters\n",
    "\n",
    "Make a function that prints all the parameters of the network (weights and biases) with information about in which layer the appear. In the object oriented spirit you should introduce a method in the DenseLayer class to print the parameters of a layer. Hint: You can take inspiration from the corresponding method in Var. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "iac-VwYGFtGm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights\n",
      "[[Var(v=0.1279, grad=0.0000), Var(v=-0.0425, grad=0.0000), Var(v=-0.0655, grad=0.0000), Var(v=-0.0085, grad=0.0000), Var(v=-0.0335, grad=0.0000)]]\n",
      "bias\n",
      "[Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000)]\n",
      "weights\n",
      "[[Var(v=0.0508, grad=0.0000)], [Var(v=0.0177, grad=0.0000)], [Var(v=-0.1827, grad=0.0000)], [Var(v=0.1423, grad=0.0000)], [Var(v=0.0433, grad=0.0000)]]\n",
      "bias\n",
      "[Var(v=0.0000, grad=0.0000)]\n"
     ]
    }
   ],
   "source": [
    "# Insert code here and in the DenseLayer class\n",
    "def get_params(self):\n",
    "    print('weights')\n",
    "    print(self.weights)\n",
    "    print('bias')\n",
    "    print(self.bias)\n",
    "\n",
    "DenseLayer.get_params = get_params\n",
    "\n",
    "for layer in NN:\n",
    "    layer.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_79HOAXrFtHK"
   },
   "source": [
    "## Visualization\n",
    "\n",
    "Now that we have defined our activation functions we can visualize them to see what they look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1FcylHqLTl-Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x110a6e5e0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-6, 6, 100)\n",
    "\n",
    "# convert from Var to ndarray  \n",
    "def Var_to_nparray(x):\n",
    "    y = np.zeros((len(x),len(x[0])))\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(x[0])):\n",
    "            y[i,j] = x[i][j].v\n",
    "    return y\n",
    "\n",
    "# define 1-1 network with weight = 1 and relu activation \n",
    "NN = [ DenseLayer(1, 1, lambda x: x.relu(), initializer = ConstantInitializer(1.0)) ] \n",
    "y = Var_to_nparray(forward(nparray_to_Var(x), NN))\n",
    "\n",
    "#y = Var_to_nparray(relu(nparray_to_Var(x)))\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "oOL2UolJFtHL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAFECAYAAAC+gVKXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABBTklEQVR4nO3dd3gUZdfA4d/Z3TRS6RBaQJSOLQhiQ0WqDX0RxAIqoq8VCyKKgoLYO6IgKOqnor5WEEUUQVFAQFS6dAgtoQZI3d3n+2M2IRUSssnsJue+rr12d+aZmTO7m5Nn5kwRYwxKKVWVOOwOQCmlKpomPqVUlaOJTylV5WjiU0pVOZr4lFJVjiY+pVSVo4mvihGRqSJiRCTB7ljy8sU01+44ChKRe0RklYik+2IcandMJyJQv3e7VLrEJyKJIvKuiGz0/VhTRWS5iDwvIg3sjq+8icho3w+8i92x5CUim0Vks91xlIaI9AdeBTKAV4AngIV2xlScQP3eA5XL7gD8RUQEeAZ4CHADs4HPgFCgM/AgcIeIDDTG/M+2QO03Autz2m53IAW0AtLsDqKAS3OejTE7bI2k7AL1e7dFpUl8wGNYSW8z1g91Zd6RInI18H/ANBG5xBjzc8WHaD9jzE5gp91xFGSMWWN3DEWIB6gESS9gv3fbGGOC/gEkANlAFtDuGO1uBwywBnDkGT7aN7xLMfM2wNQCw6f6hjcD7gb+AdKBuSWI90JgErAKSPVNtwIYBYQXM43TF/9vwEHfNOuBycDJvjabfTEVehQRd4Lv/dm+918cI97VQCZQw/c+FLgLmAls8Y3bB/wI9CwwbZfiYsr7mfreF/rsgFjgaWAt1ibnfmAW0LWItjnLGg2cBnwLHMDqSc4DOpfw9zSaY3yOxf0m8kw/N+9nXpbYyut7L7CMa4Bf8sx/OVYPMayItpt9j2rA88BW3/e/HhgOSBHTXA78hJV4M4EdvnW+w66cUVl6fDdh9V4/NcYsP0a7yVg9wxbABYA/en2vAudh/ZBnAp4STDMcaAn87psuHDgH64+ii4h0NcbkzkdEQn3tugLbgI+wEmYC0AeYD6zD2g91Jda6vYf1Az0mY8wCEVkLXCoiNY0xe/OOF5GzfLF+bozZ5xtcw7fev2PtUkgB6gOXATNF5FZjzGRf281Y+8aG+t6/kmf2fx0rNhGJw/qDbw0s9k1bC+sP9QcR+a8xZmIRkyZi9f4XYH3njYGrgZ9E5DRjzNpjLRcrcQEMApr44veXEsdWnt97nmWMw0pye3zzPwz0BMYB3X1bR9kFJgsBfsDqEX+HtWvpSqxN6XDyfF4iMgSYCOwCpvuWUwdoj/V3O6GksfqVXRnXnw+s/yYGuLUEbT/0tR2ZZ9hoTrzHtx1oWsp4m1H0f8Yxvnn2KzB8nG/4NxT4LwyEAbVLsi4F4k7IM2yEb9hdRbR/wzfusgLLbFhE21isnus+IKLAuM3A5mN8JoV6fFh/MMb3LHmGn4zVO8kssB5dONrbGVRgXrf5hk8oxfc0lwI9t2P9Jo413YnEVgHfe05vfytQL89wF1aSMsAjRXyPBuuffESe4XWwerAHgJA8w5f6vqc6RcRUqzR/N/58VJaqbn3f87YStM1pE++nZT9njNlUmgmMMRuN75sv4BXfc/ecASLiBO7A2gS53RiTWWBemcaYlNKFXMgHgBcYmHegr8fRH0jG+s+ed5lJBWdijDkIvANUBzqUJSARCQGux+qBjMj7eRlj1gGvYW1y31jE5L8ZY6YWGPYOVs/krLLE5Qcliq2Cvvebfc9jjTG78szbDTyA9ZsYXMy09xhj0vNMkwx8jfXPr0WBtm6sXVH5GGP2nHjoZVNZEp/4notKJmVpWxJ/lHYCEYkUkUdEZLGIHBQRr4gYrM0AgLyH3bTE+jH9Y8ppJ7svif0EJIpI6zyjLsParP3Q98eQdx3a+I4NyzlsyPjW4cUi1uFEtMTaj/S3ObqJndcc3/PpRYxbUnCAsTbXdmMlZTuVNLZy/96BM3zPcwqOMMb8CyQBTX27HPI6aIxZX8T8cjoVedfjQ6zvcaWIvCwiV4pI7bKFXXaVZR/fTqwfSuMStG2YZxp/2HX8Jkf5ejJzsP67rwA+wdpHlvMfcRTWZkyOON9zeR+GMBW4BKvXN9w3LKcH+F7ehiLSCWsdXFgJ8xusfU9erB33V5B/HU5ErO+5uO8pZ3hcEeMOFDONG6tYYKcDxQwvGFuc77k8v/eSfMaNfe0O5Bl+oKjGWOsAedbDGPOSiOzB6r3eg7Wv14jIPGCYMabQP4KKUFkS33ysSmlX4O3iGvk2H7r43v6WZ5TX91zU5xF3nGWXtud4BVbSe88YM6hAfPWxEl9eB3zP5X3w9ZdYyet6EXkEq6fXE6vH9XeBtiOBCOBCY8zcvCNEZATWOpbVQd9zvWLG1y/QriId6/cCx//NlMQB33N5fu95P+MNRYz3y2dsjHkfeN/Xc+yMVZi5GZglIq18m8kVqrJs6k7Fqqb2EZE2x2h3M9a+vbVY5fQc+33PjYqYJtEfAebR3Pf8eRHjLihi2BqsP4L2IlKS/ZI51eBS9Wx8+2s+xfp8ugLXYf1hv1dE8+bAvoJJz6eodciJqzQxrcU61OM0ESlq8/RC3/OfpZinvxT7exGRGOAUPyyjIr73Zb7nLgVHiEhzrK2jTcaYA6WYZ7GMMQeMMTONMbdi/c3WwDoiosJVisRnjNmIVQELAb4psJ8KABG5EusQDA/W8UPePKNz9tPdJCKuPNM0Ah73c7ibfc9dCsTXDHi2YGNjHdYyAauH9ZaIhBWYLrTAPpOcw1FKstlf0FTf842+hxtrH01Bm4EaItK+QCy3kKcwU8BeoLaIRJQkEGNMlm/ZUcCTBZZzEtZmUzZWYaZCGWMOYSWmc/L+1nxbFC9hfVdlXUZFfO/v+J5H5p2Xbz1ewMoPU0obe4E4e+T9m8qjju/ZlrN1KsumLljl/EjgfuBvEZkFrMRKhp2BjlgVsmuNMfl25hpjFonIL8D5wB8iMgeoi7VzfxZF9wRP1HSsgz3vF5F2WP91G2OdHvUtRf9wn/DFfxnwr4jMAA754uoGDONo0voZa1PsaRFpi693YowZe7zAjDG/ich6oC/W5za9mM2QV7AS3HwR+RRrUygROBf4H/CfIqb5CavS+73vs87E2oyefoyQHsbqEdwlIh1865ZzHF801uE3paqo+9HzWEnhNxH5DOvg6guxPre/gVP9sIxy/d6NMb+LyHNYxxWuEJH/AUewdnG0xdqF9HwZ12EakCEi87H+YQrWd9oB61CXH8s4/xNj13E05fXAt/8M2ISV6A5jFRFeoIhjz/JMF4e1fzAZ649yBTCE4x/Hl3ACMTbC6s1s98W4EuvH56L4MxhcWGdL/OFbpyNYB69OApoXaHs91sHB6ZTiCH7f+JE50wBXH2MdLsU6Yf8Q1ibZD1j/OAZR9LFqkcCbWJVCd8HP9BjrHYfVE17n+14OYB003a2Itl188xldTMybOcaxhEW0n5v3syti/C2+7y4Tq8g1EahZ1HQnGltFfO9YhyzN932XGb51epQiziI61mdIEccSYp118iWwEat3tw/rn/1DQLQ//uZP5CG+4JRSqsqoFPv4lFKqNPyyj893nbVDWIUDtzHG35VQpZTyG38WNy40Np6CopRSJaWbukqpKsdfic9gXSZoqe8yNEopFbD8tal7jjFmh4jUAWaLyBpjzC95G/gS4hCAyMjIM1u2bOmnRSul/CHTnc36A+tBvNQMi6delN3Xcyi9pUuX7jHGHPciCH4/nEVERgOHjTEvFNcmMTHRLFliy7nJSqli9Pi/O9nu+YVo05b5N36IwxF8e8JEZGlJiqtlXjPfJZaic15jHVG+oqzzVUpVnE/++ZXtnl8wXifPX/h4UCa90vDHpm5d4EvrJme4gI+MMd/7Yb5KqQqQ5Xbz7JKnwQntoy/nnCat7A6p3JU58RnrAgH+OC9RKWWDh2dPJNu5DXFX5/Vew+wOp0JU7v6sUuqYNuzdxeyd1pXHbjjlbmpWi7Y5ooqhiU+pKuyu78eCM51obxseOOdqu8OpMJr4lKqiPl0+nyT3PIxx8myXyl/QyCtgr8eXmppKcnIy2dmFbs6kgpTL5SI8PJzatWsTHh5udzhVWpbbzbOLx4ET2kVeznlNC127t1ILyMSXmprK7t27adCgAREREfgqxiqIGWNwu90cPnyYrVu3UrduXWJjY48/oSoXI358myznNsQdx/jeVaOgkVdAJr7k5GQaNGhAtWrV7A5F+YmIEBISQvXq1QkLC2PXrl2a+Gyycd9uftjxLjhhwMl3VZmCRl4BuVGfnZ1NRESZb1ugAlRERASZmZnHb6jKxV3fWQWNKG8rHjq3r93h2CIge3yAbt5WYvrd2ufzlb+zNXse4OTpC6pWQSOvqrnWSlVBWW434xaNQ8TQJvJSujRra3dIttHEp1QV8ciPk8lybkE8cYzv+ZDd4dhKE18FGT169HE38ebOnYuIMHfu3HKLY+rUqbzzzjtFDhcRNm/enDts9OjRzJkzp1BbFXw270tm1o53Aeh/0h3UjoqxOSJ7aeKrIIMHD2bBggV2h1Fs4uvduzcLFiygfv36ucOeeOIJTXyVxJ3fPwXONCK9LXn4vH52h2O7gC1uVDYNGzakYcOGdodRrNq1a1O79nGv36iC0BcrF7Al62fAUaULGnnpJ1BBCm7qpqSkMGDAAGJiYoiLi+PGG2/kwIEDRU77xRdf0KlTJ6pVq0ZcXBx9+/Zl69at+dokJCRw/fXXM23aNFq1akVkZCSJiYnMnz8/t02XLl2YN28ev/32GyKCiNClSxeg8KZuTqxPPfVUbtvRo0fzwgsvEBYWRkpKSr7lG2No1qwZ1157bRk/KeVPbo+HcYueQsTQutqlXNisnd0hBQRNfDa56qqrmDFjBuPGjeOTTz7B5XJx9913F2r31ltvcfXVV9O6dWv+97//MXHiRFasWMEFF1zAoUOH8rX99ddfefHFFxkzZgyffPIJHo+HSy+9NDehTpgwgdNPP5327duzYMECFixYwIQJE4qML2ezfNCgQbltBw8ezM0334zD4eDdd9/N1/6HH35g06ZN3HbbbX74dJS/PPLjFDKdWxBPLK/3qtoFjbyCZlM34eFv7Q4BgM3P9C7zPGbPns38+fP5+OOP6d+/PwDdu3enZ8+eJCUl5bY7fPgww4cP56abbsq3X65jx46ccsopTJkyhaFDh+YOT01N5a+//qJ6deteCfXq1aNDhw7MnDmTAQMG0Lp1a2JiYnC73XTq1OmYMeaMb9CgQaG2/fr1Y9KkSQwbNiy3Zzhx4kRatGiR24NU9tu8L5nvtk8BJ/Rrdgd1o/RMmRza47PBggULcDqdXH11/ssA5STBvO1SU1O57rrrcLvduY+GDRvSsmVLfvkl3/2cOPvss3OTHkC7dtZmTcHN4rK644472LBhAz/99BMAO3fuZPr06drbCzB3fT8ut6Ax4vz+x5+gCgmaHp8/elqBYufOnVSvXp2QkJB8w+vWrZvvfXJyMgBdu3Ytcj55kxxAjRo18r0PCwsDICMjo0zxFnTWWWeRmJjIW2+9RdeuXZk8eTIul4uBAwf6dTnqxH21aiGbs+agBY2iBU3iq0zq16/P/v37yc7Ozpf8du/ena9dzZo1Aavw0KZNm0LziY627+Ty//73v9x2221s376dyZMn07dv30KJV9nD7fEwduE4xGloGaEFjaJo4rPB2Wefjcfj4fPPP8+3eTtt2rR87Tp37kx0dDTr16/3W28qLCysUFGkOKGhoaSnpxc57tprr+XBBx9kwIABbN26ldtvv90v8amyG/nTO2Q6NyGeWMb3Gm53OAFJE58NLrnkEs4991xuu+029uzZw8knn8wnn3zCihX578oZExPD888/z5133klKSgo9e/YkNjaW7du3M2/ePLp06cKAAQNKtezWrVszYcIEPvnkE0466SSio6Np0aJFsW2//fZbevToQfXq1YmPjyc+Ph6wrrAyaNAgXn75Zdq1a0fnzp1P7MNQfrX1QArfJlkFjf80vV0LGsXQDX+bfPHFF/Tq1YsRI0bQr18/3G4348ePL9Tutttu45tvvmHt2rXccMMN9OzZk1GjRuF2uznttNNKvdzhw4dz8cUXM3jwYDp06HDMgsT48eOJjIzksssuo0OHDkyaNCnf+L59++bGqALDnd+NA+cRqnlPYeQFpfunWJWIMabCF5qYmGiWLFlS7PjVq1fTqlXlv7dnsHv00Ud59dVX2bFjBzExpTv3U79j//t61SIe/eNWQHjl3Pfp2rzq3fVVRJYaYxKP1043dVWpLVu2jLVr1/Lqq68yZMiQUic95X9uj4cxC59CnIZTwntVyaRXGpr4VKn16dOH3bt30717d5544gm7w1HA4z9NJdO5CTzRvKEFjePSxKdKLe+lq5T9th5IYXrS2+CEvk3voF509eNPVMVpcUOpIHfXd09rQaOUtMenVBCbvnoxGzN/BBw8ee5IPUOjhPRTUipIuT0enlwwFhFDi4iedD/5dLtDChqa+JQKUo/PmUqGc6MWNE6A3xKfiDhFZJmIzPDXPJVSRdt2YC/Tt00G4OqE27WgUUr+7PHdC6z24/yUUsW467tx4DxMhOdkHu9yvd3hBB2/JD4RaQj0Bib7Y35KqeJ9u3YJGzJnY4yDMec9pgWNE+CvT+wV4CHA66f5VSkVcVvJsti8eTMiwtSpU4/bNiEhgUGDBpV7TFWV2+Nh9G9WQePk8O5a0DhBZT6cRUQuBZKNMUtFpMsx2g0BhgA0bty4rIutVM444wwWLFhA69at7Q6lSPXr12fBggWcdNJJdodS5Y3++X0ynBt8BY2H7Q4naPnjOL5zgMtFpBcQDsSIyP8ZY/LteDDGTAImgXWRAj8st9KIiYk57j0w7BQWFhbQ8VUVSQf38fXWSeCEq5rcRnyMXvj1RJV5U9cYM8IY09AYkwD0B+YUTHoK/v33X/r06UOdOnUIDw+ncePG9O3bF7fbXeSmrsfjYeTIkdSvX59q1apx0UUXsWbNmtzbPObIuW3lmjVr6N69O5GRkTRu3Dj3LmgffPABLVu2JCoqigsvvJANGzbkiys7O5uRI0eSkJBAaGgoCQkJjBw5kuzs7Nw2xW3qvvrqqyQkJBAeHk5iYiK//vqr3z83dZR1hsZhIjzNGXXhDXaHE9T0zI0KcumllxIXF8ebb75JrVq12L59OzNnzsTrLXq36KhRoxg3bhzDhg2ja9eu/Pnnn1x++eXFzr9v377ceuutPPjgg0yYMIGbb76ZdevWMXfuXJ555hmys7O59957GTBgAIsWLcqdbuDAgXz66ac88sgjnHvuuSxYsICxY8eyceNGPvroo2KXl3OHt0GDBtGvXz/Wr1/PtddeW+KrO6vSmbl2KeszZmGdoaEFjbLya+IzxswF5vpznrlGB8iVZEcfLPUke/bsYd26dXz99df5kldxV0/ev38/r7zyCrfffjvPPvssYF21OSQkhAceeKDIaYYNG8aNN94IQGJiItOnT2fixIls2rQp97JRO3fu5N5772XLli00adKEFStW8PHHHzNq1KjcXmS3bt1wOp089thjPPzww7Rv377QsrxeL6NHj6Z79+757q9bu3btQneKU2Xn9XqtgobTcFJYd3qccobdIQU9/bdRAWrWrEmzZs14+OGHefvtt1m3bt0x2y9fvpwjR47kXuE4x3/+859ip+nZs2fu6+rVq1OnTh06deqU71p5LVu2BGDbtm0AubenvP76/Hsmct7PmzevyGUlJSWRlJTENddck2/41VdfjculGxH+9sTPH5DuXA+eKMb3HGF3OJVC8PxKT6CnFShEhNmzZzN69GhGjBjB3r17adq0KcOGDeO///1vofY7d+4EoE6dOvmGF7z9ZF4FbzUZGhpa5DA4ervJffv2AVbVNq969erlG19cfAXjcblcuXeGU/6xI3UfX2yZCE64ovEQGsZqQcMftMdXQZo1a8b7779PSkoKy5Yt46KLLuKOO+7gu+++K9Q2JxHl3Fc3R8HbT5ZVzu0gd+3alW94zvviklhOfAXjcbvd7N27168xVnV3znwGnIeI8JzE6AtvtDucSkMTXwUTEU477TReeuklgEJ3VgNo164dkZGRfPbZZ/mGF3xfVhdccAFQ+LaWH374IQDnn39+kdM1bNiQRo0a8emnn+Yb/vnnn+N2u/0aY1U2a90y1mXMwhhh1DkjcTmddodUaQTPpm4Q++eff7j33nvp168fzZs3x+PxMHXqVFwuFxdddFGhSmj16tUZOnQo48aNIzo6OreqO2XKFAC/VfTatGnDtddey+jRo3G73XTu3JkFCxYwZswYrr322iILGznLHzVqFIMHD+amm26if//+rF+/nqefflrvv+EnXq+Xx34dgzi9NAvtRu8Wx71/jioFTXwVoF69ejRu3JiXXnqJpKQkwsPDadeuHTNmzODMM88s8lS1J554AmMMU6ZM4bXXXqNjx45MnTqVc845h9hY/1W433vvPZo1a8Y777zD2LFjiY+PZ/jw4YwaNeqY091yyy0cPnyYl156iY8//pi2bdsybdq0QoUSdWKenPt/pDvXgSeKN3o9anc4lY7eXjKIfPbZZ1xzzTX88ssvnHfeeXaHUyb6HRdv16H9XPJZb3Ae4vL4+3jqkpvtDilo6O0lg9yiRYv49ttv6dixI+Hh4SxdupRnnnmGTp06ce6559odnipHd858FpyHCPc044mLBtodTqWkiS9ARUVF8csvv/DGG2+QmppKnTp1uOaaa3j66acREbvDU+Vk1rplrE3/DhAeP1sLGuVFE1+AatOmTcBepkqVD6/Xy+PzxyIOq6BxWasOdodUaenhLEoFiLHzPiLN8S94Ihnf8xG7w6nUNPEpFQB2HdrPZ5smAHBZw1tpFKdnwJQnTXxKBYCcgkaYpylPXjzI7nAqPd3Hp5TNZq/7K7egMUoLGhVCe3xK2cjr9TJy/hhEvDQNu5jLWp1ld0hVgiY+pWx0tKBRjTe0oFFhNPEpZZPdhw/y2aY3AejdcDCN42rbHFHVoYkvCAT67SfVibEuOZVKmKcpYy/W09IqkhY3lLLBnA3/sCZtJiCM7PSIFjQqmPb4bJSZmWl3CMoGXq+XR36xChoJoRdxZWu9dWdF08RXQXJuA7lixQq6d+9OVFQU11xzDWlpaQwfPpymTZsSGhpK06ZNeeqpp4q9+1qOhIQEBg0aVGh4wdtPqsDz9C/TOOJYA55qjO+hBQ076KZuBbviiiu45ZZbGD58OF6vl+7du7Nq1Soee+wx2rVrx8KFCxkzZgz79u3jxRdftDtc5We7Dx/kk40TwAk9G9xCQo06x59I+V3QJL5277WzOwQAlg9cXqbp77nnHu69917Autn3/PnzmTdvXu5l3i+++GLAuhDp8OHDC91wSAW3u2c+h3EeJMzThHFdb7E7nCpLN3UrWJ8+fXJff//99zRp0oTOnTvjdrtzH926dSM7O5uFCxfaGKnyt583LmdV2gyMER7p+KgWNGwUND2+sva0AkXeWzkmJyezZcsWQkJCimyrdyyrPLxeLyPmPYk4vDQOuZCr2pxtd0hVWtAkvsoi70VEa9asSdOmTQvdrSxHQkJCsfMJDw8nKysr37Di7oOr7PfMr5/kFjTeuGyk3eFUeZr4bNSjRw8+//xzoqKiaNmyZammbdKkSaFbU86YMcOf4Sk/STmcyrQNb4ATusffpAWNAKCJz0bXXXcd7777LhdffDEPPPAAp556KllZWWzYsIFvvvmGr776imrVqhU5bf/+/bn55pu57777uPTSS/n777+ZOnVqxa6AKpG7vrMKGqGeJozrOtjucBSa+GwVEhLCrFmzeOaZZ5g0aRKbNm0iMjKSk046id69exMaGlrstAMHDmTbtm1MmTKFiRMnct555/Hll1/SvHnzClwDdTxzN65g5ZEZgPBIx0cIdemfXCDQ20sqW1SF79jr9XLOe/057FhNI1cXZl73ut0hVXolvb1kmQ9nEZFwEflDRP4WkZUi8kRZ56lUZfDc/M847FgNngjG99SCRiDxR787E7jIGHNYREKA+SLynTFGD0JTVdbetEN8tG48uKBb/E00q1HX7pBUHmVOfMbaVj7sexvie1T89rNSAeSub5/HuA4Q6mnE011vtTscVYBfztwQEaeI/AUkA7ONMYv8MV+lgtGvm1ax/Mg3AAzvoAWNQOSXxGeM8RhjTgMaAmeJSNuCbURkiIgsEZElKSkp/lisUgHH6/UyfO6TiHho6LqAa9qda3dIqgh+PVfXGHMAmAv0KGLcJGNMojEmsXZtvcS2qpxe/O1zDjlWWgWNHlrQCFT+qOrWFpE43+sIoCuwpqzzVSrY7E07xAf/WoesXFJ/ICfVrGdzRKo4/tj5UB94T0ScWIn0U2OMnjulqpy7Zz6Pce0nxNOIZy65ze5w1DH4o6r7D3C6H2JRKmj9umkV/xz6BnHA8MQRWtAIcHo9PqXKyOv1MnzeGMThoYHzfPq1P8/ukNRxaOKrIF999RUvvfRSuS5j8+bNiAiTJ08u1+Wo/F787QsOyQrwRPC6FjSCgia+ClIRiU9VvP1ph/ng39cAuLj+QE6uVf84U6hAoIlPqTK467sXrIKGuyHPaUEjaGjiqwCDBg3ivffeY/v27YgIIkJCQgIZGRncd999tG3blqioKOrVq8dll13GmjX5jwaaOnUqIsLChQu57rrriImJIT4+nnvuuYeMjIxCy/N4PDz++OPUr1+fuLg4LrvsMpKSkipqdauM37as5u/UrwB4qIMWNIKJflMV4LHHHiMlJYXFixfzzTfWqUxhYWFkZmZy6NAhRo4cSf369dm3bx8TJkygU6dOrFmzhnr18h8HdsMNN3DttdfyxRdfsGDBAkaPHk316tV54on8F8R5+umn6dy5M++88w7Jyck88MADXHfddcybN6/C1rmy83q9PPSzVdCId55H//bn2x2SKoWgSXyrWwbGtdtarVld6mlOOukkateuTWhoKJ06dco3Lm8hwuPx0L17d+rWrcvHH3/Mfffdl6/tgAEDcpNc165dWbRoER9//HGhxNekSRM++uij3PcpKSkMGzaMHTt2EB8fX+r4VWEv//4lqbIcPOGM7/2Y3eGoUtJNXZt9+umndOzYkbi4OFwuF5GRkRw+fJi1a9cWatu7d+9879u1a8fWrVtL1A4osq0qvf1ph3lvrVXQuKieFjSCUdD0+E6kpxXopk+fTr9+/Rg4cCCjRo2iVq1aOBwOevXqVeS+uxo1auR7n7O5XJJ2QJHzVKV393cvYlz7CPE05NlLhtgdjjoBQZP4KqNp06bRvHnzfDcJys7O1ttEBrDft6zhr9QvEQcMO/NhwkOKvy+KCly6qVtBwsLCSE9PzzcsLS0NV4FK4AcffIDH46nI0FQJWQWNJ3MLGteeeoHdIakTpD2+CtK6dWv27dvHm2++SWJiIuHh4fTo0YOvvvoq9xaRS5cu5bXXXiMuLs7ucFURXl3wNQd9BY3XeukZGsFME18FGTx4MAsXLuSRRx7hwIEDNGnShI0bN7Jt2zbeeecdJk6cSIcOHZg+fTp9+vSxO1xVwIH0I7y75hVwQZe6N9CitlbHg5neXlLZIti+4xs+H8Nfhz/F5Y5nwY3Tdd9egKqw20sqVdkt3LqWZalfAPCAFjQqBU18Sh3HsDljEIebeo5zuP60C+0OR/mBJj6ljuGV37/igPwN3nC95FQloolPqWIcSD/Cu6tfAeD82tfRsnZDewNSfqOJT6li3PPdy3hde3G543mx+x12h6P8KGATnx3VZlUxguG7XbR1HX8e/ByA+88YrgWNSiYgE19ISEihsxxU5ZGenp57/nCgevDnJ30Fjc7ccPpFdoej/CwgE1+dOnXYvn07aWlpQdE7UMdnjMk9DzkpKYmaNWvaHVKxXl/wNQf4C+MN47Xuesmpyiggz9yIiYkBYMeOHWRnZ9scjfIXl8tFeHg4jRs3Jjw83O5winQwI43Jq14BF5xf6zpa1dGCRmUUkIkPrOSXkwCVqij3fvcyXtceXO76vNBDCxqVVUBu6iplh8VJ61ly4H8ADD19ONVCAns/pDpxmviU8nngJ6ugUcfRiYFnXGx3OKocaeJTChi/cDr7WWYVNLo9bnc4qpxp4lNV3sGMNN5ead3s/bxaA2hTt5HNEanypolPVXlDv3vFV9Cox4s97rQ7HFUBNPGpKm3p9g0s9hU07jntIS1oVBFlTnwi0khEfhaR1SKyUkTu9UdgSlWE+398EnFkU8fRiZvOvMTucFQF8cdxfG7gAWPMnyISDSwVkdnGmFV+mLdS5ebNP2ayjz8x3jBe1TM0qpQy9/iMMTuNMX/6Xh8CVgMNyjpfpcrTocx03lr+AgDn1OxP23qNbY5IVSS/7uMTkQTgdGBREeOGiMgSEVmSkpLiz8UqVWpDv3sVrysFp7seL3W/2+5wVAXzW+ITkSjgc2CoMSa14HhjzCRjTKIxJrF27dr+WqxSpbZ0+wYW7f8UgHtOHUZkgF8pRvmfXxKfiIRgJb0PjTFf+GOeSpWXB34cgziyqS1ncXNiN7vDUTbwR1VXgCnAamPMS2UPSany8+YfM9nLUow3lFe6aUGjqvJHj+8c4AbgIhH5y/fo5Yf5KuVXeQsaZ9foT/t6CfYGpGxT5sNZjDHzAfFDLEqVq6HfveYraNThlR732B2OspGeuaGqhGU7NrFo/ycA3Nn+IS1oVHGa+FSVcN9s6wyNWtKBWzt0tzscZTNNfKrSm7T4O/ayBOMN5VW95JRCE5+q5I5kZjLhHy1oqPw08alKbej3r+FxJWtBQ+WjiU9VWv/s2syCfdMAuKP9g1rQULk08alKa+gPYxBHFjVJZEiHnnaHowKIJj5VKb29eBYp5g+MN4SXL9GChspPE5+qdI5kZvLGP88D0LF6P06Pb2pzRCrQaOJTlc79s17H49qNw12bV3pqQUMVpolPVSr/7NrMb3s/BuD2dg8SHRZhc0QqEGniU5XK0B/G+goaZ/Lfs/RaGapomvhUpTFlySxSzCJfQWOU3eGoAKaJT1UKRzIzef1v6wyNjtWv0YKGOiZNfKpSeOCH8Xhcu3wFDb3DqTo2TXwq6K3cvY35e6yCxm1t79eChjouTXwq6N3zw5OII5PqnMEdHS+1OxwVBDTxqaD27tLZJHsXYrwuXrpY76GhSkYTnwpaadmZvPbXcwB0iOtLYsPmNkekgoUmPhW0Hvx+Am7XLhzuWrzSc6jd4aggoolPBaWVu7fxy54PARjS5n5iw6vZHJEKJpr4VFC694cxvoLG6dzZ6TK7w1FBRhOfCjrv/fkTu70LMF4XL16sl5xSpaeJTwWVtOxMXllmFTTOjP0PHbSgoU6AJj4VVKyCxg4c7pq81us+u8NRQUoTnwoaq5OTcgsag1vfpwUNdcI08amgcc+ssYgjkzhO4+6zr7A7HBXENPGpoPDBsjns8v6G8bp44UItaKiy0cSnAl5GdhYv/fksAKfHXEXHxifbHJEKdpr4VMB7cNabuQWN13vdb3c4qhLwS+ITkXdEJFlEVvhjfkrlWJOSxLyU/wPgplZDiYuItDkiVRn4q8c3Fejhp3kpleue78eCI4NY056hna+0OxxVSbj8MRNjzC8ikuCPeSmV4//++pmdOQUNm87Q8GZl4T1yxPdIw2Sk403PwJuRjsnMwmRlYbIyMdnZmKxs69njwbizwe3BeDzgcWM8XvB6fM9ejNcDXgPGizHGeu31gjGAwXiN9TrngcmNyeQO94LHYz0bLxiPNdybM8zXBt+z1wDe/PM0BpPbJmcYBd7nLLvAayuYAq8pYnyeYabA+CLHFTesUIMSjivML4mvJERkCDAEoHHjxhW1WBWkMrKzeHHpM+CC02P60KlxC7/N25uVhXvnTrK3byd7xw7cKSlkJyfj2bMXz/79uA/sx3PwIN7UQ5jMTL8tVwWOCkt8xphJwCSAxMTE0qVnVeUM++Et3K4diLsGr/d64ITmYbxesrduJWPVKjJWrSJz3XoyN20iOynJ6l2VhMuFMyoKR7VqOCKrIRHVcISFIi4HDqdBHB7EZCFkW8/edMSbCZ4M67U7HUw2IgYERAABxFivsd4L1rD87/PEIZC3V2PNxwVOFzhc4AwBh9N67XD5XjtBnIVfi+Poe3GCw2HNUBxFPPIMz1mB3PccXaGc4QA4jq6ASJ73edofXSlyP4jceZGvjUiBdvk/lPwf4uCS3V2vwhKfUiW1NmUHc5M/AAfc1LLkBQ1jDFkbNnDk99858scfpC9egufgwcINHQ5C4uMJadCAkPh4XHXqWI9aNXFWr4EzNhqn4whO9z4kLQk5uA0ObIOD2yB1ExzaCV53yVfIEQIRcRAeB+ExEB4LYdG+RwyERkFoJIRFWa9DIiAk0vfse7jCfc9h4Ayz3jv0oIxCNPGpYHX3rDG+gkY77i3BGRrpK1eS+u1MDv/0E1lbtuQb56pdm/A2bQhv3ZqwFi0Ia9aUkCZNcISGQtYRSF4DKb7HnnWwfj3s33T8xFatFkTXh+i6EFUPompDZB2IrAXValrPEdUhooaV1Ar1VpSd/JL4RORjoAtQS0SSgFHGmCn+mLeqWj7+ex47PfMxXifPXfQ4jmJ6NZ7DRzj41Vcc+PxzMlevzh3ujIsj8vzziOzYiWodzyKkQQNrU+lwMuz8G3Z+BX/+DbtXwr5NFLtTPKYBVG8K1ZtAXBOIawxxjazhMfFWz0sFLX9Vda/1x3xU1ZaRncXzS58BJ5wW04fOTVoWauPev59977/P/g8/wpuaCoAzNpaYyy4jpns3Ik4/3dqftusf2Po1LFgMSUvh4NbCC3SEQK1ToE5LqN0Sap0MNU+GGs0gVC+AUJnppq4KGA/9MJFsZ5JV0OiZv6Dhzchg37vvsmfS25j0dAAizjyTGtcNIKrL+ThSlsPmufDhGEhaDNlp+WceGgX1Tz36qNfOSnKu0ApaOxVINPGpgLA2ZQc/734fnDCwxT1UrxaVOy519mySn3mW7O3bAYg8/zxq9b+UatV2wMb34OXBkH0k/wxrngyNO0KjjtAgEWq3sCqZSqGJTwWIe2aNBWcGMaYt93XuA4AnNZVdT44hdcYMAMISGlC3VxMiWQy/fJJ/BrVaQNPzIeFcaHKOVWxQqhia+JTtpv3zCzs8v+YraBz54w92PDQc965dSIiDOmekU73JYmTfYmui8DhofjGcdDE06wKxDexcBRVkNPEpW2W53Ty3+GlwQfvoKzmnQTP2vzySXW9/Dl4Ir5FFfKf9hMV4rEJEi17Qoqe1+erUn686MfrLUbZ6aPZEsl1JhLmjeIud7Orbhv2rQwCo2fIQtbs1Q9rdCa0us6quSvmBJj5lm00b/2D+zrfBCc8kb+Lgh7s4vCMccUK9Gy8gbsjDUD3B7jBVJaSJT1WsrDRY/Q38+QHvHllFZnQU56emc8qc6hzeAc6YKBq++RbVzjzT7khVJaaJT1WMXStg6bvwz2eQeZC/wkL5Mr4e4VmG2+e14Mi2jTirV6fx1HcJb+G/K7EoVRRNfKr8ZKfDii+shJe0OHewO/4MhjqycXgP8OiMOrjWbsRZo4aV9E45xcaAVVWhiU/53571sGQK/PUhZPiujhIWC6f2gzMG8tCyeezd/SaDvw+hxdqdOGNjafLeVMJO1uKFqhia+JR/eNzw73eweDJsnHt0eIMzIfFmaHMVhFZjw95dzN75HpcvNnT7KwMJDaXhhDc06akKpYlPlc3hZFj6nrU5m2qdUoYrAtr9BzoMhvjT8jW/6/unOGv9Ea7/2boQaPxzz2ohQ1U4TXyq9IyBbYvgj7dh1dfgzbaG12xuJbtTr7UuvFnA/5b/hmf3z9wxw0p6dR58gJgeeo8qVfE08amSyzwMyz+FxVNgt+9OouKAFr3hrMHQtEuxVwXOcrt56bexjPrSQ7UsiO7Rgxq33FJhoSuVlyY+dXy7V8KSd+HvaZB1yBpWrRacORDOvMm6QOdxPDL7bQbO3kLjFHAmNKH+2LFH76WgVAXTxKeKlp1ubcYueRe2LTw6vPHZkHgLtL68xFch3rhvNxk/TOL8lQZ3WAjNxo/HGaU3Blf20cSn8tu9Cv58D/7++OihKKHR1qEoZ94E9dqWepajPh7J0J8yAGg4ajRhzZv7M2KlSk0Tn4L0A7Dic1j2f7Djz6PD40+HMwZCu77WHcBOwBf//MaVX/5GtSzIOKcjcX36+CdmpcpAE19V5XHDhjnw90ewZiZ4fDfODou1DkU5c6B1ifYycHs8/P3GQ/RPMhyKCuOMF17W/XoqIGjiq0qMsU4dW/6ZdSpZ2h7fCIGmF8Dp11uXfwqJ8MvinvvgWf7z6z4AGox7Flf16n6Zr1JlpYmvsjMGtv8Jq76ElV9ZN8XOUfNkOLU/tO9XospsaWxK2Umb9z/C5YVN555Br27d/Tp/pcpCE19l5MmGLb/Dmm9hzYyjZ1QARMdD26us/Xb1Ty23G11PG3sHV+7wsD/KxSUvTiiXZSh1ojTxVRaHdlv77NbNgvU/QWbq0XHR8dDqUut82UYdiz3I2F9mzJ1BjzlrrDf3309IbGy5Lk+p0tLEF6yyjsCWBbBprnVRgF3L84+v3RJO6QGtLreqs+Wc7HJku90ceXYU4dmwom0D+g64qUKWq1RpaOILFmn7rMLElt9hy2+wYxl43UfHuyKsWys27wqndIcaTW0Jc/ILD9NlUxqHw4VzX5xkSwxKHY8mvkCUlWadJrbjTyvBJS2GvevztxEHxJ8BzS6wKrKNz4aQcHvi9dmyfTPtP5sJwL9X96JDk2a2xqNUcTTx2cnrhQNbIGUNJK+yzprYtRz2rgPjzd/WFW4lukZnWT27RmdBeGDtO5v1yG2cd8SwPj6C/iOesTscpYqlia+8eT2QusNKcPs3w76NsHeD1YPbux7cGYWnESfUaW0luvjToMEZULcduEIrOvoS+37Gp5zzx1a8ArEPj8bp0p+WClx++XWKSA/gVcAJTDbGVI1/91lpcCTZuhjnoV2+xw4r0R3cbh0zl7rj6PXqihJVD+q0tBJdnVZQrx3UbmX7ZmtppKankvXSUzgM/H72SdzS7XK7Q1LqmMqc+ETECbwBXAIkAYtF5BtjzKqyzrvcGWP1uDIPW5dbyvQ9MlKtE/QzDkLGAUjfbz3S9kH6Pjiyx3pkHynZcqLqQlxj6x6xNU6CGs2gVnPrAOLwmPJcw3JnjGH8mBvosyOL/ZEOej+tBQ0V+PzR4zsLWG+M2QggItOAK4DiE58ny9rk83rBeKzqpLfgs9vqKXk91gG53mzrOfd1lu99FrizrHNN3b6HJxOyM6yk5s6wLrGUnQ7udKuXlnUEsn3PxnPia+4MtZJaZG3rOboexMRDdH2IbQixjSC2gd9OAQtEb/36Khd/9y8AKTfcSud68TZHpNTx+SPxNQDynAdFEtDxWBOs2/8vvb/o5YdFl5LL96gmQKTvIVaFNPeR895pPTscR987nIVf5zoE2YeswsTeil81u1zyv83EpMP6hg247J577A5HqRLxR+Ir6pwnU6iRyBBgCEB4QjhbQ0L8sGh/y6mkesBkW2vhPVb7qi1hl+GSZV48Ipwy5gUcFXSQtFJl5Y/ElwTkPcO9IbCjYCNjzCRgEkD709ub6X2m+2HRyi4et4d/r7odh9nGuvN7c/nZp9kdklIl5o/Etxg4WUSaAtuB/sCAY00Q6gylSUwTPyxa2WX285Nosmsb+yNiuGDcI3aHo1SplDnxGWPcInIXMAvrcJZ3jDEryxyZClj7d6QQ+39W9Tbj1ruJraXX2VPBxS/H8RljZgIz/TEvFfjmP/wEzTOPsLFRK3refszOvVIBSfdGq1JZ+eNvNPtjDtni5KSxT2hBQwUl/dWqEvNkZrF79GgcGNZ3uZyWHdvZHZJSJ0QTnyqxX55+nfp7kkiOqslF4x62OxylTpgmPlUie9dvovpn7wGQcecDxFUP7lPtVNWmiU8dlzGGvx54lDBPNv+06Ei3QVfaHZJSZaKJTx3X6vc+IX7tMg6HRNB+3Ci9N64Kepr41DFl7d5NxsvPA7Dqypto1caeS9or5U+a+FSxjDH8NfRhIjLT+Cu+NVeMuM3ukJTyC018qli7PvuC6GULOewKp9qIx4irFrhXgFaqNDTxqSJlJW0nedw4AGZdOIDLu55qc0RK+Y8mPlWIyc5mw733EZqRxoL6bbjq4SFa0FCViiY+VUjK+PGwcjkpEbHsuu1BWjcIrLu5KVVWeisslc+RBQvYM+ltvAhvnTeIN6840+6QlPI77fGpXNnbt5N0/wOIMXzU8hL63Nib2IhAvFK2UmWjiU8B4D1yhG133Il3/36W1GnB2q7/4eozGtodllLlQjd1FcbrZceIR8hcu5akqNo81+F6Pu7THodDCxqqctIenyLl5Vc49MMPpIdGMLrjTfQ5vyVttaChKjFNfFXc3smT2fv22xiHg6fOvI6Meg154JIWdoelVLnSTd0qbP+0aSS/8CKI8NbZ17O0dkue69mS2Gpa0FCVmya+Kmr/Z5+x64knAVjWZzDfeFtweuM4/qMFDVUFaOKrYowx7J04iZRXXgFAhtzJY3ua4RDDmCvaakFDVQma+KoQ4/Gw+9ln2f/+ByBC3cce47+HEvAk7+OGTk20oKGqDC1uVBHuvXvZOngw+9//AAkJocHLL/Fr6/NZtGkfNSJDebCbFjRU1aGJrwpI+3MZm666mrQFC3HWqEGjyZORLhfz1LerARjeo4UWNFSVopu6lZg3LY2U115n3/vvg9dLxBln0ODllwipW5exM1aRfCiT0xrF0ffMRnaHqlSF0sRXCRljODxvHrvHjCV7+3ZwOKg5+BZq33svEhLCv7sP8e7vmxFBCxqqStLEV8mkLV1K8ssvk75kKQBhLVtSf8wYItq1Bayk+PjXK/B4Ddd1bEy7hlrQUFWPJr5KwLjdHJozh/3/9yFpf/wBgDM2lpq3306N669DQo7uv5v+z04WbtxH9WohDOuuBQ1VNWniC2KZ69Zx8NtvOfjNN7h37ATAUa0aNQYNosbNN+GMisrX/nCmm6e+XQXA8B4t9R4aqsrSxBdETFYWaX8u48hv8zk8dx6Z69bljgtp0pga111PbJ8rcUZHFzn9az+tY3dqJqc2iuOaRC1oqKqrTIlPRPoCo4FWwFnGmCX+CEpZBxtnbdlK5r//krFiOWl//UXGipWYjIzcNo7YWGK6XUJM795UO+ssxFH80Unrdh/infmbfAWNNlrQUFVaWXt8K4CrgIl+iKVKMVlZuPftw71nL+7du8jetYvsHTvI3rqNrK1bydq8GZOZWWi6sJObE3nueUSeew6RHTogocffXDXGMOqblbi9hgEdG9O+YVw5rJFSwaNMic8Ysxoo/R24jMGbmQnGFDv+mMPzjD/60uSfzpjch8k7Xd7hXmNN5/WC12u1y3nt9YLHg/F6MW639drtAY8b43ZjsrOt56ws63VWFt6MDExGJt7MDExaGt60dLzp6XgPH8Z75DCeg6l4UlPxHDyINzX1uB+TK74+4SefQlirlkScdhoRp56Kq3r1405X0LfLd/L7hr3EVQthmJ6hoZQ9+/gyVq5i7amn2bHowOF04qxRHVfNWrjq1iGkXn1C6tcjpFEjQpskENqkcbH76krjSKabsTOsMzQe6t6S6pFa0FDquIlPRH4E6hUx6lFjzNclXZCIDAGGALQODz+6iVZcb/F4w/OMl7zj8k6X817EapPnPSLgEEQcvtcOq+fqcIDTgTiceZ6diNOJuFzWa5cLCQmxnkNDrdehoUh4GI6wcOs5ohqOiAgc1SJwREXjiIrCGR2FMy4OR0wMztjYY+6T85fX5qxjV2oG7RvG0q+DFjSUghIkPmNMV38syBgzCZgEkJiYaFou0TpIeVuffIgpv27KPUPDqQUNpQC9SEGllbeg0b9DI05tFGd3SEoFjDIlPhHpIyJJwNnAtyIyyz9hqbKauXwXv633FTS6t7Q7HKUCSlmrul8CX/opFuUnRzLdjPWdoTGsewtqaEFDqXx0U7cSen3OenYezKBdg1j6d2hsdzhKBRxNfJXMhpTDTJm/0SpoXKkFDaWKoomvEjHGMPqblWR7DP0SG3GaFjSUKpImvkrk+xW7+HXdHmIjQniohxY0lCqOJr5KIi3LzZgZVkHjQS1oKHVMmvgqifFz1rPjYAZtG8Qw4CwtaCh1LJr4KoGNKYd5+9eNADypZ2godVya+IJczhka2R7DNYkNOaNx6a/eolRVo4kvyM1aaRU0YsJdDNeChlIlookviKVneRjju+TUsO4tqBkVZnNESgUHTXxB7I2f17P9QDpt4mMY0LGJ3eEoFTQ08QWpTXuOMOkXLWgodSI08QWhnDM0sjxe/nNmQ85sogUNpUpDE18Q+mHVbub9m0J0uIuHe2pBQ6nS0sQXZNKzPDw53XeGRrcW1NKChlKlpokvyEyYaxU0WtWP4bqOeoaGUidCE18Q2bznCBPnWQWNMVe0weXUr0+pE6F/OUHCGMPo6VZB46ozGpCYUMPukJQKWpr4gsTsVbuZuzaF6DAXI3q2sjscpYKaJr4gkJ7l4QlfQeP+bqdQO1oLGkqVhSa+IPCmr6DRsl40N3TSMzSUKitNfAFuy94jvOU7Q2PMlW21oKGUH+hfUYB7YvoqstxWQaODFjSU8gtNfAHsx1W7mbMmmegwPUNDKX/SxBegMrI9jJ6+EoD7LjmFOtHhNkekVOWhiS9AvTl3A0n7rYLGjWdrQUMpf9LEF4C27k3jzXkbAOuSU1rQUMq/9C8qAD0xfSVZbi99Tm/AWU21oKGUv2niCzA/rd7NT2uSiQpzMUILGkqVC018ASQj++gZGkO7nkydGC1oKFUeypT4ROR5EVkjIv+IyJciEuenuKqkifM2snVfGi3qRjOwc4Ld4ShVaZW1xzcbaGuMaQ/8C4woe0hV07Z9aUyYux6AJ69oQ4gWNJQqN2X66zLG/GCMcfveLgQalj2kqumJ6avIdHu58rR4OjaraXc4SlVq/uxW3Ax858f5VRk/r0nmx9W7iQx1MqKXXnJKqfImxphjNxD5EahXxKhHjTFf+9o8CiQCV5liZigiQ4AhvrdtgRUnGrSNagF77A7iBAVr7MEaNwRv7MEaN0ALY0z08RodN/EddwYiA4HbgYuNMWklnGaJMSaxTAu2QbDGDcEbe7DGDcEbe7DGDSWP3VXGhfQAhgMXlDTpKaWU3cq6j288EA3MFpG/ROQtP8SklFLlqkw9PmNM8xOcdFJZlmujYI0bgjf2YI0bgjf2YI0bShh7mffxKaVUsNGjZJVSVY6tiU9E7haRtSKyUkSeszOW0hKRB0XEiEgtu2MpqWA7xVBEevh+H+tF5GG74ykpEWkkIj+LyGrfb/teu2MqDRFxisgyEZlhdyylISJxIvI/3298tYicXVxb2xKfiFwIXAG0N8a0AV6wK5bSEpFGwCXAVrtjKaWgOcVQRJzAG0BPoDVwrYi0tjeqEnMDDxhjWgGdgDuDKHaAe4HVdgdxAl4FvjfGtARO5RjrYGeP77/AM8aYTABjTLKNsZTWy8BDQFDtIA2yUwzPAtYbYzYaY7KAaVj/KAOeMWanMeZP3+tDWH+ADeyNqmREpCHQG5hsdyylISIxwPnAFABjTJYx5kBx7e1MfKcA54nIIhGZJyIdbIylxETkcmC7MeZvu2Mpo0A/xbABsC3P+ySCJHnkJSIJwOnAIptDKalXsP6pe22Oo7SaASnAu77N9MkiEllc4zIdznI8xzrdzbfs6libAh2AT0WkWXGnvFWk48T9CNCtYiMquVKcYugGPqzI2EpJihhm+2+jNEQkCvgcGGqMSbU7nuMRkUuBZGPMUhHpYnM4peUCzgDuNsYsEpFXgYeBx4prXG6MMV2LGyci/wW+8CW6P0TEi3WOYEp5xlQSxcUtIu2ApsDfIgLWpuKfInKWMWZXBYZYrGN95pB7iuGlWKcYBnIiSQIa5XnfENhhUyylJiIhWEnvQ2PMF3bHU0LnAJeLSC8gHIgRkf8zxlxvc1wlkQQkGWNyetb/w0p8RbJzU/cr4CIAETkFCCXAT4w2xiw3xtQxxiQYYxKwPuwzAiXpHU+eUwwvD4JTDBcDJ4tIUxEJBfoD39gcU4mI9V9xCrDaGPOS3fGUlDFmhDGmoe+33R+YEyRJD9/f4DYRaeEbdDGwqrj25drjO453gHdEZAWQBQwM8B5IZTAeCMM6xRBgoTHmdntDKpoxxi0idwGzACfwjjFmpc1hldQ5wA3AchH5yzfsEWPMTPtCqhLuBj70/aPcCNxUXEM9c0MpVeXomRtKqSpHE59SqsrRxKeUqnI08SmlqhxNfEqpKkcTn1KqytHEp5SqcjTxKaWqnP8HZGH/G1YUyJcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing all activation layers\n",
    "\n",
    "x = np.linspace(-6, 6, 100)\n",
    "units = {\n",
    "    \"identity\": lambda x: x.identity(),\n",
    "    \"sigmoid\": lambda x: x.sigmoid(),\n",
    "    \"relu\": lambda x: x.relu(),\n",
    "    \"tanh\": lambda x: x.tanh()\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "[plt.plot(x, Var_to_nparray(forward(nparray_to_Var(x), [DenseLayer(1, 1, unit, initializer = ConstantInitializer(1.0))]) ), label=unit_name, lw=2) for unit_name, unit in units.items()] # unit(nparray_to_Var(x))), label=unit_name, lw=2) for unit_name, unit in units.items()]\n",
    "plt.legend(loc=2, fontsize=16)\n",
    "plt.title('Our activation functions', fontsize=20)\n",
    "plt.ylim([-2, 5])\n",
    "plt.xlim([-6, 6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-jdEl-7FtGs"
   },
   "source": [
    "# Advanced initialization schemes\n",
    "\n",
    "If we are not careful with initialization, the signals we propagate forward ($a^{(l)}$, $l=1,\\ldots,L$) and backward ($\\delta^l$, $l=L,L-1,\\ldots,1$) can blow up or shrink to zero. A statistical analysis of the variance of the signals for different activation functions can be found in these two papers: [Glorot initialization](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) and [He initialization](https://arxiv.org/pdf/1502.01852v1.pdf). \n",
    "\n",
    "The result of the analyses are proposals for how to make the initialization such that the variance of the signals (forward and backward) are kept approxmimatly constant when propagating from layer to layer. The exact expressions depend upon the non-linear activation function used. In Glorot initialization, the aim is to keep both the forward and backward variances constant whereas He only aims at keeping the variance in the forward pass constant.\n",
    "\n",
    "We define $n_{in}$ and $n_{out}$ as the number of input units and output units of a particular layer. \n",
    "\n",
    "The Glorot initialization has the form: \n",
    "\n",
    "$$w_{ij} \\sim N \\bigg( 0, \\, \\frac{2 \\alpha }{n_{in} + n_{out}} \\bigg) \\ . $$\n",
    "\n",
    "where $N(\\mu,\\sigma^2)$ is a Gaussian distribution with mean $\\mu$ and variance $\\sigma^2$ and $\\alpha$ is a parameter that depends upon the activation function used. For $\\tanh$, $\\alpha=1$ and for Rectified Linear Unit (ReLU) activations, $\\alpha=2$. (It is also possible to use a uniform distribution for initialization, see [this blog post](https://mmuratarat.github.io/2019-02-25/xavier-glorot-he-weight-init).) \n",
    "\n",
    "The He initialization is very similar\n",
    "\n",
    "$$w_{ij} \\sim N \\bigg( 0, \\, \\frac{\\alpha}{n_{in}} \\bigg) \\ . $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqeyab9qFtGs"
   },
   "source": [
    "## Exercise i) Glorot and He initialization\n",
    " \n",
    "Using the Initializer class, implement functions that implement Glorot and He \n",
    "\n",
    "Explain briefly how you would test numerically that these initializations have the sought after property. Hint: See plots in Glorot paper.\n",
    "\n",
    "Comment: If you want to be more advanced then try to make a universal initializer taking both the activation function and type (Glorot or He) as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Qyk01CgaFtGt"
   },
   "outputs": [],
   "source": [
    "## Glorot\n",
    "class DenseLayer_Glorot_tanh(Initializer):\n",
    "    def __init__(self, n_in, n_out, alpha=2):\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "    \n",
    "    def init_weights(self, n_in, n_out, alpha=2):\n",
    "        return [[Var(random.gauss(0, 4/(n_in + n_out))) for _ in range(n_out)] for _ in range(n_in)]\n",
    "    \n",
    "    def init_bias(self, n_out):\n",
    "        return [Var(0.0) for _ in range(n_out)]\n",
    "\n",
    "## He\n",
    "class DenseLayer_Glorot_tanh(Initializer):\n",
    "    def __init__(self, n_in, n_out, alpha=2):\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "    \n",
    "    def init_weights(self, n_in, n_out, alpha=2):\n",
    "        return [[Var(random.gauss(0, 4/(n_in))) for _ in range(n_out)] for _ in range(n_in)]\n",
    "    \n",
    "    def init_bias(self, n_out):\n",
    "        return [Var(0.0) for _ in range(n_out)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XyXBD37FtHk"
   },
   "source": [
    "## Exercise j) Forward pass unit test\n",
    "\n",
    "Write a bit of code to make a unit test that the forward pass works. This can be done by defining a simple network with for example all weights equal to one (using the ConstantInitializer method) and identity activation functions. \n",
    "\n",
    "Hints: Use the [assert](https://www.w3schools.com/python/ref_keyword_assert.asp), the nparray_to_Var and the Var_to_nparray commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "k0miqRUAFtHl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000)], [Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000)], [Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000)], [Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000)], [Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000), Var(v=2.0000, grad=0.0000)]]\n",
      "\n",
      "weights\n",
      "[[Var(v=1.0000, grad=0.0000), Var(v=1.0000, grad=0.0000), Var(v=1.0000, grad=0.0000), Var(v=1.0000, grad=0.0000), Var(v=1.0000, grad=0.0000)]]\n",
      "bias\n",
      "[Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000)]\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "NN = [\n",
    "    DenseLayer(1,5, lambda x: x.identity(), initializer=ConstantInitializer(1.0))\n",
    "]\n",
    "\n",
    "x = np.array([1,1,1,1,1])\n",
    "x_train_ = nparray_to_Var(x)\n",
    "\n",
    "def forward(input, network):\n",
    "\n",
    "    def forward_single(x, network):\n",
    "        for layer in network:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    output = [ forward_single(input[n], network) for n in range(len(input))]\n",
    "    return output\n",
    "\n",
    "print(forward(x_train_, NN))\n",
    "\n",
    "print('')\n",
    "for layer in NN:\n",
    "    layer.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faCxhfFnFtHp"
   },
   "source": [
    "# Loss functions\n",
    "\n",
    "We are only missing a loss function to we need to define a loss function and its derivative with respect to the output of the neural network $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "I2eDYKvAFtHq"
   },
   "outputs": [],
   "source": [
    "def squared_loss(t, y):\n",
    "    # add check that sizes agree\n",
    "    def squared_loss_single(t, y):\n",
    "        Loss = Var(0.0)\n",
    "        for i in range(len(t)): # sum over outputs\n",
    "            Loss += (t[i]-y[i]) ** 2\n",
    "        return Loss\n",
    "\n",
    "    Loss = Var(0.0)\n",
    "    for n in range(len(t)): # sum over training data\n",
    "        Loss += squared_loss_single(t[n],y[n])\n",
    "    return Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrwSJ2UWFtHu"
   },
   "source": [
    "## Exercise k) Implement cross entropy loss\n",
    "\n",
    "Insert code below to implement cross-entropy loss for general dimensionality of $t$. Use a logits formulation:\n",
    "$$\n",
    "\\rm{Loss} = - \\sum_i t_i \\, log \\, p_i \n",
    "$$\n",
    "with $p$ given by the the softmax function in terms of the logits $h$:\n",
    "$$\n",
    "p_i = \\frac{\\exp(h_i)}{\\sum_{i'} \\exp(h_{i'})} .\n",
    "$$\n",
    "Inserting $p$ in the expression for the loss gives\n",
    "$$\n",
    "\\rm{Loss} = - \\sum_i t_i h_i + \\rm{LogSumExp}(h) \\ ,\n",
    "$$\n",
    "where \n",
    "$$\n",
    "\\rm{LogSumExp}(h) = \\log \\sum_i \\exp h_i \\ .\n",
    "$$\n",
    "This is true for $t$ being a one-hot vector. \n",
    "\n",
    "Call the function to convince yourself it works. \n",
    "\n",
    "In practice you want to implement a [numerically stable](https://leimao.github.io/blog/LogSumExp/) version of LogSumExp. But we will not bother about that here.\n",
    "\n",
    "Help: You can add these methods in the Var class:\n",
    "\n",
    "    def exp(self):\n",
    "        return Var(exp(self.v), lambda: [(self, exp(self.v))])\n",
    "    \n",
    "    def log(self):\n",
    "        return Var(log(self.v), lambda: [(self, self.v ** -1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6nMuxyfzFtHv"
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(t, h):\n",
    "     \n",
    "    Loss = Var(0.0)\n",
    "    # Insert code here\n",
    "    return Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fAF5ew4FtHy"
   },
   "source": [
    "# Backward pass\n",
    "\n",
    "Now the magic happens! We get the calculation of the gradients for free. Just do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "iHyfPPI9Qqwu"
   },
   "outputs": [],
   "source": [
    "NN = [\n",
    "    DenseLayer(1, 5, lambda x: x.relu()),\n",
    "    DenseLayer(5, 1, lambda x: x.identity()) # identity\n",
    "]\n",
    "\n",
    "output = forward(x_train, NN)\n",
    "\n",
    "Loss = squared_loss(y_train,output)\n",
    "Loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49biIAYKQ1oG"
   },
   "source": [
    "and the gradients will be calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_rGt1bq_Q7uk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 \n",
      " Weights: [[Var(v=0.0380, grad=20.2474), Var(v=0.0638, grad=20.2474), Var(v=0.1226, grad=20.2474), Var(v=0.1235, grad=20.2474), Var(v=-0.1369, grad=1.8221)]] Biases: [Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000)]\n",
      "Layer 1 \n",
      " Weights: [[Var(v=-0.0954, grad=-98.8722)], [Var(v=-0.0440, grad=0.0000)], [Var(v=-0.0515, grad=0.0000)], [Var(v=-0.1341, grad=0.0000)], [Var(v=-0.1086, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print('Layer', i, '\\n', NN[i]) for i in range(len(NN))] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7d7qK0uFtH9"
   },
   "source": [
    "# Backward pass unit test\n",
    "\n",
    "Above we used finite differences to test that Nanograd is actually doing what it is supposed to do. We can in principle try the same for the neural network. But we will trust that the test above is enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgBi8GOSFtIN"
   },
   "source": [
    "# Training and validation\n",
    "\n",
    "We are ready to train some neural networks!\n",
    "\n",
    "We initialize again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "01ePmzBzRtdh"
   },
   "outputs": [],
   "source": [
    "NN = [\n",
    "    DenseLayer(1, 15, lambda x: x.relu()),\n",
    "    DenseLayer(15, 50, lambda x: x.relu()),\n",
    "    DenseLayer(50, 1, lambda x: x.identity()) # identity\n",
    "]\n",
    "\n",
    "output = forward(x_train, NN)\n",
    "\n",
    "Loss = squared_loss(y_train,output)\n",
    "Loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10iRPiQ1ISHw"
   },
   "source": [
    "and make an update:\n",
    "\n",
    "We introduce a help function parameters to have a handle in all parameters in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "dhAI7eyeznia",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network before update:\n",
      "Layer 0 \n",
      " Weights: [[Var(v=-0.0573, grad=-5.4408), Var(v=-0.0936, grad=-5.4408), Var(v=0.0398, grad=-7.9029), Var(v=0.0755, grad=-7.9029), Var(v=-0.0053, grad=-5.4408), Var(v=0.0539, grad=-7.9029), Var(v=0.1546, grad=-7.9029), Var(v=0.1682, grad=-7.9029), Var(v=-0.0580, grad=-5.4408), Var(v=0.0280, grad=-7.9029), Var(v=0.1328, grad=-7.9029), Var(v=-0.0421, grad=-5.4408), Var(v=0.0863, grad=-7.9029), Var(v=0.0030, grad=-7.9029), Var(v=-0.0573, grad=-5.4408)]] Biases: [Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000)]\n",
      "Layer 1 \n",
      " Weights: [[Var(v=0.0782, grad=10.2816), Var(v=0.0218, grad=10.2816), Var(v=-0.0291, grad=0.0000), Var(v=-0.0274, grad=0.0000), Var(v=0.1296, grad=10.2816), Var(v=0.0380, grad=10.2816), Var(v=0.0541, grad=10.2816), Var(v=0.1570, grad=10.2816), Var(v=0.0610, grad=10.2816), Var(v=0.0469, grad=10.2816), Var(v=0.0698, grad=10.2816), Var(v=-0.0721, grad=0.0000), Var(v=0.0259, grad=10.2816), Var(v=-0.0246, grad=0.0000), Var(v=-0.1104, grad=0.0000), Var(v=0.0681, grad=10.2816), Var(v=0.1958, grad=10.2816), Var(v=0.0564, grad=10.2816), Var(v=-0.0485, grad=0.0000), Var(v=-0.0726, grad=0.0000), Var(v=-0.1896, grad=0.0000), Var(v=-0.0328, grad=0.0000), Var(v=0.0254, grad=10.2816), Var(v=0.0058, grad=10.2816), Var(v=-0.0506, grad=0.0000), Var(v=-0.0135, grad=0.0000), Var(v=0.1725, grad=10.2816), Var(v=-0.0064, grad=0.0000), Var(v=-0.0522, grad=0.0000), Var(v=0.0451, grad=10.2816), Var(v=0.0801, grad=10.2816), Var(v=-0.0168, grad=0.0000), Var(v=0.0358, grad=10.2816), Var(v=0.1023, grad=10.2816), Var(v=-0.1736, grad=0.0000), Var(v=0.0358, grad=10.2816), Var(v=0.0297, grad=10.2816), Var(v=-0.1591, grad=0.0000), Var(v=-0.1195, grad=0.0000), Var(v=0.1455, grad=10.2816), Var(v=-0.0279, grad=0.0000), Var(v=-0.1020, grad=0.0000), Var(v=-0.0050, grad=0.0000), Var(v=-0.0315, grad=0.0000), Var(v=-0.0740, grad=0.0000), Var(v=-0.0217, grad=0.0000), Var(v=0.0008, grad=10.2816), Var(v=-0.0106, grad=0.0000), Var(v=0.1295, grad=10.2816), Var(v=-0.1335, grad=0.0000)], [Var(v=-0.0280, grad=0.0000), Var(v=0.2105, grad=0.0000), Var(v=-0.0859, grad=0.0000), Var(v=0.0430, grad=0.0000), Var(v=0.0422, grad=0.0000), Var(v=-0.0653, grad=0.0000), Var(v=0.1955, grad=0.0000), Var(v=-0.2217, grad=0.0000), Var(v=0.0418, grad=0.0000), Var(v=-0.0536, grad=0.0000), Var(v=-0.2416, grad=0.0000), Var(v=0.1587, grad=0.0000), Var(v=0.2336, grad=0.0000), Var(v=-0.0398, grad=0.0000), Var(v=-0.1858, grad=0.0000), Var(v=-0.0185, grad=0.0000), Var(v=0.0897, grad=0.0000), Var(v=-0.0018, grad=0.0000), Var(v=-0.1277, grad=0.0000), Var(v=0.1195, grad=0.0000), Var(v=0.0419, grad=0.0000), Var(v=0.0276, grad=0.0000), Var(v=0.1041, grad=0.0000), Var(v=-0.0629, grad=0.0000), Var(v=-0.0304, grad=0.0000), Var(v=0.1064, grad=0.0000), Var(v=0.1086, grad=0.0000), Var(v=0.0832, grad=0.0000), Var(v=-0.0126, grad=0.0000), Var(v=-0.1861, grad=0.0000), Var(v=-0.0023, grad=0.0000), Var(v=-0.0177, grad=0.0000), Var(v=-0.0561, grad=0.0000), Var(v=0.0937, grad=0.0000), Var(v=-0.2188, grad=0.0000), Var(v=0.1159, grad=0.0000), Var(v=-0.1135, grad=0.0000), Var(v=0.0454, grad=0.0000), Var(v=0.0124, grad=0.0000), Var(v=-0.1677, grad=0.0000), Var(v=-0.1014, grad=0.0000), Var(v=-0.0596, grad=0.0000), Var(v=0.0626, grad=0.0000), Var(v=-0.1280, grad=0.0000), Var(v=-0.0244, grad=0.0000), Var(v=-0.0416, grad=0.0000), Var(v=-0.0511, grad=0.0000), Var(v=0.0007, grad=0.0000), Var(v=-0.0460, grad=0.0000), Var(v=0.0863, grad=0.0000)], [Var(v=-0.1234, grad=0.0000), Var(v=0.0391, grad=0.0000), Var(v=-0.0708, grad=0.0000), Var(v=0.0640, grad=0.0000), Var(v=-0.0790, grad=0.0000), Var(v=-0.0678, grad=0.0000), Var(v=-0.0249, grad=0.0000), Var(v=-0.0263, grad=0.0000), Var(v=0.0372, grad=0.0000), Var(v=0.0088, grad=0.0000), Var(v=-0.1351, grad=0.0000), Var(v=0.1972, grad=0.0000), Var(v=-0.2591, grad=0.0000), Var(v=0.1303, grad=0.0000), Var(v=0.0125, grad=0.0000), Var(v=0.0038, grad=0.0000), Var(v=0.0370, grad=0.0000), Var(v=0.0444, grad=0.0000), Var(v=0.1684, grad=0.0000), Var(v=0.1105, grad=0.0000), Var(v=-0.0130, grad=0.0000), Var(v=-0.0522, grad=0.0000), Var(v=-0.0012, grad=0.0000), Var(v=-0.1538, grad=0.0000), Var(v=0.0756, grad=0.0000), Var(v=-0.0295, grad=0.0000), Var(v=0.1108, grad=0.0000), Var(v=0.0397, grad=0.0000), Var(v=-0.0524, grad=0.0000), Var(v=0.0212, grad=0.0000), Var(v=0.1012, grad=0.0000), Var(v=0.1443, grad=0.0000), Var(v=-0.0869, grad=0.0000), Var(v=0.0976, grad=0.0000), Var(v=-0.0400, grad=0.0000), Var(v=-0.0760, grad=0.0000), Var(v=0.0280, grad=0.0000), Var(v=0.2216, grad=0.0000), Var(v=0.0014, grad=0.0000), Var(v=-0.0465, grad=0.0000), Var(v=0.0411, grad=0.0000), Var(v=-0.0514, grad=0.0000), Var(v=-0.1270, grad=0.0000), Var(v=-0.0001, grad=0.0000), Var(v=-0.0644, grad=0.0000), Var(v=-0.0402, grad=0.0000), Var(v=-0.1421, grad=0.0000), Var(v=-0.0635, grad=0.0000), Var(v=0.0211, grad=0.0000), Var(v=-0.2321, grad=0.0000)], [Var(v=-0.1263, grad=0.0000), Var(v=0.0390, grad=0.0000), Var(v=0.0105, grad=0.0000), Var(v=0.0497, grad=0.0000), Var(v=-0.1610, grad=0.0000), Var(v=0.0405, grad=0.0000), Var(v=0.0044, grad=0.0000), Var(v=0.0480, grad=0.0000), Var(v=0.0148, grad=0.0000), Var(v=0.0137, grad=0.0000), Var(v=0.0047, grad=0.0000), Var(v=-0.0067, grad=0.0000), Var(v=-0.1823, grad=0.0000), Var(v=0.2593, grad=0.0000), Var(v=-0.0195, grad=0.0000), Var(v=0.0741, grad=0.0000), Var(v=0.0657, grad=0.0000), Var(v=0.0095, grad=0.0000), Var(v=0.0372, grad=0.0000), Var(v=0.0168, grad=0.0000), Var(v=0.1490, grad=0.0000), Var(v=-0.1437, grad=0.0000), Var(v=-0.0081, grad=0.0000), Var(v=0.0234, grad=0.0000), Var(v=-0.0154, grad=0.0000), Var(v=-0.0526, grad=0.0000), Var(v=0.0396, grad=0.0000), Var(v=0.0942, grad=0.0000), Var(v=0.0128, grad=0.0000), Var(v=-0.0047, grad=0.0000), Var(v=0.1060, grad=0.0000), Var(v=0.0077, grad=0.0000), Var(v=0.0165, grad=0.0000), Var(v=-0.1319, grad=0.0000), Var(v=-0.1437, grad=0.0000), Var(v=0.1319, grad=0.0000), Var(v=-0.1410, grad=0.0000), Var(v=-0.1132, grad=0.0000), Var(v=0.1762, grad=0.0000), Var(v=-0.0366, grad=0.0000), Var(v=-0.0398, grad=0.0000), Var(v=0.0944, grad=0.0000), Var(v=-0.1840, grad=0.0000), Var(v=0.0560, grad=0.0000), Var(v=-0.1942, grad=0.0000), Var(v=0.0202, grad=0.0000), Var(v=-0.0145, grad=0.0000), Var(v=0.2416, grad=0.0000), Var(v=0.0360, grad=0.0000), Var(v=-0.0821, grad=0.0000)], [Var(v=-0.1921, grad=0.0000), Var(v=-0.0361, grad=0.0000), Var(v=0.1252, grad=0.0000), Var(v=-0.0746, grad=0.0000), Var(v=0.0977, grad=0.0000), Var(v=-0.1074, grad=0.0000), Var(v=-0.1399, grad=0.0000), Var(v=-0.1213, grad=0.0000), Var(v=0.0831, grad=0.0000), Var(v=-0.0238, grad=0.0000), Var(v=-0.0545, grad=0.0000), Var(v=0.1688, grad=0.0000), Var(v=0.0549, grad=0.0000), Var(v=-0.0537, grad=0.0000), Var(v=-0.0163, grad=0.0000), Var(v=0.1032, grad=0.0000), Var(v=-0.0969, grad=0.0000), Var(v=-0.0906, grad=0.0000), Var(v=0.2441, grad=0.0000), Var(v=-0.0312, grad=0.0000), Var(v=-0.1136, grad=0.0000), Var(v=-0.0619, grad=0.0000), Var(v=0.1180, grad=0.0000), Var(v=0.1648, grad=0.0000), Var(v=-0.1482, grad=0.0000), Var(v=-0.1099, grad=0.0000), Var(v=-0.1822, grad=0.0000), Var(v=0.0968, grad=0.0000), Var(v=0.0612, grad=0.0000), Var(v=-0.0517, grad=0.0000), Var(v=-0.0413, grad=0.0000), Var(v=0.0771, grad=0.0000), Var(v=0.0720, grad=0.0000), Var(v=0.0726, grad=0.0000), Var(v=0.0885, grad=0.0000), Var(v=0.1973, grad=0.0000), Var(v=-0.2039, grad=0.0000), Var(v=-0.0554, grad=0.0000), Var(v=-0.0295, grad=0.0000), Var(v=0.0855, grad=0.0000), Var(v=-0.0072, grad=0.0000), Var(v=-0.0404, grad=0.0000), Var(v=0.0217, grad=0.0000), Var(v=-0.0987, grad=0.0000), Var(v=-0.1306, grad=0.0000), Var(v=0.1043, grad=0.0000), Var(v=0.0395, grad=0.0000), Var(v=0.0036, grad=0.0000), Var(v=0.0618, grad=0.0000), Var(v=0.0945, grad=0.0000)], [Var(v=0.1707, grad=0.0000), Var(v=-0.0952, grad=0.0000), Var(v=-0.0950, grad=0.0000), Var(v=-0.0642, grad=0.0000), Var(v=0.0555, grad=0.0000), Var(v=-0.1315, grad=0.0000), Var(v=-0.0666, grad=0.0000), Var(v=-0.0077, grad=0.0000), Var(v=0.0083, grad=0.0000), Var(v=0.0115, grad=0.0000), Var(v=-0.0024, grad=0.0000), Var(v=-0.0633, grad=0.0000), Var(v=-0.1334, grad=0.0000), Var(v=-0.1212, grad=0.0000), Var(v=-0.0814, grad=0.0000), Var(v=0.0818, grad=0.0000), Var(v=-0.0033, grad=0.0000), Var(v=0.0366, grad=0.0000), Var(v=-0.0900, grad=0.0000), Var(v=0.0813, grad=0.0000), Var(v=-0.1005, grad=0.0000), Var(v=0.0243, grad=0.0000), Var(v=-0.1237, grad=0.0000), Var(v=0.0867, grad=0.0000), Var(v=-0.0524, grad=0.0000), Var(v=-0.0542, grad=0.0000), Var(v=-0.0276, grad=0.0000), Var(v=0.0774, grad=0.0000), Var(v=-0.0206, grad=0.0000), Var(v=-0.0596, grad=0.0000), Var(v=-0.2217, grad=0.0000), Var(v=-0.2644, grad=0.0000), Var(v=-0.2766, grad=0.0000), Var(v=0.0345, grad=0.0000), Var(v=-0.0135, grad=0.0000), Var(v=0.1262, grad=0.0000), Var(v=-0.0134, grad=0.0000), Var(v=0.1211, grad=0.0000), Var(v=0.0604, grad=0.0000), Var(v=-0.0682, grad=0.0000), Var(v=-0.0536, grad=0.0000), Var(v=-0.0372, grad=0.0000), Var(v=0.0115, grad=0.0000), Var(v=-0.0629, grad=0.0000), Var(v=-0.0311, grad=0.0000), Var(v=0.0743, grad=0.0000), Var(v=0.0931, grad=0.0000), Var(v=-0.0277, grad=0.0000), Var(v=-0.0917, grad=0.0000), Var(v=-0.0528, grad=0.0000)], [Var(v=0.1527, grad=0.0000), Var(v=-0.0612, grad=0.0000), Var(v=0.0922, grad=0.0000), Var(v=0.0444, grad=0.0000), Var(v=-0.0105, grad=0.0000), Var(v=-0.0556, grad=0.0000), Var(v=0.1595, grad=0.0000), Var(v=-0.0364, grad=0.0000), Var(v=-0.0790, grad=0.0000), Var(v=0.0633, grad=0.0000), Var(v=-0.1215, grad=0.0000), Var(v=0.0727, grad=0.0000), Var(v=0.1648, grad=0.0000), Var(v=0.0497, grad=0.0000), Var(v=0.0359, grad=0.0000), Var(v=0.0261, grad=0.0000), Var(v=0.0181, grad=0.0000), Var(v=0.2016, grad=0.0000), Var(v=0.0620, grad=0.0000), Var(v=-0.1190, grad=0.0000), Var(v=-0.0106, grad=0.0000), Var(v=0.0612, grad=0.0000), Var(v=0.0493, grad=0.0000), Var(v=0.1004, grad=0.0000), Var(v=-0.1772, grad=0.0000), Var(v=-0.0642, grad=0.0000), Var(v=0.0892, grad=0.0000), Var(v=-0.0499, grad=0.0000), Var(v=-0.0623, grad=0.0000), Var(v=0.0486, grad=0.0000), Var(v=-0.0678, grad=0.0000), Var(v=-0.0225, grad=0.0000), Var(v=0.1001, grad=0.0000), Var(v=0.1421, grad=0.0000), Var(v=0.0077, grad=0.0000), Var(v=0.2333, grad=0.0000), Var(v=-0.0094, grad=0.0000), Var(v=0.0324, grad=0.0000), Var(v=0.0076, grad=0.0000), Var(v=-0.1168, grad=0.0000), Var(v=-0.0268, grad=0.0000), Var(v=-0.0179, grad=0.0000), Var(v=0.0654, grad=0.0000), Var(v=-0.0238, grad=0.0000), Var(v=-0.0545, grad=0.0000), Var(v=-0.2191, grad=0.0000), Var(v=-0.0245, grad=0.0000), Var(v=-0.1259, grad=0.0000), Var(v=-0.0152, grad=0.0000), Var(v=-0.0569, grad=0.0000)], [Var(v=-0.0512, grad=0.0000), Var(v=-0.0893, grad=0.0000), Var(v=-0.0207, grad=0.0000), Var(v=-0.0790, grad=0.0000), Var(v=0.0782, grad=0.0000), Var(v=0.1015, grad=0.0000), Var(v=-0.0659, grad=0.0000), Var(v=0.0516, grad=0.0000), Var(v=0.0279, grad=0.0000), Var(v=-0.0012, grad=0.0000), Var(v=0.0502, grad=0.0000), Var(v=-0.1403, grad=0.0000), Var(v=0.1502, grad=0.0000), Var(v=0.0259, grad=0.0000), Var(v=0.1220, grad=0.0000), Var(v=0.0195, grad=0.0000), Var(v=-0.0167, grad=0.0000), Var(v=-0.0776, grad=0.0000), Var(v=-0.1297, grad=0.0000), Var(v=-0.1277, grad=0.0000), Var(v=0.0880, grad=0.0000), Var(v=-0.1370, grad=0.0000), Var(v=0.0573, grad=0.0000), Var(v=0.0829, grad=0.0000), Var(v=0.0076, grad=0.0000), Var(v=0.0427, grad=0.0000), Var(v=0.0613, grad=0.0000), Var(v=-0.0037, grad=0.0000), Var(v=-0.0918, grad=0.0000), Var(v=0.0025, grad=0.0000), Var(v=-0.1247, grad=0.0000), Var(v=-0.0955, grad=0.0000), Var(v=-0.0429, grad=0.0000), Var(v=-0.1164, grad=0.0000), Var(v=-0.0365, grad=0.0000), Var(v=0.1153, grad=0.0000), Var(v=0.1101, grad=0.0000), Var(v=0.0612, grad=0.0000), Var(v=0.0382, grad=0.0000), Var(v=0.0961, grad=0.0000), Var(v=0.1367, grad=0.0000), Var(v=0.0654, grad=0.0000), Var(v=0.1085, grad=0.0000), Var(v=-0.0914, grad=0.0000), Var(v=-0.0651, grad=0.0000), Var(v=0.0268, grad=0.0000), Var(v=0.0979, grad=0.0000), Var(v=0.0602, grad=0.0000), Var(v=-0.0958, grad=0.0000), Var(v=-0.0524, grad=0.0000)], [Var(v=-0.0589, grad=0.0000), Var(v=-0.0074, grad=0.0000), Var(v=0.0087, grad=0.0000), Var(v=-0.0031, grad=0.0000), Var(v=0.2136, grad=0.0000), Var(v=0.0850, grad=0.0000), Var(v=0.2095, grad=0.0000), Var(v=-0.0947, grad=0.0000), Var(v=0.0288, grad=0.0000), Var(v=-0.1088, grad=0.0000), Var(v=0.0823, grad=0.0000), Var(v=0.0523, grad=0.0000), Var(v=0.1317, grad=0.0000), Var(v=0.0202, grad=0.0000), Var(v=0.0362, grad=0.0000), Var(v=-0.0930, grad=0.0000), Var(v=0.0817, grad=0.0000), Var(v=0.0589, grad=0.0000), Var(v=-0.0431, grad=0.0000), Var(v=0.0461, grad=0.0000), Var(v=-0.1277, grad=0.0000), Var(v=0.0435, grad=0.0000), Var(v=-0.1575, grad=0.0000), Var(v=-0.2250, grad=0.0000), Var(v=0.0297, grad=0.0000), Var(v=0.0463, grad=0.0000), Var(v=-0.0246, grad=0.0000), Var(v=-0.0257, grad=0.0000), Var(v=0.1145, grad=0.0000), Var(v=0.0564, grad=0.0000), Var(v=0.2071, grad=0.0000), Var(v=0.0278, grad=0.0000), Var(v=-0.1397, grad=0.0000), Var(v=0.0109, grad=0.0000), Var(v=0.0270, grad=0.0000), Var(v=0.0655, grad=0.0000), Var(v=-0.2040, grad=0.0000), Var(v=-0.2655, grad=0.0000), Var(v=-0.1302, grad=0.0000), Var(v=-0.0100, grad=0.0000), Var(v=0.2206, grad=0.0000), Var(v=-0.0583, grad=0.0000), Var(v=-0.0226, grad=0.0000), Var(v=-0.0811, grad=0.0000), Var(v=0.1847, grad=0.0000), Var(v=-0.0464, grad=0.0000), Var(v=0.0678, grad=0.0000), Var(v=0.1650, grad=0.0000), Var(v=-0.0605, grad=0.0000), Var(v=0.2224, grad=0.0000)], [Var(v=-0.1238, grad=0.0000), Var(v=-0.1092, grad=0.0000), Var(v=-0.0995, grad=0.0000), Var(v=-0.1001, grad=0.0000), Var(v=-0.0025, grad=0.0000), Var(v=-0.0045, grad=0.0000), Var(v=-0.0705, grad=0.0000), Var(v=0.0076, grad=0.0000), Var(v=0.1164, grad=0.0000), Var(v=-0.0768, grad=0.0000), Var(v=-0.1270, grad=0.0000), Var(v=0.0869, grad=0.0000), Var(v=-0.0131, grad=0.0000), Var(v=0.1023, grad=0.0000), Var(v=0.0709, grad=0.0000), Var(v=-0.0274, grad=0.0000), Var(v=-0.0734, grad=0.0000), Var(v=0.1952, grad=0.0000), Var(v=0.0545, grad=0.0000), Var(v=0.0978, grad=0.0000), Var(v=0.0771, grad=0.0000), Var(v=-0.0807, grad=0.0000), Var(v=0.1207, grad=0.0000), Var(v=-0.1439, grad=0.0000), Var(v=-0.1163, grad=0.0000), Var(v=-0.0352, grad=0.0000), Var(v=-0.0738, grad=0.0000), Var(v=0.1126, grad=0.0000), Var(v=0.2074, grad=0.0000), Var(v=0.0735, grad=0.0000), Var(v=-0.0320, grad=0.0000), Var(v=0.0752, grad=0.0000), Var(v=-0.0363, grad=0.0000), Var(v=0.2110, grad=0.0000), Var(v=-0.1189, grad=0.0000), Var(v=0.1353, grad=0.0000), Var(v=0.0193, grad=0.0000), Var(v=-0.0073, grad=0.0000), Var(v=0.0169, grad=0.0000), Var(v=0.0901, grad=0.0000), Var(v=0.0113, grad=0.0000), Var(v=-0.0341, grad=0.0000), Var(v=-0.0431, grad=0.0000), Var(v=0.1733, grad=0.0000), Var(v=0.1296, grad=0.0000), Var(v=0.0770, grad=0.0000), Var(v=0.1533, grad=0.0000), Var(v=-0.0533, grad=0.0000), Var(v=-0.0862, grad=0.0000), Var(v=0.0035, grad=0.0000)], [Var(v=0.0218, grad=0.0000), Var(v=-0.0258, grad=0.0000), Var(v=0.0421, grad=0.0000), Var(v=-0.1501, grad=0.0000), Var(v=-0.0437, grad=0.0000), Var(v=-0.2342, grad=0.0000), Var(v=0.0226, grad=0.0000), Var(v=-0.0068, grad=0.0000), Var(v=0.0764, grad=0.0000), Var(v=0.1958, grad=0.0000), Var(v=-0.1297, grad=0.0000), Var(v=-0.0348, grad=0.0000), Var(v=-0.1576, grad=0.0000), Var(v=0.0286, grad=0.0000), Var(v=0.2357, grad=0.0000), Var(v=0.0293, grad=0.0000), Var(v=-0.0522, grad=0.0000), Var(v=0.1109, grad=0.0000), Var(v=-0.0907, grad=0.0000), Var(v=0.0033, grad=0.0000), Var(v=0.0678, grad=0.0000), Var(v=-0.0270, grad=0.0000), Var(v=-0.0059, grad=0.0000), Var(v=0.1597, grad=0.0000), Var(v=0.0523, grad=0.0000), Var(v=-0.0065, grad=0.0000), Var(v=0.0887, grad=0.0000), Var(v=0.0540, grad=0.0000), Var(v=0.0137, grad=0.0000), Var(v=-0.0089, grad=0.0000), Var(v=-0.1937, grad=0.0000), Var(v=-0.0363, grad=0.0000), Var(v=-0.0823, grad=0.0000), Var(v=0.0186, grad=0.0000), Var(v=0.0166, grad=0.0000), Var(v=-0.1328, grad=0.0000), Var(v=0.0895, grad=0.0000), Var(v=0.1123, grad=0.0000), Var(v=0.0087, grad=0.0000), Var(v=0.0007, grad=0.0000), Var(v=0.0457, grad=0.0000), Var(v=0.1148, grad=0.0000), Var(v=0.0541, grad=0.0000), Var(v=-0.0846, grad=0.0000), Var(v=-0.0259, grad=0.0000), Var(v=-0.2476, grad=0.0000), Var(v=0.1373, grad=0.0000), Var(v=0.0616, grad=0.0000), Var(v=-0.0364, grad=0.0000), Var(v=-0.0124, grad=0.0000)], [Var(v=-0.1167, grad=0.0000), Var(v=0.1104, grad=0.0000), Var(v=0.0760, grad=0.0000), Var(v=-0.0472, grad=0.0000), Var(v=0.1253, grad=0.0000), Var(v=-0.0775, grad=0.0000), Var(v=-0.1530, grad=0.0000), Var(v=0.1607, grad=0.0000), Var(v=0.0034, grad=0.0000), Var(v=0.0309, grad=0.0000), Var(v=-0.0004, grad=0.0000), Var(v=0.0447, grad=0.0000), Var(v=-0.1836, grad=0.0000), Var(v=0.0397, grad=0.0000), Var(v=-0.1679, grad=0.0000), Var(v=-0.0306, grad=0.0000), Var(v=-0.2528, grad=0.0000), Var(v=-0.0375, grad=0.0000), Var(v=0.0042, grad=0.0000), Var(v=-0.0296, grad=0.0000), Var(v=-0.1130, grad=0.0000), Var(v=0.1394, grad=0.0000), Var(v=0.0151, grad=0.0000), Var(v=-0.0859, grad=0.0000), Var(v=-0.0079, grad=0.0000), Var(v=-0.0298, grad=0.0000), Var(v=-0.0586, grad=0.0000), Var(v=-0.0864, grad=0.0000), Var(v=-0.1322, grad=0.0000), Var(v=0.0560, grad=0.0000), Var(v=0.2181, grad=0.0000), Var(v=-0.1245, grad=0.0000), Var(v=-0.0503, grad=0.0000), Var(v=0.0973, grad=0.0000), Var(v=-0.0205, grad=0.0000), Var(v=-0.0408, grad=0.0000), Var(v=-0.0243, grad=0.0000), Var(v=-0.0810, grad=0.0000), Var(v=-0.0675, grad=0.0000), Var(v=-0.1168, grad=0.0000), Var(v=0.1607, grad=0.0000), Var(v=-0.1004, grad=0.0000), Var(v=0.1823, grad=0.0000), Var(v=-0.1037, grad=0.0000), Var(v=0.0464, grad=0.0000), Var(v=-0.0925, grad=0.0000), Var(v=-0.0491, grad=0.0000), Var(v=-0.0733, grad=0.0000), Var(v=0.1706, grad=0.0000), Var(v=0.0177, grad=0.0000)], [Var(v=0.0772, grad=0.0000), Var(v=-0.0610, grad=0.0000), Var(v=-0.0034, grad=0.0000), Var(v=-0.0003, grad=0.0000), Var(v=0.0462, grad=0.0000), Var(v=-0.1706, grad=0.0000), Var(v=0.1417, grad=0.0000), Var(v=0.0084, grad=0.0000), Var(v=0.0556, grad=0.0000), Var(v=0.0377, grad=0.0000), Var(v=-0.0778, grad=0.0000), Var(v=-0.0300, grad=0.0000), Var(v=0.0844, grad=0.0000), Var(v=0.1490, grad=0.0000), Var(v=-0.1141, grad=0.0000), Var(v=0.0846, grad=0.0000), Var(v=-0.2961, grad=0.0000), Var(v=-0.0043, grad=0.0000), Var(v=0.0729, grad=0.0000), Var(v=0.0067, grad=0.0000), Var(v=0.0331, grad=0.0000), Var(v=0.0744, grad=0.0000), Var(v=-0.1516, grad=0.0000), Var(v=-0.1232, grad=0.0000), Var(v=-0.0074, grad=0.0000), Var(v=0.0710, grad=0.0000), Var(v=0.1022, grad=0.0000), Var(v=0.1010, grad=0.0000), Var(v=-0.1167, grad=0.0000), Var(v=0.0646, grad=0.0000), Var(v=-0.0215, grad=0.0000), Var(v=-0.0746, grad=0.0000), Var(v=-0.0193, grad=0.0000), Var(v=-0.0948, grad=0.0000), Var(v=0.1224, grad=0.0000), Var(v=0.0187, grad=0.0000), Var(v=0.0316, grad=0.0000), Var(v=-0.0773, grad=0.0000), Var(v=-0.1863, grad=0.0000), Var(v=0.0829, grad=0.0000), Var(v=0.0976, grad=0.0000), Var(v=-0.1383, grad=0.0000), Var(v=0.0271, grad=0.0000), Var(v=-0.0461, grad=0.0000), Var(v=0.0759, grad=0.0000), Var(v=0.2165, grad=0.0000), Var(v=-0.0304, grad=0.0000), Var(v=0.2026, grad=0.0000), Var(v=-0.1363, grad=0.0000), Var(v=-0.0016, grad=0.0000)], [Var(v=0.0231, grad=0.0000), Var(v=0.0764, grad=0.0000), Var(v=-0.1507, grad=0.0000), Var(v=0.0889, grad=0.0000), Var(v=0.0263, grad=0.0000), Var(v=0.0337, grad=0.0000), Var(v=-0.0444, grad=0.0000), Var(v=-0.0104, grad=0.0000), Var(v=0.0041, grad=0.0000), Var(v=-0.0393, grad=0.0000), Var(v=0.1272, grad=0.0000), Var(v=-0.0889, grad=0.0000), Var(v=0.0472, grad=0.0000), Var(v=-0.0917, grad=0.0000), Var(v=0.0477, grad=0.0000), Var(v=-0.0070, grad=0.0000), Var(v=0.1879, grad=0.0000), Var(v=-0.0746, grad=0.0000), Var(v=0.2687, grad=0.0000), Var(v=0.1036, grad=0.0000), Var(v=0.0842, grad=0.0000), Var(v=0.0313, grad=0.0000), Var(v=-0.0864, grad=0.0000), Var(v=-0.0687, grad=0.0000), Var(v=0.1095, grad=0.0000), Var(v=-0.0185, grad=0.0000), Var(v=-0.0951, grad=0.0000), Var(v=0.0087, grad=0.0000), Var(v=-0.0026, grad=0.0000), Var(v=-0.1955, grad=0.0000), Var(v=-0.0966, grad=0.0000), Var(v=-0.0604, grad=0.0000), Var(v=-0.0084, grad=0.0000), Var(v=-0.0295, grad=0.0000), Var(v=0.1506, grad=0.0000), Var(v=-0.0607, grad=0.0000), Var(v=0.0571, grad=0.0000), Var(v=-0.0186, grad=0.0000), Var(v=0.0934, grad=0.0000), Var(v=-0.0804, grad=0.0000), Var(v=-0.1147, grad=0.0000), Var(v=0.0567, grad=0.0000), Var(v=-0.0167, grad=0.0000), Var(v=-0.0150, grad=0.0000), Var(v=-0.0706, grad=0.0000), Var(v=-0.1013, grad=0.0000), Var(v=-0.3237, grad=0.0000), Var(v=-0.0763, grad=0.0000), Var(v=0.0660, grad=0.0000), Var(v=0.1843, grad=0.0000)], [Var(v=-0.0498, grad=0.0000), Var(v=-0.1291, grad=0.0000), Var(v=0.1743, grad=0.0000), Var(v=0.0605, grad=0.0000), Var(v=-0.0081, grad=0.0000), Var(v=0.0517, grad=0.0000), Var(v=0.0600, grad=0.0000), Var(v=-0.0349, grad=0.0000), Var(v=0.0254, grad=0.0000), Var(v=0.0421, grad=0.0000), Var(v=-0.0929, grad=0.0000), Var(v=-0.1511, grad=0.0000), Var(v=0.1010, grad=0.0000), Var(v=-0.0361, grad=0.0000), Var(v=-0.0317, grad=0.0000), Var(v=-0.0381, grad=0.0000), Var(v=-0.0196, grad=0.0000), Var(v=-0.0047, grad=0.0000), Var(v=-0.0043, grad=0.0000), Var(v=0.1461, grad=0.0000), Var(v=-0.0893, grad=0.0000), Var(v=-0.0392, grad=0.0000), Var(v=-0.0409, grad=0.0000), Var(v=-0.0886, grad=0.0000), Var(v=-0.0370, grad=0.0000), Var(v=0.1508, grad=0.0000), Var(v=-0.0677, grad=0.0000), Var(v=0.0811, grad=0.0000), Var(v=0.1225, grad=0.0000), Var(v=0.0890, grad=0.0000), Var(v=0.0464, grad=0.0000), Var(v=0.0804, grad=0.0000), Var(v=-0.1003, grad=0.0000), Var(v=-0.1679, grad=0.0000), Var(v=0.0205, grad=0.0000), Var(v=-0.1377, grad=0.0000), Var(v=0.1281, grad=0.0000), Var(v=0.1255, grad=0.0000), Var(v=0.0708, grad=0.0000), Var(v=-0.0031, grad=0.0000), Var(v=0.1143, grad=0.0000), Var(v=0.1305, grad=0.0000), Var(v=0.0019, grad=0.0000), Var(v=-0.0215, grad=0.0000), Var(v=0.0711, grad=0.0000), Var(v=0.0271, grad=0.0000), Var(v=-0.0496, grad=0.0000), Var(v=0.0012, grad=0.0000), Var(v=0.0693, grad=0.0000), Var(v=-0.0236, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000)]\n",
      "Layer 2 \n",
      " Weights: [[Var(v=0.1183, grad=263.7151)], [Var(v=-0.1759, grad=0.0000)], [Var(v=0.0386, grad=0.0000)], [Var(v=-0.0449, grad=0.0000)], [Var(v=0.1252, grad=0.0000)], [Var(v=-0.0706, grad=0.0000)], [Var(v=-0.0168, grad=0.0000)], [Var(v=0.1058, grad=0.0000)], [Var(v=0.0956, grad=0.0000)], [Var(v=-0.0060, grad=0.0000)], [Var(v=0.0394, grad=0.0000)], [Var(v=0.1752, grad=0.0000)], [Var(v=-0.0471, grad=0.0000)], [Var(v=-0.0009, grad=0.0000)], [Var(v=0.0536, grad=0.0000)], [Var(v=-0.0759, grad=0.0000)], [Var(v=-0.0576, grad=0.0000)], [Var(v=0.0152, grad=0.0000)], [Var(v=0.2578, grad=0.0000)], [Var(v=-0.1890, grad=0.0000)], [Var(v=-0.0878, grad=0.0000)], [Var(v=-0.0294, grad=0.0000)], [Var(v=-0.0827, grad=0.0000)], [Var(v=0.0570, grad=0.0000)], [Var(v=0.0825, grad=0.0000)], [Var(v=-0.0061, grad=0.0000)], [Var(v=0.0036, grad=0.0000)], [Var(v=-0.0514, grad=0.0000)], [Var(v=0.0917, grad=0.0000)], [Var(v=0.0736, grad=0.0000)], [Var(v=-0.0659, grad=0.0000)], [Var(v=-0.0808, grad=0.0000)], [Var(v=-0.0094, grad=0.0000)], [Var(v=0.0755, grad=0.0000)], [Var(v=-0.0131, grad=0.0000)], [Var(v=-0.1725, grad=0.0000)], [Var(v=0.0217, grad=0.0000)], [Var(v=-0.1217, grad=0.0000)], [Var(v=-0.0068, grad=0.0000)], [Var(v=-0.0257, grad=0.0000)], [Var(v=-0.0815, grad=0.0000)], [Var(v=-0.0661, grad=0.0000)], [Var(v=-0.1933, grad=0.0000)], [Var(v=0.0058, grad=0.0000)], [Var(v=0.0469, grad=0.0000)], [Var(v=0.0188, grad=0.0000)], [Var(v=0.0890, grad=0.0000)], [Var(v=0.1812, grad=0.0000)], [Var(v=-0.0928, grad=0.0000)], [Var(v=0.0197, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000)]\n",
      "\n",
      "Network after update:\n",
      "Layer 0 \n",
      " Weights: [[Var(v=-0.0029, grad=-5.4408), Var(v=-0.0392, grad=-5.4408), Var(v=0.1189, grad=-7.9029), Var(v=0.1545, grad=-7.9029), Var(v=0.0491, grad=-5.4408), Var(v=0.1329, grad=-7.9029), Var(v=0.2336, grad=-7.9029), Var(v=0.2472, grad=-7.9029), Var(v=-0.0036, grad=-5.4408), Var(v=0.1070, grad=-7.9029), Var(v=0.2119, grad=-7.9029), Var(v=0.0123, grad=-5.4408), Var(v=0.1654, grad=-7.9029), Var(v=0.0820, grad=-7.9029), Var(v=-0.0029, grad=-5.4408)]] Biases: [Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000)]\n",
      "Layer 1 \n",
      " Weights: [[Var(v=-0.0246, grad=10.2816), Var(v=-0.0810, grad=10.2816), Var(v=-0.0291, grad=0.0000), Var(v=-0.0274, grad=0.0000), Var(v=0.0268, grad=10.2816), Var(v=-0.0648, grad=10.2816), Var(v=-0.0487, grad=10.2816), Var(v=0.0542, grad=10.2816), Var(v=-0.0418, grad=10.2816), Var(v=-0.0559, grad=10.2816), Var(v=-0.0330, grad=10.2816), Var(v=-0.0721, grad=0.0000), Var(v=-0.0769, grad=10.2816), Var(v=-0.0246, grad=0.0000), Var(v=-0.1104, grad=0.0000), Var(v=-0.0347, grad=10.2816), Var(v=0.0930, grad=10.2816), Var(v=-0.0465, grad=10.2816), Var(v=-0.0485, grad=0.0000), Var(v=-0.0726, grad=0.0000), Var(v=-0.1896, grad=0.0000), Var(v=-0.0328, grad=0.0000), Var(v=-0.0775, grad=10.2816), Var(v=-0.0970, grad=10.2816), Var(v=-0.0506, grad=0.0000), Var(v=-0.0135, grad=0.0000), Var(v=0.0697, grad=10.2816), Var(v=-0.0064, grad=0.0000), Var(v=-0.0522, grad=0.0000), Var(v=-0.0577, grad=10.2816), Var(v=-0.0227, grad=10.2816), Var(v=-0.0168, grad=0.0000), Var(v=-0.0670, grad=10.2816), Var(v=-0.0005, grad=10.2816), Var(v=-0.1736, grad=0.0000), Var(v=-0.0670, grad=10.2816), Var(v=-0.0731, grad=10.2816), Var(v=-0.1591, grad=0.0000), Var(v=-0.1195, grad=0.0000), Var(v=0.0427, grad=10.2816), Var(v=-0.0279, grad=0.0000), Var(v=-0.1020, grad=0.0000), Var(v=-0.0050, grad=0.0000), Var(v=-0.0315, grad=0.0000), Var(v=-0.0740, grad=0.0000), Var(v=-0.0217, grad=0.0000), Var(v=-0.1020, grad=10.2816), Var(v=-0.0106, grad=0.0000), Var(v=0.0267, grad=10.2816), Var(v=-0.1335, grad=0.0000)], [Var(v=-0.0280, grad=0.0000), Var(v=0.2105, grad=0.0000), Var(v=-0.0859, grad=0.0000), Var(v=0.0430, grad=0.0000), Var(v=0.0422, grad=0.0000), Var(v=-0.0653, grad=0.0000), Var(v=0.1955, grad=0.0000), Var(v=-0.2217, grad=0.0000), Var(v=0.0418, grad=0.0000), Var(v=-0.0536, grad=0.0000), Var(v=-0.2416, grad=0.0000), Var(v=0.1587, grad=0.0000), Var(v=0.2336, grad=0.0000), Var(v=-0.0398, grad=0.0000), Var(v=-0.1858, grad=0.0000), Var(v=-0.0185, grad=0.0000), Var(v=0.0897, grad=0.0000), Var(v=-0.0018, grad=0.0000), Var(v=-0.1277, grad=0.0000), Var(v=0.1195, grad=0.0000), Var(v=0.0419, grad=0.0000), Var(v=0.0276, grad=0.0000), Var(v=0.1041, grad=0.0000), Var(v=-0.0629, grad=0.0000), Var(v=-0.0304, grad=0.0000), Var(v=0.1064, grad=0.0000), Var(v=0.1086, grad=0.0000), Var(v=0.0832, grad=0.0000), Var(v=-0.0126, grad=0.0000), Var(v=-0.1861, grad=0.0000), Var(v=-0.0023, grad=0.0000), Var(v=-0.0177, grad=0.0000), Var(v=-0.0561, grad=0.0000), Var(v=0.0937, grad=0.0000), Var(v=-0.2188, grad=0.0000), Var(v=0.1159, grad=0.0000), Var(v=-0.1135, grad=0.0000), Var(v=0.0454, grad=0.0000), Var(v=0.0124, grad=0.0000), Var(v=-0.1677, grad=0.0000), Var(v=-0.1014, grad=0.0000), Var(v=-0.0596, grad=0.0000), Var(v=0.0626, grad=0.0000), Var(v=-0.1280, grad=0.0000), Var(v=-0.0244, grad=0.0000), Var(v=-0.0416, grad=0.0000), Var(v=-0.0511, grad=0.0000), Var(v=0.0007, grad=0.0000), Var(v=-0.0460, grad=0.0000), Var(v=0.0863, grad=0.0000)], [Var(v=-0.1234, grad=0.0000), Var(v=0.0391, grad=0.0000), Var(v=-0.0708, grad=0.0000), Var(v=0.0640, grad=0.0000), Var(v=-0.0790, grad=0.0000), Var(v=-0.0678, grad=0.0000), Var(v=-0.0249, grad=0.0000), Var(v=-0.0263, grad=0.0000), Var(v=0.0372, grad=0.0000), Var(v=0.0088, grad=0.0000), Var(v=-0.1351, grad=0.0000), Var(v=0.1972, grad=0.0000), Var(v=-0.2591, grad=0.0000), Var(v=0.1303, grad=0.0000), Var(v=0.0125, grad=0.0000), Var(v=0.0038, grad=0.0000), Var(v=0.0370, grad=0.0000), Var(v=0.0444, grad=0.0000), Var(v=0.1684, grad=0.0000), Var(v=0.1105, grad=0.0000), Var(v=-0.0130, grad=0.0000), Var(v=-0.0522, grad=0.0000), Var(v=-0.0012, grad=0.0000), Var(v=-0.1538, grad=0.0000), Var(v=0.0756, grad=0.0000), Var(v=-0.0295, grad=0.0000), Var(v=0.1108, grad=0.0000), Var(v=0.0397, grad=0.0000), Var(v=-0.0524, grad=0.0000), Var(v=0.0212, grad=0.0000), Var(v=0.1012, grad=0.0000), Var(v=0.1443, grad=0.0000), Var(v=-0.0869, grad=0.0000), Var(v=0.0976, grad=0.0000), Var(v=-0.0400, grad=0.0000), Var(v=-0.0760, grad=0.0000), Var(v=0.0280, grad=0.0000), Var(v=0.2216, grad=0.0000), Var(v=0.0014, grad=0.0000), Var(v=-0.0465, grad=0.0000), Var(v=0.0411, grad=0.0000), Var(v=-0.0514, grad=0.0000), Var(v=-0.1270, grad=0.0000), Var(v=-0.0001, grad=0.0000), Var(v=-0.0644, grad=0.0000), Var(v=-0.0402, grad=0.0000), Var(v=-0.1421, grad=0.0000), Var(v=-0.0635, grad=0.0000), Var(v=0.0211, grad=0.0000), Var(v=-0.2321, grad=0.0000)], [Var(v=-0.1263, grad=0.0000), Var(v=0.0390, grad=0.0000), Var(v=0.0105, grad=0.0000), Var(v=0.0497, grad=0.0000), Var(v=-0.1610, grad=0.0000), Var(v=0.0405, grad=0.0000), Var(v=0.0044, grad=0.0000), Var(v=0.0480, grad=0.0000), Var(v=0.0148, grad=0.0000), Var(v=0.0137, grad=0.0000), Var(v=0.0047, grad=0.0000), Var(v=-0.0067, grad=0.0000), Var(v=-0.1823, grad=0.0000), Var(v=0.2593, grad=0.0000), Var(v=-0.0195, grad=0.0000), Var(v=0.0741, grad=0.0000), Var(v=0.0657, grad=0.0000), Var(v=0.0095, grad=0.0000), Var(v=0.0372, grad=0.0000), Var(v=0.0168, grad=0.0000), Var(v=0.1490, grad=0.0000), Var(v=-0.1437, grad=0.0000), Var(v=-0.0081, grad=0.0000), Var(v=0.0234, grad=0.0000), Var(v=-0.0154, grad=0.0000), Var(v=-0.0526, grad=0.0000), Var(v=0.0396, grad=0.0000), Var(v=0.0942, grad=0.0000), Var(v=0.0128, grad=0.0000), Var(v=-0.0047, grad=0.0000), Var(v=0.1060, grad=0.0000), Var(v=0.0077, grad=0.0000), Var(v=0.0165, grad=0.0000), Var(v=-0.1319, grad=0.0000), Var(v=-0.1437, grad=0.0000), Var(v=0.1319, grad=0.0000), Var(v=-0.1410, grad=0.0000), Var(v=-0.1132, grad=0.0000), Var(v=0.1762, grad=0.0000), Var(v=-0.0366, grad=0.0000), Var(v=-0.0398, grad=0.0000), Var(v=0.0944, grad=0.0000), Var(v=-0.1840, grad=0.0000), Var(v=0.0560, grad=0.0000), Var(v=-0.1942, grad=0.0000), Var(v=0.0202, grad=0.0000), Var(v=-0.0145, grad=0.0000), Var(v=0.2416, grad=0.0000), Var(v=0.0360, grad=0.0000), Var(v=-0.0821, grad=0.0000)], [Var(v=-0.1921, grad=0.0000), Var(v=-0.0361, grad=0.0000), Var(v=0.1252, grad=0.0000), Var(v=-0.0746, grad=0.0000), Var(v=0.0977, grad=0.0000), Var(v=-0.1074, grad=0.0000), Var(v=-0.1399, grad=0.0000), Var(v=-0.1213, grad=0.0000), Var(v=0.0831, grad=0.0000), Var(v=-0.0238, grad=0.0000), Var(v=-0.0545, grad=0.0000), Var(v=0.1688, grad=0.0000), Var(v=0.0549, grad=0.0000), Var(v=-0.0537, grad=0.0000), Var(v=-0.0163, grad=0.0000), Var(v=0.1032, grad=0.0000), Var(v=-0.0969, grad=0.0000), Var(v=-0.0906, grad=0.0000), Var(v=0.2441, grad=0.0000), Var(v=-0.0312, grad=0.0000), Var(v=-0.1136, grad=0.0000), Var(v=-0.0619, grad=0.0000), Var(v=0.1180, grad=0.0000), Var(v=0.1648, grad=0.0000), Var(v=-0.1482, grad=0.0000), Var(v=-0.1099, grad=0.0000), Var(v=-0.1822, grad=0.0000), Var(v=0.0968, grad=0.0000), Var(v=0.0612, grad=0.0000), Var(v=-0.0517, grad=0.0000), Var(v=-0.0413, grad=0.0000), Var(v=0.0771, grad=0.0000), Var(v=0.0720, grad=0.0000), Var(v=0.0726, grad=0.0000), Var(v=0.0885, grad=0.0000), Var(v=0.1973, grad=0.0000), Var(v=-0.2039, grad=0.0000), Var(v=-0.0554, grad=0.0000), Var(v=-0.0295, grad=0.0000), Var(v=0.0855, grad=0.0000), Var(v=-0.0072, grad=0.0000), Var(v=-0.0404, grad=0.0000), Var(v=0.0217, grad=0.0000), Var(v=-0.0987, grad=0.0000), Var(v=-0.1306, grad=0.0000), Var(v=0.1043, grad=0.0000), Var(v=0.0395, grad=0.0000), Var(v=0.0036, grad=0.0000), Var(v=0.0618, grad=0.0000), Var(v=0.0945, grad=0.0000)], [Var(v=0.1707, grad=0.0000), Var(v=-0.0952, grad=0.0000), Var(v=-0.0950, grad=0.0000), Var(v=-0.0642, grad=0.0000), Var(v=0.0555, grad=0.0000), Var(v=-0.1315, grad=0.0000), Var(v=-0.0666, grad=0.0000), Var(v=-0.0077, grad=0.0000), Var(v=0.0083, grad=0.0000), Var(v=0.0115, grad=0.0000), Var(v=-0.0024, grad=0.0000), Var(v=-0.0633, grad=0.0000), Var(v=-0.1334, grad=0.0000), Var(v=-0.1212, grad=0.0000), Var(v=-0.0814, grad=0.0000), Var(v=0.0818, grad=0.0000), Var(v=-0.0033, grad=0.0000), Var(v=0.0366, grad=0.0000), Var(v=-0.0900, grad=0.0000), Var(v=0.0813, grad=0.0000), Var(v=-0.1005, grad=0.0000), Var(v=0.0243, grad=0.0000), Var(v=-0.1237, grad=0.0000), Var(v=0.0867, grad=0.0000), Var(v=-0.0524, grad=0.0000), Var(v=-0.0542, grad=0.0000), Var(v=-0.0276, grad=0.0000), Var(v=0.0774, grad=0.0000), Var(v=-0.0206, grad=0.0000), Var(v=-0.0596, grad=0.0000), Var(v=-0.2217, grad=0.0000), Var(v=-0.2644, grad=0.0000), Var(v=-0.2766, grad=0.0000), Var(v=0.0345, grad=0.0000), Var(v=-0.0135, grad=0.0000), Var(v=0.1262, grad=0.0000), Var(v=-0.0134, grad=0.0000), Var(v=0.1211, grad=0.0000), Var(v=0.0604, grad=0.0000), Var(v=-0.0682, grad=0.0000), Var(v=-0.0536, grad=0.0000), Var(v=-0.0372, grad=0.0000), Var(v=0.0115, grad=0.0000), Var(v=-0.0629, grad=0.0000), Var(v=-0.0311, grad=0.0000), Var(v=0.0743, grad=0.0000), Var(v=0.0931, grad=0.0000), Var(v=-0.0277, grad=0.0000), Var(v=-0.0917, grad=0.0000), Var(v=-0.0528, grad=0.0000)], [Var(v=0.1527, grad=0.0000), Var(v=-0.0612, grad=0.0000), Var(v=0.0922, grad=0.0000), Var(v=0.0444, grad=0.0000), Var(v=-0.0105, grad=0.0000), Var(v=-0.0556, grad=0.0000), Var(v=0.1595, grad=0.0000), Var(v=-0.0364, grad=0.0000), Var(v=-0.0790, grad=0.0000), Var(v=0.0633, grad=0.0000), Var(v=-0.1215, grad=0.0000), Var(v=0.0727, grad=0.0000), Var(v=0.1648, grad=0.0000), Var(v=0.0497, grad=0.0000), Var(v=0.0359, grad=0.0000), Var(v=0.0261, grad=0.0000), Var(v=0.0181, grad=0.0000), Var(v=0.2016, grad=0.0000), Var(v=0.0620, grad=0.0000), Var(v=-0.1190, grad=0.0000), Var(v=-0.0106, grad=0.0000), Var(v=0.0612, grad=0.0000), Var(v=0.0493, grad=0.0000), Var(v=0.1004, grad=0.0000), Var(v=-0.1772, grad=0.0000), Var(v=-0.0642, grad=0.0000), Var(v=0.0892, grad=0.0000), Var(v=-0.0499, grad=0.0000), Var(v=-0.0623, grad=0.0000), Var(v=0.0486, grad=0.0000), Var(v=-0.0678, grad=0.0000), Var(v=-0.0225, grad=0.0000), Var(v=0.1001, grad=0.0000), Var(v=0.1421, grad=0.0000), Var(v=0.0077, grad=0.0000), Var(v=0.2333, grad=0.0000), Var(v=-0.0094, grad=0.0000), Var(v=0.0324, grad=0.0000), Var(v=0.0076, grad=0.0000), Var(v=-0.1168, grad=0.0000), Var(v=-0.0268, grad=0.0000), Var(v=-0.0179, grad=0.0000), Var(v=0.0654, grad=0.0000), Var(v=-0.0238, grad=0.0000), Var(v=-0.0545, grad=0.0000), Var(v=-0.2191, grad=0.0000), Var(v=-0.0245, grad=0.0000), Var(v=-0.1259, grad=0.0000), Var(v=-0.0152, grad=0.0000), Var(v=-0.0569, grad=0.0000)], [Var(v=-0.0512, grad=0.0000), Var(v=-0.0893, grad=0.0000), Var(v=-0.0207, grad=0.0000), Var(v=-0.0790, grad=0.0000), Var(v=0.0782, grad=0.0000), Var(v=0.1015, grad=0.0000), Var(v=-0.0659, grad=0.0000), Var(v=0.0516, grad=0.0000), Var(v=0.0279, grad=0.0000), Var(v=-0.0012, grad=0.0000), Var(v=0.0502, grad=0.0000), Var(v=-0.1403, grad=0.0000), Var(v=0.1502, grad=0.0000), Var(v=0.0259, grad=0.0000), Var(v=0.1220, grad=0.0000), Var(v=0.0195, grad=0.0000), Var(v=-0.0167, grad=0.0000), Var(v=-0.0776, grad=0.0000), Var(v=-0.1297, grad=0.0000), Var(v=-0.1277, grad=0.0000), Var(v=0.0880, grad=0.0000), Var(v=-0.1370, grad=0.0000), Var(v=0.0573, grad=0.0000), Var(v=0.0829, grad=0.0000), Var(v=0.0076, grad=0.0000), Var(v=0.0427, grad=0.0000), Var(v=0.0613, grad=0.0000), Var(v=-0.0037, grad=0.0000), Var(v=-0.0918, grad=0.0000), Var(v=0.0025, grad=0.0000), Var(v=-0.1247, grad=0.0000), Var(v=-0.0955, grad=0.0000), Var(v=-0.0429, grad=0.0000), Var(v=-0.1164, grad=0.0000), Var(v=-0.0365, grad=0.0000), Var(v=0.1153, grad=0.0000), Var(v=0.1101, grad=0.0000), Var(v=0.0612, grad=0.0000), Var(v=0.0382, grad=0.0000), Var(v=0.0961, grad=0.0000), Var(v=0.1367, grad=0.0000), Var(v=0.0654, grad=0.0000), Var(v=0.1085, grad=0.0000), Var(v=-0.0914, grad=0.0000), Var(v=-0.0651, grad=0.0000), Var(v=0.0268, grad=0.0000), Var(v=0.0979, grad=0.0000), Var(v=0.0602, grad=0.0000), Var(v=-0.0958, grad=0.0000), Var(v=-0.0524, grad=0.0000)], [Var(v=-0.0589, grad=0.0000), Var(v=-0.0074, grad=0.0000), Var(v=0.0087, grad=0.0000), Var(v=-0.0031, grad=0.0000), Var(v=0.2136, grad=0.0000), Var(v=0.0850, grad=0.0000), Var(v=0.2095, grad=0.0000), Var(v=-0.0947, grad=0.0000), Var(v=0.0288, grad=0.0000), Var(v=-0.1088, grad=0.0000), Var(v=0.0823, grad=0.0000), Var(v=0.0523, grad=0.0000), Var(v=0.1317, grad=0.0000), Var(v=0.0202, grad=0.0000), Var(v=0.0362, grad=0.0000), Var(v=-0.0930, grad=0.0000), Var(v=0.0817, grad=0.0000), Var(v=0.0589, grad=0.0000), Var(v=-0.0431, grad=0.0000), Var(v=0.0461, grad=0.0000), Var(v=-0.1277, grad=0.0000), Var(v=0.0435, grad=0.0000), Var(v=-0.1575, grad=0.0000), Var(v=-0.2250, grad=0.0000), Var(v=0.0297, grad=0.0000), Var(v=0.0463, grad=0.0000), Var(v=-0.0246, grad=0.0000), Var(v=-0.0257, grad=0.0000), Var(v=0.1145, grad=0.0000), Var(v=0.0564, grad=0.0000), Var(v=0.2071, grad=0.0000), Var(v=0.0278, grad=0.0000), Var(v=-0.1397, grad=0.0000), Var(v=0.0109, grad=0.0000), Var(v=0.0270, grad=0.0000), Var(v=0.0655, grad=0.0000), Var(v=-0.2040, grad=0.0000), Var(v=-0.2655, grad=0.0000), Var(v=-0.1302, grad=0.0000), Var(v=-0.0100, grad=0.0000), Var(v=0.2206, grad=0.0000), Var(v=-0.0583, grad=0.0000), Var(v=-0.0226, grad=0.0000), Var(v=-0.0811, grad=0.0000), Var(v=0.1847, grad=0.0000), Var(v=-0.0464, grad=0.0000), Var(v=0.0678, grad=0.0000), Var(v=0.1650, grad=0.0000), Var(v=-0.0605, grad=0.0000), Var(v=0.2224, grad=0.0000)], [Var(v=-0.1238, grad=0.0000), Var(v=-0.1092, grad=0.0000), Var(v=-0.0995, grad=0.0000), Var(v=-0.1001, grad=0.0000), Var(v=-0.0025, grad=0.0000), Var(v=-0.0045, grad=0.0000), Var(v=-0.0705, grad=0.0000), Var(v=0.0076, grad=0.0000), Var(v=0.1164, grad=0.0000), Var(v=-0.0768, grad=0.0000), Var(v=-0.1270, grad=0.0000), Var(v=0.0869, grad=0.0000), Var(v=-0.0131, grad=0.0000), Var(v=0.1023, grad=0.0000), Var(v=0.0709, grad=0.0000), Var(v=-0.0274, grad=0.0000), Var(v=-0.0734, grad=0.0000), Var(v=0.1952, grad=0.0000), Var(v=0.0545, grad=0.0000), Var(v=0.0978, grad=0.0000), Var(v=0.0771, grad=0.0000), Var(v=-0.0807, grad=0.0000), Var(v=0.1207, grad=0.0000), Var(v=-0.1439, grad=0.0000), Var(v=-0.1163, grad=0.0000), Var(v=-0.0352, grad=0.0000), Var(v=-0.0738, grad=0.0000), Var(v=0.1126, grad=0.0000), Var(v=0.2074, grad=0.0000), Var(v=0.0735, grad=0.0000), Var(v=-0.0320, grad=0.0000), Var(v=0.0752, grad=0.0000), Var(v=-0.0363, grad=0.0000), Var(v=0.2110, grad=0.0000), Var(v=-0.1189, grad=0.0000), Var(v=0.1353, grad=0.0000), Var(v=0.0193, grad=0.0000), Var(v=-0.0073, grad=0.0000), Var(v=0.0169, grad=0.0000), Var(v=0.0901, grad=0.0000), Var(v=0.0113, grad=0.0000), Var(v=-0.0341, grad=0.0000), Var(v=-0.0431, grad=0.0000), Var(v=0.1733, grad=0.0000), Var(v=0.1296, grad=0.0000), Var(v=0.0770, grad=0.0000), Var(v=0.1533, grad=0.0000), Var(v=-0.0533, grad=0.0000), Var(v=-0.0862, grad=0.0000), Var(v=0.0035, grad=0.0000)], [Var(v=0.0218, grad=0.0000), Var(v=-0.0258, grad=0.0000), Var(v=0.0421, grad=0.0000), Var(v=-0.1501, grad=0.0000), Var(v=-0.0437, grad=0.0000), Var(v=-0.2342, grad=0.0000), Var(v=0.0226, grad=0.0000), Var(v=-0.0068, grad=0.0000), Var(v=0.0764, grad=0.0000), Var(v=0.1958, grad=0.0000), Var(v=-0.1297, grad=0.0000), Var(v=-0.0348, grad=0.0000), Var(v=-0.1576, grad=0.0000), Var(v=0.0286, grad=0.0000), Var(v=0.2357, grad=0.0000), Var(v=0.0293, grad=0.0000), Var(v=-0.0522, grad=0.0000), Var(v=0.1109, grad=0.0000), Var(v=-0.0907, grad=0.0000), Var(v=0.0033, grad=0.0000), Var(v=0.0678, grad=0.0000), Var(v=-0.0270, grad=0.0000), Var(v=-0.0059, grad=0.0000), Var(v=0.1597, grad=0.0000), Var(v=0.0523, grad=0.0000), Var(v=-0.0065, grad=0.0000), Var(v=0.0887, grad=0.0000), Var(v=0.0540, grad=0.0000), Var(v=0.0137, grad=0.0000), Var(v=-0.0089, grad=0.0000), Var(v=-0.1937, grad=0.0000), Var(v=-0.0363, grad=0.0000), Var(v=-0.0823, grad=0.0000), Var(v=0.0186, grad=0.0000), Var(v=0.0166, grad=0.0000), Var(v=-0.1328, grad=0.0000), Var(v=0.0895, grad=0.0000), Var(v=0.1123, grad=0.0000), Var(v=0.0087, grad=0.0000), Var(v=0.0007, grad=0.0000), Var(v=0.0457, grad=0.0000), Var(v=0.1148, grad=0.0000), Var(v=0.0541, grad=0.0000), Var(v=-0.0846, grad=0.0000), Var(v=-0.0259, grad=0.0000), Var(v=-0.2476, grad=0.0000), Var(v=0.1373, grad=0.0000), Var(v=0.0616, grad=0.0000), Var(v=-0.0364, grad=0.0000), Var(v=-0.0124, grad=0.0000)], [Var(v=-0.1167, grad=0.0000), Var(v=0.1104, grad=0.0000), Var(v=0.0760, grad=0.0000), Var(v=-0.0472, grad=0.0000), Var(v=0.1253, grad=0.0000), Var(v=-0.0775, grad=0.0000), Var(v=-0.1530, grad=0.0000), Var(v=0.1607, grad=0.0000), Var(v=0.0034, grad=0.0000), Var(v=0.0309, grad=0.0000), Var(v=-0.0004, grad=0.0000), Var(v=0.0447, grad=0.0000), Var(v=-0.1836, grad=0.0000), Var(v=0.0397, grad=0.0000), Var(v=-0.1679, grad=0.0000), Var(v=-0.0306, grad=0.0000), Var(v=-0.2528, grad=0.0000), Var(v=-0.0375, grad=0.0000), Var(v=0.0042, grad=0.0000), Var(v=-0.0296, grad=0.0000), Var(v=-0.1130, grad=0.0000), Var(v=0.1394, grad=0.0000), Var(v=0.0151, grad=0.0000), Var(v=-0.0859, grad=0.0000), Var(v=-0.0079, grad=0.0000), Var(v=-0.0298, grad=0.0000), Var(v=-0.0586, grad=0.0000), Var(v=-0.0864, grad=0.0000), Var(v=-0.1322, grad=0.0000), Var(v=0.0560, grad=0.0000), Var(v=0.2181, grad=0.0000), Var(v=-0.1245, grad=0.0000), Var(v=-0.0503, grad=0.0000), Var(v=0.0973, grad=0.0000), Var(v=-0.0205, grad=0.0000), Var(v=-0.0408, grad=0.0000), Var(v=-0.0243, grad=0.0000), Var(v=-0.0810, grad=0.0000), Var(v=-0.0675, grad=0.0000), Var(v=-0.1168, grad=0.0000), Var(v=0.1607, grad=0.0000), Var(v=-0.1004, grad=0.0000), Var(v=0.1823, grad=0.0000), Var(v=-0.1037, grad=0.0000), Var(v=0.0464, grad=0.0000), Var(v=-0.0925, grad=0.0000), Var(v=-0.0491, grad=0.0000), Var(v=-0.0733, grad=0.0000), Var(v=0.1706, grad=0.0000), Var(v=0.0177, grad=0.0000)], [Var(v=0.0772, grad=0.0000), Var(v=-0.0610, grad=0.0000), Var(v=-0.0034, grad=0.0000), Var(v=-0.0003, grad=0.0000), Var(v=0.0462, grad=0.0000), Var(v=-0.1706, grad=0.0000), Var(v=0.1417, grad=0.0000), Var(v=0.0084, grad=0.0000), Var(v=0.0556, grad=0.0000), Var(v=0.0377, grad=0.0000), Var(v=-0.0778, grad=0.0000), Var(v=-0.0300, grad=0.0000), Var(v=0.0844, grad=0.0000), Var(v=0.1490, grad=0.0000), Var(v=-0.1141, grad=0.0000), Var(v=0.0846, grad=0.0000), Var(v=-0.2961, grad=0.0000), Var(v=-0.0043, grad=0.0000), Var(v=0.0729, grad=0.0000), Var(v=0.0067, grad=0.0000), Var(v=0.0331, grad=0.0000), Var(v=0.0744, grad=0.0000), Var(v=-0.1516, grad=0.0000), Var(v=-0.1232, grad=0.0000), Var(v=-0.0074, grad=0.0000), Var(v=0.0710, grad=0.0000), Var(v=0.1022, grad=0.0000), Var(v=0.1010, grad=0.0000), Var(v=-0.1167, grad=0.0000), Var(v=0.0646, grad=0.0000), Var(v=-0.0215, grad=0.0000), Var(v=-0.0746, grad=0.0000), Var(v=-0.0193, grad=0.0000), Var(v=-0.0948, grad=0.0000), Var(v=0.1224, grad=0.0000), Var(v=0.0187, grad=0.0000), Var(v=0.0316, grad=0.0000), Var(v=-0.0773, grad=0.0000), Var(v=-0.1863, grad=0.0000), Var(v=0.0829, grad=0.0000), Var(v=0.0976, grad=0.0000), Var(v=-0.1383, grad=0.0000), Var(v=0.0271, grad=0.0000), Var(v=-0.0461, grad=0.0000), Var(v=0.0759, grad=0.0000), Var(v=0.2165, grad=0.0000), Var(v=-0.0304, grad=0.0000), Var(v=0.2026, grad=0.0000), Var(v=-0.1363, grad=0.0000), Var(v=-0.0016, grad=0.0000)], [Var(v=0.0231, grad=0.0000), Var(v=0.0764, grad=0.0000), Var(v=-0.1507, grad=0.0000), Var(v=0.0889, grad=0.0000), Var(v=0.0263, grad=0.0000), Var(v=0.0337, grad=0.0000), Var(v=-0.0444, grad=0.0000), Var(v=-0.0104, grad=0.0000), Var(v=0.0041, grad=0.0000), Var(v=-0.0393, grad=0.0000), Var(v=0.1272, grad=0.0000), Var(v=-0.0889, grad=0.0000), Var(v=0.0472, grad=0.0000), Var(v=-0.0917, grad=0.0000), Var(v=0.0477, grad=0.0000), Var(v=-0.0070, grad=0.0000), Var(v=0.1879, grad=0.0000), Var(v=-0.0746, grad=0.0000), Var(v=0.2687, grad=0.0000), Var(v=0.1036, grad=0.0000), Var(v=0.0842, grad=0.0000), Var(v=0.0313, grad=0.0000), Var(v=-0.0864, grad=0.0000), Var(v=-0.0687, grad=0.0000), Var(v=0.1095, grad=0.0000), Var(v=-0.0185, grad=0.0000), Var(v=-0.0951, grad=0.0000), Var(v=0.0087, grad=0.0000), Var(v=-0.0026, grad=0.0000), Var(v=-0.1955, grad=0.0000), Var(v=-0.0966, grad=0.0000), Var(v=-0.0604, grad=0.0000), Var(v=-0.0084, grad=0.0000), Var(v=-0.0295, grad=0.0000), Var(v=0.1506, grad=0.0000), Var(v=-0.0607, grad=0.0000), Var(v=0.0571, grad=0.0000), Var(v=-0.0186, grad=0.0000), Var(v=0.0934, grad=0.0000), Var(v=-0.0804, grad=0.0000), Var(v=-0.1147, grad=0.0000), Var(v=0.0567, grad=0.0000), Var(v=-0.0167, grad=0.0000), Var(v=-0.0150, grad=0.0000), Var(v=-0.0706, grad=0.0000), Var(v=-0.1013, grad=0.0000), Var(v=-0.3237, grad=0.0000), Var(v=-0.0763, grad=0.0000), Var(v=0.0660, grad=0.0000), Var(v=0.1843, grad=0.0000)], [Var(v=-0.0498, grad=0.0000), Var(v=-0.1291, grad=0.0000), Var(v=0.1743, grad=0.0000), Var(v=0.0605, grad=0.0000), Var(v=-0.0081, grad=0.0000), Var(v=0.0517, grad=0.0000), Var(v=0.0600, grad=0.0000), Var(v=-0.0349, grad=0.0000), Var(v=0.0254, grad=0.0000), Var(v=0.0421, grad=0.0000), Var(v=-0.0929, grad=0.0000), Var(v=-0.1511, grad=0.0000), Var(v=0.1010, grad=0.0000), Var(v=-0.0361, grad=0.0000), Var(v=-0.0317, grad=0.0000), Var(v=-0.0381, grad=0.0000), Var(v=-0.0196, grad=0.0000), Var(v=-0.0047, grad=0.0000), Var(v=-0.0043, grad=0.0000), Var(v=0.1461, grad=0.0000), Var(v=-0.0893, grad=0.0000), Var(v=-0.0392, grad=0.0000), Var(v=-0.0409, grad=0.0000), Var(v=-0.0886, grad=0.0000), Var(v=-0.0370, grad=0.0000), Var(v=0.1508, grad=0.0000), Var(v=-0.0677, grad=0.0000), Var(v=0.0811, grad=0.0000), Var(v=0.1225, grad=0.0000), Var(v=0.0890, grad=0.0000), Var(v=0.0464, grad=0.0000), Var(v=0.0804, grad=0.0000), Var(v=-0.1003, grad=0.0000), Var(v=-0.1679, grad=0.0000), Var(v=0.0205, grad=0.0000), Var(v=-0.1377, grad=0.0000), Var(v=0.1281, grad=0.0000), Var(v=0.1255, grad=0.0000), Var(v=0.0708, grad=0.0000), Var(v=-0.0031, grad=0.0000), Var(v=0.1143, grad=0.0000), Var(v=0.1305, grad=0.0000), Var(v=0.0019, grad=0.0000), Var(v=-0.0215, grad=0.0000), Var(v=0.0711, grad=0.0000), Var(v=0.0271, grad=0.0000), Var(v=-0.0496, grad=0.0000), Var(v=0.0012, grad=0.0000), Var(v=0.0693, grad=0.0000), Var(v=-0.0236, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000)]\n",
      "Layer 2 \n",
      " Weights: [[Var(v=-2.5188, grad=263.7151)], [Var(v=-0.1759, grad=0.0000)], [Var(v=0.0386, grad=0.0000)], [Var(v=-0.0449, grad=0.0000)], [Var(v=0.1252, grad=0.0000)], [Var(v=-0.0706, grad=0.0000)], [Var(v=-0.0168, grad=0.0000)], [Var(v=0.1058, grad=0.0000)], [Var(v=0.0956, grad=0.0000)], [Var(v=-0.0060, grad=0.0000)], [Var(v=0.0394, grad=0.0000)], [Var(v=0.1752, grad=0.0000)], [Var(v=-0.0471, grad=0.0000)], [Var(v=-0.0009, grad=0.0000)], [Var(v=0.0536, grad=0.0000)], [Var(v=-0.0759, grad=0.0000)], [Var(v=-0.0576, grad=0.0000)], [Var(v=0.0152, grad=0.0000)], [Var(v=0.2578, grad=0.0000)], [Var(v=-0.1890, grad=0.0000)], [Var(v=-0.0878, grad=0.0000)], [Var(v=-0.0294, grad=0.0000)], [Var(v=-0.0827, grad=0.0000)], [Var(v=0.0570, grad=0.0000)], [Var(v=0.0825, grad=0.0000)], [Var(v=-0.0061, grad=0.0000)], [Var(v=0.0036, grad=0.0000)], [Var(v=-0.0514, grad=0.0000)], [Var(v=0.0917, grad=0.0000)], [Var(v=0.0736, grad=0.0000)], [Var(v=-0.0659, grad=0.0000)], [Var(v=-0.0808, grad=0.0000)], [Var(v=-0.0094, grad=0.0000)], [Var(v=0.0755, grad=0.0000)], [Var(v=-0.0131, grad=0.0000)], [Var(v=-0.1725, grad=0.0000)], [Var(v=0.0217, grad=0.0000)], [Var(v=-0.1217, grad=0.0000)], [Var(v=-0.0068, grad=0.0000)], [Var(v=-0.0257, grad=0.0000)], [Var(v=-0.0815, grad=0.0000)], [Var(v=-0.0661, grad=0.0000)], [Var(v=-0.1933, grad=0.0000)], [Var(v=0.0058, grad=0.0000)], [Var(v=0.0469, grad=0.0000)], [Var(v=0.0188, grad=0.0000)], [Var(v=0.0890, grad=0.0000)], [Var(v=0.1812, grad=0.0000)], [Var(v=-0.0928, grad=0.0000)], [Var(v=0.0197, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000)]\n",
      "\n",
      "Network after zeroing gradients:\n",
      "Layer 0 \n",
      " Weights: [[Var(v=-0.0029, grad=0.0000), Var(v=-0.0392, grad=0.0000), Var(v=0.1189, grad=0.0000), Var(v=0.1545, grad=0.0000), Var(v=0.0491, grad=0.0000), Var(v=0.1329, grad=0.0000), Var(v=0.2336, grad=0.0000), Var(v=0.2472, grad=0.0000), Var(v=-0.0036, grad=0.0000), Var(v=0.1070, grad=0.0000), Var(v=0.2119, grad=0.0000), Var(v=0.0123, grad=0.0000), Var(v=0.1654, grad=0.0000), Var(v=0.0820, grad=0.0000), Var(v=-0.0029, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000)]\n",
      "Layer 1 \n",
      " Weights: [[Var(v=-0.0246, grad=0.0000), Var(v=-0.0810, grad=0.0000), Var(v=-0.0291, grad=0.0000), Var(v=-0.0274, grad=0.0000), Var(v=0.0268, grad=0.0000), Var(v=-0.0648, grad=0.0000), Var(v=-0.0487, grad=0.0000), Var(v=0.0542, grad=0.0000), Var(v=-0.0418, grad=0.0000), Var(v=-0.0559, grad=0.0000), Var(v=-0.0330, grad=0.0000), Var(v=-0.0721, grad=0.0000), Var(v=-0.0769, grad=0.0000), Var(v=-0.0246, grad=0.0000), Var(v=-0.1104, grad=0.0000), Var(v=-0.0347, grad=0.0000), Var(v=0.0930, grad=0.0000), Var(v=-0.0465, grad=0.0000), Var(v=-0.0485, grad=0.0000), Var(v=-0.0726, grad=0.0000), Var(v=-0.1896, grad=0.0000), Var(v=-0.0328, grad=0.0000), Var(v=-0.0775, grad=0.0000), Var(v=-0.0970, grad=0.0000), Var(v=-0.0506, grad=0.0000), Var(v=-0.0135, grad=0.0000), Var(v=0.0697, grad=0.0000), Var(v=-0.0064, grad=0.0000), Var(v=-0.0522, grad=0.0000), Var(v=-0.0577, grad=0.0000), Var(v=-0.0227, grad=0.0000), Var(v=-0.0168, grad=0.0000), Var(v=-0.0670, grad=0.0000), Var(v=-0.0005, grad=0.0000), Var(v=-0.1736, grad=0.0000), Var(v=-0.0670, grad=0.0000), Var(v=-0.0731, grad=0.0000), Var(v=-0.1591, grad=0.0000), Var(v=-0.1195, grad=0.0000), Var(v=0.0427, grad=0.0000), Var(v=-0.0279, grad=0.0000), Var(v=-0.1020, grad=0.0000), Var(v=-0.0050, grad=0.0000), Var(v=-0.0315, grad=0.0000), Var(v=-0.0740, grad=0.0000), Var(v=-0.0217, grad=0.0000), Var(v=-0.1020, grad=0.0000), Var(v=-0.0106, grad=0.0000), Var(v=0.0267, grad=0.0000), Var(v=-0.1335, grad=0.0000)], [Var(v=-0.0280, grad=0.0000), Var(v=0.2105, grad=0.0000), Var(v=-0.0859, grad=0.0000), Var(v=0.0430, grad=0.0000), Var(v=0.0422, grad=0.0000), Var(v=-0.0653, grad=0.0000), Var(v=0.1955, grad=0.0000), Var(v=-0.2217, grad=0.0000), Var(v=0.0418, grad=0.0000), Var(v=-0.0536, grad=0.0000), Var(v=-0.2416, grad=0.0000), Var(v=0.1587, grad=0.0000), Var(v=0.2336, grad=0.0000), Var(v=-0.0398, grad=0.0000), Var(v=-0.1858, grad=0.0000), Var(v=-0.0185, grad=0.0000), Var(v=0.0897, grad=0.0000), Var(v=-0.0018, grad=0.0000), Var(v=-0.1277, grad=0.0000), Var(v=0.1195, grad=0.0000), Var(v=0.0419, grad=0.0000), Var(v=0.0276, grad=0.0000), Var(v=0.1041, grad=0.0000), Var(v=-0.0629, grad=0.0000), Var(v=-0.0304, grad=0.0000), Var(v=0.1064, grad=0.0000), Var(v=0.1086, grad=0.0000), Var(v=0.0832, grad=0.0000), Var(v=-0.0126, grad=0.0000), Var(v=-0.1861, grad=0.0000), Var(v=-0.0023, grad=0.0000), Var(v=-0.0177, grad=0.0000), Var(v=-0.0561, grad=0.0000), Var(v=0.0937, grad=0.0000), Var(v=-0.2188, grad=0.0000), Var(v=0.1159, grad=0.0000), Var(v=-0.1135, grad=0.0000), Var(v=0.0454, grad=0.0000), Var(v=0.0124, grad=0.0000), Var(v=-0.1677, grad=0.0000), Var(v=-0.1014, grad=0.0000), Var(v=-0.0596, grad=0.0000), Var(v=0.0626, grad=0.0000), Var(v=-0.1280, grad=0.0000), Var(v=-0.0244, grad=0.0000), Var(v=-0.0416, grad=0.0000), Var(v=-0.0511, grad=0.0000), Var(v=0.0007, grad=0.0000), Var(v=-0.0460, grad=0.0000), Var(v=0.0863, grad=0.0000)], [Var(v=-0.1234, grad=0.0000), Var(v=0.0391, grad=0.0000), Var(v=-0.0708, grad=0.0000), Var(v=0.0640, grad=0.0000), Var(v=-0.0790, grad=0.0000), Var(v=-0.0678, grad=0.0000), Var(v=-0.0249, grad=0.0000), Var(v=-0.0263, grad=0.0000), Var(v=0.0372, grad=0.0000), Var(v=0.0088, grad=0.0000), Var(v=-0.1351, grad=0.0000), Var(v=0.1972, grad=0.0000), Var(v=-0.2591, grad=0.0000), Var(v=0.1303, grad=0.0000), Var(v=0.0125, grad=0.0000), Var(v=0.0038, grad=0.0000), Var(v=0.0370, grad=0.0000), Var(v=0.0444, grad=0.0000), Var(v=0.1684, grad=0.0000), Var(v=0.1105, grad=0.0000), Var(v=-0.0130, grad=0.0000), Var(v=-0.0522, grad=0.0000), Var(v=-0.0012, grad=0.0000), Var(v=-0.1538, grad=0.0000), Var(v=0.0756, grad=0.0000), Var(v=-0.0295, grad=0.0000), Var(v=0.1108, grad=0.0000), Var(v=0.0397, grad=0.0000), Var(v=-0.0524, grad=0.0000), Var(v=0.0212, grad=0.0000), Var(v=0.1012, grad=0.0000), Var(v=0.1443, grad=0.0000), Var(v=-0.0869, grad=0.0000), Var(v=0.0976, grad=0.0000), Var(v=-0.0400, grad=0.0000), Var(v=-0.0760, grad=0.0000), Var(v=0.0280, grad=0.0000), Var(v=0.2216, grad=0.0000), Var(v=0.0014, grad=0.0000), Var(v=-0.0465, grad=0.0000), Var(v=0.0411, grad=0.0000), Var(v=-0.0514, grad=0.0000), Var(v=-0.1270, grad=0.0000), Var(v=-0.0001, grad=0.0000), Var(v=-0.0644, grad=0.0000), Var(v=-0.0402, grad=0.0000), Var(v=-0.1421, grad=0.0000), Var(v=-0.0635, grad=0.0000), Var(v=0.0211, grad=0.0000), Var(v=-0.2321, grad=0.0000)], [Var(v=-0.1263, grad=0.0000), Var(v=0.0390, grad=0.0000), Var(v=0.0105, grad=0.0000), Var(v=0.0497, grad=0.0000), Var(v=-0.1610, grad=0.0000), Var(v=0.0405, grad=0.0000), Var(v=0.0044, grad=0.0000), Var(v=0.0480, grad=0.0000), Var(v=0.0148, grad=0.0000), Var(v=0.0137, grad=0.0000), Var(v=0.0047, grad=0.0000), Var(v=-0.0067, grad=0.0000), Var(v=-0.1823, grad=0.0000), Var(v=0.2593, grad=0.0000), Var(v=-0.0195, grad=0.0000), Var(v=0.0741, grad=0.0000), Var(v=0.0657, grad=0.0000), Var(v=0.0095, grad=0.0000), Var(v=0.0372, grad=0.0000), Var(v=0.0168, grad=0.0000), Var(v=0.1490, grad=0.0000), Var(v=-0.1437, grad=0.0000), Var(v=-0.0081, grad=0.0000), Var(v=0.0234, grad=0.0000), Var(v=-0.0154, grad=0.0000), Var(v=-0.0526, grad=0.0000), Var(v=0.0396, grad=0.0000), Var(v=0.0942, grad=0.0000), Var(v=0.0128, grad=0.0000), Var(v=-0.0047, grad=0.0000), Var(v=0.1060, grad=0.0000), Var(v=0.0077, grad=0.0000), Var(v=0.0165, grad=0.0000), Var(v=-0.1319, grad=0.0000), Var(v=-0.1437, grad=0.0000), Var(v=0.1319, grad=0.0000), Var(v=-0.1410, grad=0.0000), Var(v=-0.1132, grad=0.0000), Var(v=0.1762, grad=0.0000), Var(v=-0.0366, grad=0.0000), Var(v=-0.0398, grad=0.0000), Var(v=0.0944, grad=0.0000), Var(v=-0.1840, grad=0.0000), Var(v=0.0560, grad=0.0000), Var(v=-0.1942, grad=0.0000), Var(v=0.0202, grad=0.0000), Var(v=-0.0145, grad=0.0000), Var(v=0.2416, grad=0.0000), Var(v=0.0360, grad=0.0000), Var(v=-0.0821, grad=0.0000)], [Var(v=-0.1921, grad=0.0000), Var(v=-0.0361, grad=0.0000), Var(v=0.1252, grad=0.0000), Var(v=-0.0746, grad=0.0000), Var(v=0.0977, grad=0.0000), Var(v=-0.1074, grad=0.0000), Var(v=-0.1399, grad=0.0000), Var(v=-0.1213, grad=0.0000), Var(v=0.0831, grad=0.0000), Var(v=-0.0238, grad=0.0000), Var(v=-0.0545, grad=0.0000), Var(v=0.1688, grad=0.0000), Var(v=0.0549, grad=0.0000), Var(v=-0.0537, grad=0.0000), Var(v=-0.0163, grad=0.0000), Var(v=0.1032, grad=0.0000), Var(v=-0.0969, grad=0.0000), Var(v=-0.0906, grad=0.0000), Var(v=0.2441, grad=0.0000), Var(v=-0.0312, grad=0.0000), Var(v=-0.1136, grad=0.0000), Var(v=-0.0619, grad=0.0000), Var(v=0.1180, grad=0.0000), Var(v=0.1648, grad=0.0000), Var(v=-0.1482, grad=0.0000), Var(v=-0.1099, grad=0.0000), Var(v=-0.1822, grad=0.0000), Var(v=0.0968, grad=0.0000), Var(v=0.0612, grad=0.0000), Var(v=-0.0517, grad=0.0000), Var(v=-0.0413, grad=0.0000), Var(v=0.0771, grad=0.0000), Var(v=0.0720, grad=0.0000), Var(v=0.0726, grad=0.0000), Var(v=0.0885, grad=0.0000), Var(v=0.1973, grad=0.0000), Var(v=-0.2039, grad=0.0000), Var(v=-0.0554, grad=0.0000), Var(v=-0.0295, grad=0.0000), Var(v=0.0855, grad=0.0000), Var(v=-0.0072, grad=0.0000), Var(v=-0.0404, grad=0.0000), Var(v=0.0217, grad=0.0000), Var(v=-0.0987, grad=0.0000), Var(v=-0.1306, grad=0.0000), Var(v=0.1043, grad=0.0000), Var(v=0.0395, grad=0.0000), Var(v=0.0036, grad=0.0000), Var(v=0.0618, grad=0.0000), Var(v=0.0945, grad=0.0000)], [Var(v=0.1707, grad=0.0000), Var(v=-0.0952, grad=0.0000), Var(v=-0.0950, grad=0.0000), Var(v=-0.0642, grad=0.0000), Var(v=0.0555, grad=0.0000), Var(v=-0.1315, grad=0.0000), Var(v=-0.0666, grad=0.0000), Var(v=-0.0077, grad=0.0000), Var(v=0.0083, grad=0.0000), Var(v=0.0115, grad=0.0000), Var(v=-0.0024, grad=0.0000), Var(v=-0.0633, grad=0.0000), Var(v=-0.1334, grad=0.0000), Var(v=-0.1212, grad=0.0000), Var(v=-0.0814, grad=0.0000), Var(v=0.0818, grad=0.0000), Var(v=-0.0033, grad=0.0000), Var(v=0.0366, grad=0.0000), Var(v=-0.0900, grad=0.0000), Var(v=0.0813, grad=0.0000), Var(v=-0.1005, grad=0.0000), Var(v=0.0243, grad=0.0000), Var(v=-0.1237, grad=0.0000), Var(v=0.0867, grad=0.0000), Var(v=-0.0524, grad=0.0000), Var(v=-0.0542, grad=0.0000), Var(v=-0.0276, grad=0.0000), Var(v=0.0774, grad=0.0000), Var(v=-0.0206, grad=0.0000), Var(v=-0.0596, grad=0.0000), Var(v=-0.2217, grad=0.0000), Var(v=-0.2644, grad=0.0000), Var(v=-0.2766, grad=0.0000), Var(v=0.0345, grad=0.0000), Var(v=-0.0135, grad=0.0000), Var(v=0.1262, grad=0.0000), Var(v=-0.0134, grad=0.0000), Var(v=0.1211, grad=0.0000), Var(v=0.0604, grad=0.0000), Var(v=-0.0682, grad=0.0000), Var(v=-0.0536, grad=0.0000), Var(v=-0.0372, grad=0.0000), Var(v=0.0115, grad=0.0000), Var(v=-0.0629, grad=0.0000), Var(v=-0.0311, grad=0.0000), Var(v=0.0743, grad=0.0000), Var(v=0.0931, grad=0.0000), Var(v=-0.0277, grad=0.0000), Var(v=-0.0917, grad=0.0000), Var(v=-0.0528, grad=0.0000)], [Var(v=0.1527, grad=0.0000), Var(v=-0.0612, grad=0.0000), Var(v=0.0922, grad=0.0000), Var(v=0.0444, grad=0.0000), Var(v=-0.0105, grad=0.0000), Var(v=-0.0556, grad=0.0000), Var(v=0.1595, grad=0.0000), Var(v=-0.0364, grad=0.0000), Var(v=-0.0790, grad=0.0000), Var(v=0.0633, grad=0.0000), Var(v=-0.1215, grad=0.0000), Var(v=0.0727, grad=0.0000), Var(v=0.1648, grad=0.0000), Var(v=0.0497, grad=0.0000), Var(v=0.0359, grad=0.0000), Var(v=0.0261, grad=0.0000), Var(v=0.0181, grad=0.0000), Var(v=0.2016, grad=0.0000), Var(v=0.0620, grad=0.0000), Var(v=-0.1190, grad=0.0000), Var(v=-0.0106, grad=0.0000), Var(v=0.0612, grad=0.0000), Var(v=0.0493, grad=0.0000), Var(v=0.1004, grad=0.0000), Var(v=-0.1772, grad=0.0000), Var(v=-0.0642, grad=0.0000), Var(v=0.0892, grad=0.0000), Var(v=-0.0499, grad=0.0000), Var(v=-0.0623, grad=0.0000), Var(v=0.0486, grad=0.0000), Var(v=-0.0678, grad=0.0000), Var(v=-0.0225, grad=0.0000), Var(v=0.1001, grad=0.0000), Var(v=0.1421, grad=0.0000), Var(v=0.0077, grad=0.0000), Var(v=0.2333, grad=0.0000), Var(v=-0.0094, grad=0.0000), Var(v=0.0324, grad=0.0000), Var(v=0.0076, grad=0.0000), Var(v=-0.1168, grad=0.0000), Var(v=-0.0268, grad=0.0000), Var(v=-0.0179, grad=0.0000), Var(v=0.0654, grad=0.0000), Var(v=-0.0238, grad=0.0000), Var(v=-0.0545, grad=0.0000), Var(v=-0.2191, grad=0.0000), Var(v=-0.0245, grad=0.0000), Var(v=-0.1259, grad=0.0000), Var(v=-0.0152, grad=0.0000), Var(v=-0.0569, grad=0.0000)], [Var(v=-0.0512, grad=0.0000), Var(v=-0.0893, grad=0.0000), Var(v=-0.0207, grad=0.0000), Var(v=-0.0790, grad=0.0000), Var(v=0.0782, grad=0.0000), Var(v=0.1015, grad=0.0000), Var(v=-0.0659, grad=0.0000), Var(v=0.0516, grad=0.0000), Var(v=0.0279, grad=0.0000), Var(v=-0.0012, grad=0.0000), Var(v=0.0502, grad=0.0000), Var(v=-0.1403, grad=0.0000), Var(v=0.1502, grad=0.0000), Var(v=0.0259, grad=0.0000), Var(v=0.1220, grad=0.0000), Var(v=0.0195, grad=0.0000), Var(v=-0.0167, grad=0.0000), Var(v=-0.0776, grad=0.0000), Var(v=-0.1297, grad=0.0000), Var(v=-0.1277, grad=0.0000), Var(v=0.0880, grad=0.0000), Var(v=-0.1370, grad=0.0000), Var(v=0.0573, grad=0.0000), Var(v=0.0829, grad=0.0000), Var(v=0.0076, grad=0.0000), Var(v=0.0427, grad=0.0000), Var(v=0.0613, grad=0.0000), Var(v=-0.0037, grad=0.0000), Var(v=-0.0918, grad=0.0000), Var(v=0.0025, grad=0.0000), Var(v=-0.1247, grad=0.0000), Var(v=-0.0955, grad=0.0000), Var(v=-0.0429, grad=0.0000), Var(v=-0.1164, grad=0.0000), Var(v=-0.0365, grad=0.0000), Var(v=0.1153, grad=0.0000), Var(v=0.1101, grad=0.0000), Var(v=0.0612, grad=0.0000), Var(v=0.0382, grad=0.0000), Var(v=0.0961, grad=0.0000), Var(v=0.1367, grad=0.0000), Var(v=0.0654, grad=0.0000), Var(v=0.1085, grad=0.0000), Var(v=-0.0914, grad=0.0000), Var(v=-0.0651, grad=0.0000), Var(v=0.0268, grad=0.0000), Var(v=0.0979, grad=0.0000), Var(v=0.0602, grad=0.0000), Var(v=-0.0958, grad=0.0000), Var(v=-0.0524, grad=0.0000)], [Var(v=-0.0589, grad=0.0000), Var(v=-0.0074, grad=0.0000), Var(v=0.0087, grad=0.0000), Var(v=-0.0031, grad=0.0000), Var(v=0.2136, grad=0.0000), Var(v=0.0850, grad=0.0000), Var(v=0.2095, grad=0.0000), Var(v=-0.0947, grad=0.0000), Var(v=0.0288, grad=0.0000), Var(v=-0.1088, grad=0.0000), Var(v=0.0823, grad=0.0000), Var(v=0.0523, grad=0.0000), Var(v=0.1317, grad=0.0000), Var(v=0.0202, grad=0.0000), Var(v=0.0362, grad=0.0000), Var(v=-0.0930, grad=0.0000), Var(v=0.0817, grad=0.0000), Var(v=0.0589, grad=0.0000), Var(v=-0.0431, grad=0.0000), Var(v=0.0461, grad=0.0000), Var(v=-0.1277, grad=0.0000), Var(v=0.0435, grad=0.0000), Var(v=-0.1575, grad=0.0000), Var(v=-0.2250, grad=0.0000), Var(v=0.0297, grad=0.0000), Var(v=0.0463, grad=0.0000), Var(v=-0.0246, grad=0.0000), Var(v=-0.0257, grad=0.0000), Var(v=0.1145, grad=0.0000), Var(v=0.0564, grad=0.0000), Var(v=0.2071, grad=0.0000), Var(v=0.0278, grad=0.0000), Var(v=-0.1397, grad=0.0000), Var(v=0.0109, grad=0.0000), Var(v=0.0270, grad=0.0000), Var(v=0.0655, grad=0.0000), Var(v=-0.2040, grad=0.0000), Var(v=-0.2655, grad=0.0000), Var(v=-0.1302, grad=0.0000), Var(v=-0.0100, grad=0.0000), Var(v=0.2206, grad=0.0000), Var(v=-0.0583, grad=0.0000), Var(v=-0.0226, grad=0.0000), Var(v=-0.0811, grad=0.0000), Var(v=0.1847, grad=0.0000), Var(v=-0.0464, grad=0.0000), Var(v=0.0678, grad=0.0000), Var(v=0.1650, grad=0.0000), Var(v=-0.0605, grad=0.0000), Var(v=0.2224, grad=0.0000)], [Var(v=-0.1238, grad=0.0000), Var(v=-0.1092, grad=0.0000), Var(v=-0.0995, grad=0.0000), Var(v=-0.1001, grad=0.0000), Var(v=-0.0025, grad=0.0000), Var(v=-0.0045, grad=0.0000), Var(v=-0.0705, grad=0.0000), Var(v=0.0076, grad=0.0000), Var(v=0.1164, grad=0.0000), Var(v=-0.0768, grad=0.0000), Var(v=-0.1270, grad=0.0000), Var(v=0.0869, grad=0.0000), Var(v=-0.0131, grad=0.0000), Var(v=0.1023, grad=0.0000), Var(v=0.0709, grad=0.0000), Var(v=-0.0274, grad=0.0000), Var(v=-0.0734, grad=0.0000), Var(v=0.1952, grad=0.0000), Var(v=0.0545, grad=0.0000), Var(v=0.0978, grad=0.0000), Var(v=0.0771, grad=0.0000), Var(v=-0.0807, grad=0.0000), Var(v=0.1207, grad=0.0000), Var(v=-0.1439, grad=0.0000), Var(v=-0.1163, grad=0.0000), Var(v=-0.0352, grad=0.0000), Var(v=-0.0738, grad=0.0000), Var(v=0.1126, grad=0.0000), Var(v=0.2074, grad=0.0000), Var(v=0.0735, grad=0.0000), Var(v=-0.0320, grad=0.0000), Var(v=0.0752, grad=0.0000), Var(v=-0.0363, grad=0.0000), Var(v=0.2110, grad=0.0000), Var(v=-0.1189, grad=0.0000), Var(v=0.1353, grad=0.0000), Var(v=0.0193, grad=0.0000), Var(v=-0.0073, grad=0.0000), Var(v=0.0169, grad=0.0000), Var(v=0.0901, grad=0.0000), Var(v=0.0113, grad=0.0000), Var(v=-0.0341, grad=0.0000), Var(v=-0.0431, grad=0.0000), Var(v=0.1733, grad=0.0000), Var(v=0.1296, grad=0.0000), Var(v=0.0770, grad=0.0000), Var(v=0.1533, grad=0.0000), Var(v=-0.0533, grad=0.0000), Var(v=-0.0862, grad=0.0000), Var(v=0.0035, grad=0.0000)], [Var(v=0.0218, grad=0.0000), Var(v=-0.0258, grad=0.0000), Var(v=0.0421, grad=0.0000), Var(v=-0.1501, grad=0.0000), Var(v=-0.0437, grad=0.0000), Var(v=-0.2342, grad=0.0000), Var(v=0.0226, grad=0.0000), Var(v=-0.0068, grad=0.0000), Var(v=0.0764, grad=0.0000), Var(v=0.1958, grad=0.0000), Var(v=-0.1297, grad=0.0000), Var(v=-0.0348, grad=0.0000), Var(v=-0.1576, grad=0.0000), Var(v=0.0286, grad=0.0000), Var(v=0.2357, grad=0.0000), Var(v=0.0293, grad=0.0000), Var(v=-0.0522, grad=0.0000), Var(v=0.1109, grad=0.0000), Var(v=-0.0907, grad=0.0000), Var(v=0.0033, grad=0.0000), Var(v=0.0678, grad=0.0000), Var(v=-0.0270, grad=0.0000), Var(v=-0.0059, grad=0.0000), Var(v=0.1597, grad=0.0000), Var(v=0.0523, grad=0.0000), Var(v=-0.0065, grad=0.0000), Var(v=0.0887, grad=0.0000), Var(v=0.0540, grad=0.0000), Var(v=0.0137, grad=0.0000), Var(v=-0.0089, grad=0.0000), Var(v=-0.1937, grad=0.0000), Var(v=-0.0363, grad=0.0000), Var(v=-0.0823, grad=0.0000), Var(v=0.0186, grad=0.0000), Var(v=0.0166, grad=0.0000), Var(v=-0.1328, grad=0.0000), Var(v=0.0895, grad=0.0000), Var(v=0.1123, grad=0.0000), Var(v=0.0087, grad=0.0000), Var(v=0.0007, grad=0.0000), Var(v=0.0457, grad=0.0000), Var(v=0.1148, grad=0.0000), Var(v=0.0541, grad=0.0000), Var(v=-0.0846, grad=0.0000), Var(v=-0.0259, grad=0.0000), Var(v=-0.2476, grad=0.0000), Var(v=0.1373, grad=0.0000), Var(v=0.0616, grad=0.0000), Var(v=-0.0364, grad=0.0000), Var(v=-0.0124, grad=0.0000)], [Var(v=-0.1167, grad=0.0000), Var(v=0.1104, grad=0.0000), Var(v=0.0760, grad=0.0000), Var(v=-0.0472, grad=0.0000), Var(v=0.1253, grad=0.0000), Var(v=-0.0775, grad=0.0000), Var(v=-0.1530, grad=0.0000), Var(v=0.1607, grad=0.0000), Var(v=0.0034, grad=0.0000), Var(v=0.0309, grad=0.0000), Var(v=-0.0004, grad=0.0000), Var(v=0.0447, grad=0.0000), Var(v=-0.1836, grad=0.0000), Var(v=0.0397, grad=0.0000), Var(v=-0.1679, grad=0.0000), Var(v=-0.0306, grad=0.0000), Var(v=-0.2528, grad=0.0000), Var(v=-0.0375, grad=0.0000), Var(v=0.0042, grad=0.0000), Var(v=-0.0296, grad=0.0000), Var(v=-0.1130, grad=0.0000), Var(v=0.1394, grad=0.0000), Var(v=0.0151, grad=0.0000), Var(v=-0.0859, grad=0.0000), Var(v=-0.0079, grad=0.0000), Var(v=-0.0298, grad=0.0000), Var(v=-0.0586, grad=0.0000), Var(v=-0.0864, grad=0.0000), Var(v=-0.1322, grad=0.0000), Var(v=0.0560, grad=0.0000), Var(v=0.2181, grad=0.0000), Var(v=-0.1245, grad=0.0000), Var(v=-0.0503, grad=0.0000), Var(v=0.0973, grad=0.0000), Var(v=-0.0205, grad=0.0000), Var(v=-0.0408, grad=0.0000), Var(v=-0.0243, grad=0.0000), Var(v=-0.0810, grad=0.0000), Var(v=-0.0675, grad=0.0000), Var(v=-0.1168, grad=0.0000), Var(v=0.1607, grad=0.0000), Var(v=-0.1004, grad=0.0000), Var(v=0.1823, grad=0.0000), Var(v=-0.1037, grad=0.0000), Var(v=0.0464, grad=0.0000), Var(v=-0.0925, grad=0.0000), Var(v=-0.0491, grad=0.0000), Var(v=-0.0733, grad=0.0000), Var(v=0.1706, grad=0.0000), Var(v=0.0177, grad=0.0000)], [Var(v=0.0772, grad=0.0000), Var(v=-0.0610, grad=0.0000), Var(v=-0.0034, grad=0.0000), Var(v=-0.0003, grad=0.0000), Var(v=0.0462, grad=0.0000), Var(v=-0.1706, grad=0.0000), Var(v=0.1417, grad=0.0000), Var(v=0.0084, grad=0.0000), Var(v=0.0556, grad=0.0000), Var(v=0.0377, grad=0.0000), Var(v=-0.0778, grad=0.0000), Var(v=-0.0300, grad=0.0000), Var(v=0.0844, grad=0.0000), Var(v=0.1490, grad=0.0000), Var(v=-0.1141, grad=0.0000), Var(v=0.0846, grad=0.0000), Var(v=-0.2961, grad=0.0000), Var(v=-0.0043, grad=0.0000), Var(v=0.0729, grad=0.0000), Var(v=0.0067, grad=0.0000), Var(v=0.0331, grad=0.0000), Var(v=0.0744, grad=0.0000), Var(v=-0.1516, grad=0.0000), Var(v=-0.1232, grad=0.0000), Var(v=-0.0074, grad=0.0000), Var(v=0.0710, grad=0.0000), Var(v=0.1022, grad=0.0000), Var(v=0.1010, grad=0.0000), Var(v=-0.1167, grad=0.0000), Var(v=0.0646, grad=0.0000), Var(v=-0.0215, grad=0.0000), Var(v=-0.0746, grad=0.0000), Var(v=-0.0193, grad=0.0000), Var(v=-0.0948, grad=0.0000), Var(v=0.1224, grad=0.0000), Var(v=0.0187, grad=0.0000), Var(v=0.0316, grad=0.0000), Var(v=-0.0773, grad=0.0000), Var(v=-0.1863, grad=0.0000), Var(v=0.0829, grad=0.0000), Var(v=0.0976, grad=0.0000), Var(v=-0.1383, grad=0.0000), Var(v=0.0271, grad=0.0000), Var(v=-0.0461, grad=0.0000), Var(v=0.0759, grad=0.0000), Var(v=0.2165, grad=0.0000), Var(v=-0.0304, grad=0.0000), Var(v=0.2026, grad=0.0000), Var(v=-0.1363, grad=0.0000), Var(v=-0.0016, grad=0.0000)], [Var(v=0.0231, grad=0.0000), Var(v=0.0764, grad=0.0000), Var(v=-0.1507, grad=0.0000), Var(v=0.0889, grad=0.0000), Var(v=0.0263, grad=0.0000), Var(v=0.0337, grad=0.0000), Var(v=-0.0444, grad=0.0000), Var(v=-0.0104, grad=0.0000), Var(v=0.0041, grad=0.0000), Var(v=-0.0393, grad=0.0000), Var(v=0.1272, grad=0.0000), Var(v=-0.0889, grad=0.0000), Var(v=0.0472, grad=0.0000), Var(v=-0.0917, grad=0.0000), Var(v=0.0477, grad=0.0000), Var(v=-0.0070, grad=0.0000), Var(v=0.1879, grad=0.0000), Var(v=-0.0746, grad=0.0000), Var(v=0.2687, grad=0.0000), Var(v=0.1036, grad=0.0000), Var(v=0.0842, grad=0.0000), Var(v=0.0313, grad=0.0000), Var(v=-0.0864, grad=0.0000), Var(v=-0.0687, grad=0.0000), Var(v=0.1095, grad=0.0000), Var(v=-0.0185, grad=0.0000), Var(v=-0.0951, grad=0.0000), Var(v=0.0087, grad=0.0000), Var(v=-0.0026, grad=0.0000), Var(v=-0.1955, grad=0.0000), Var(v=-0.0966, grad=0.0000), Var(v=-0.0604, grad=0.0000), Var(v=-0.0084, grad=0.0000), Var(v=-0.0295, grad=0.0000), Var(v=0.1506, grad=0.0000), Var(v=-0.0607, grad=0.0000), Var(v=0.0571, grad=0.0000), Var(v=-0.0186, grad=0.0000), Var(v=0.0934, grad=0.0000), Var(v=-0.0804, grad=0.0000), Var(v=-0.1147, grad=0.0000), Var(v=0.0567, grad=0.0000), Var(v=-0.0167, grad=0.0000), Var(v=-0.0150, grad=0.0000), Var(v=-0.0706, grad=0.0000), Var(v=-0.1013, grad=0.0000), Var(v=-0.3237, grad=0.0000), Var(v=-0.0763, grad=0.0000), Var(v=0.0660, grad=0.0000), Var(v=0.1843, grad=0.0000)], [Var(v=-0.0498, grad=0.0000), Var(v=-0.1291, grad=0.0000), Var(v=0.1743, grad=0.0000), Var(v=0.0605, grad=0.0000), Var(v=-0.0081, grad=0.0000), Var(v=0.0517, grad=0.0000), Var(v=0.0600, grad=0.0000), Var(v=-0.0349, grad=0.0000), Var(v=0.0254, grad=0.0000), Var(v=0.0421, grad=0.0000), Var(v=-0.0929, grad=0.0000), Var(v=-0.1511, grad=0.0000), Var(v=0.1010, grad=0.0000), Var(v=-0.0361, grad=0.0000), Var(v=-0.0317, grad=0.0000), Var(v=-0.0381, grad=0.0000), Var(v=-0.0196, grad=0.0000), Var(v=-0.0047, grad=0.0000), Var(v=-0.0043, grad=0.0000), Var(v=0.1461, grad=0.0000), Var(v=-0.0893, grad=0.0000), Var(v=-0.0392, grad=0.0000), Var(v=-0.0409, grad=0.0000), Var(v=-0.0886, grad=0.0000), Var(v=-0.0370, grad=0.0000), Var(v=0.1508, grad=0.0000), Var(v=-0.0677, grad=0.0000), Var(v=0.0811, grad=0.0000), Var(v=0.1225, grad=0.0000), Var(v=0.0890, grad=0.0000), Var(v=0.0464, grad=0.0000), Var(v=0.0804, grad=0.0000), Var(v=-0.1003, grad=0.0000), Var(v=-0.1679, grad=0.0000), Var(v=0.0205, grad=0.0000), Var(v=-0.1377, grad=0.0000), Var(v=0.1281, grad=0.0000), Var(v=0.1255, grad=0.0000), Var(v=0.0708, grad=0.0000), Var(v=-0.0031, grad=0.0000), Var(v=0.1143, grad=0.0000), Var(v=0.1305, grad=0.0000), Var(v=0.0019, grad=0.0000), Var(v=-0.0215, grad=0.0000), Var(v=0.0711, grad=0.0000), Var(v=0.0271, grad=0.0000), Var(v=-0.0496, grad=0.0000), Var(v=0.0012, grad=0.0000), Var(v=0.0693, grad=0.0000), Var(v=-0.0236, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000)]\n",
      "Layer 2 \n",
      " Weights: [[Var(v=-2.5188, grad=0.0000)], [Var(v=-0.1759, grad=0.0000)], [Var(v=0.0386, grad=0.0000)], [Var(v=-0.0449, grad=0.0000)], [Var(v=0.1252, grad=0.0000)], [Var(v=-0.0706, grad=0.0000)], [Var(v=-0.0168, grad=0.0000)], [Var(v=0.1058, grad=0.0000)], [Var(v=0.0956, grad=0.0000)], [Var(v=-0.0060, grad=0.0000)], [Var(v=0.0394, grad=0.0000)], [Var(v=0.1752, grad=0.0000)], [Var(v=-0.0471, grad=0.0000)], [Var(v=-0.0009, grad=0.0000)], [Var(v=0.0536, grad=0.0000)], [Var(v=-0.0759, grad=0.0000)], [Var(v=-0.0576, grad=0.0000)], [Var(v=0.0152, grad=0.0000)], [Var(v=0.2578, grad=0.0000)], [Var(v=-0.1890, grad=0.0000)], [Var(v=-0.0878, grad=0.0000)], [Var(v=-0.0294, grad=0.0000)], [Var(v=-0.0827, grad=0.0000)], [Var(v=0.0570, grad=0.0000)], [Var(v=0.0825, grad=0.0000)], [Var(v=-0.0061, grad=0.0000)], [Var(v=0.0036, grad=0.0000)], [Var(v=-0.0514, grad=0.0000)], [Var(v=0.0917, grad=0.0000)], [Var(v=0.0736, grad=0.0000)], [Var(v=-0.0659, grad=0.0000)], [Var(v=-0.0808, grad=0.0000)], [Var(v=-0.0094, grad=0.0000)], [Var(v=0.0755, grad=0.0000)], [Var(v=-0.0131, grad=0.0000)], [Var(v=-0.1725, grad=0.0000)], [Var(v=0.0217, grad=0.0000)], [Var(v=-0.1217, grad=0.0000)], [Var(v=-0.0068, grad=0.0000)], [Var(v=-0.0257, grad=0.0000)], [Var(v=-0.0815, grad=0.0000)], [Var(v=-0.0661, grad=0.0000)], [Var(v=-0.1933, grad=0.0000)], [Var(v=0.0058, grad=0.0000)], [Var(v=0.0469, grad=0.0000)], [Var(v=0.0188, grad=0.0000)], [Var(v=0.0890, grad=0.0000)], [Var(v=0.1812, grad=0.0000)], [Var(v=-0.0928, grad=0.0000)], [Var(v=0.0197, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Network before update:')\n",
    "[print('Layer', i, '\\n', NN[i]) for i in range(len(NN))] \n",
    "\n",
    "def parameters(network):\n",
    "  params = []\n",
    "  for layer in range(len(network)):\n",
    "    params += network[layer].parameters()\n",
    "  return params\n",
    "\n",
    "def update_parameters(params, learning_rate=0.01):\n",
    "  for p in params:\n",
    "    p.v -= learning_rate*p.grad\n",
    "\n",
    "def zero_gradients(params):\n",
    "  for p in params:\n",
    "    p.grad = 0.0\n",
    "\n",
    "update_parameters(parameters(NN))\n",
    "\n",
    "print('\\nNetwork after update:')\n",
    "[print('Layer', i, '\\n', NN[i]) for i in range(len(NN))] \n",
    "\n",
    "zero_gradients(parameters(NN))\n",
    "\n",
    "print('\\nNetwork after zeroing gradients:')\n",
    "[print('Layer', i, '\\n', NN[i]) for i in range(len(NN))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "woWYpdw6FtIO"
   },
   "outputs": [],
   "source": [
    "# Initialize an arbitrary neural network\n",
    "NN = [\n",
    "    DenseLayer(1, 8, lambda x: x.relu()),\n",
    "    DenseLayer(8, 1, lambda x: x.identity()) # identity\n",
    "]\n",
    "\n",
    "# Recommended hyper-parameters for 3-D: \n",
    "#NN = [\n",
    "#    DenseLayer(3, 16, lambda x: x.relu()),\n",
    "#    DenseLayer(16, 1, lambda x: x.identity())\n",
    "#]\n",
    "\n",
    "\n",
    "### Notice that, when we switch from tanh to relu activation, we decrease the learning rate. This is due the stability of the gradients \n",
    "## of the activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "mdqaqYBVFtIR"
   },
   "outputs": [],
   "source": [
    "# Initialize training hyperparameters\n",
    "EPOCHS = 200\n",
    "LEARN_R = 2e-3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kfg76GMFtIW",
    "outputId": "e30cf68a-31f2-42b4-cc5e-860c297c0f04",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 ( 0.00%) Train loss: 106.102 \t Validation loss: 99.190\n",
      "  10 ( 5.00%) Train loss: 86.869 \t Validation loss: 76.545\n",
      "  20 (10.00%) Train loss: 94.599 \t Validation loss: 107.213\n",
      "  30 (15.00%) Train loss: 93.667 \t Validation loss: 106.508\n",
      "  40 (20.00%) Train loss: 92.806 \t Validation loss: 105.821\n",
      "  50 (25.00%) Train loss: 92.011 \t Validation loss: 105.160\n",
      "  60 (30.00%) Train loss: 91.280 \t Validation loss: 104.529\n",
      "  70 (35.00%) Train loss: 90.606 \t Validation loss: 103.929\n",
      "  80 (40.00%) Train loss: 89.985 \t Validation loss: 103.361\n",
      "  90 (45.00%) Train loss: 89.411 \t Validation loss: 102.824\n",
      " 100 (50.00%) Train loss: 88.879 \t Validation loss: 102.317\n",
      " 110 (55.00%) Train loss: 88.386 \t Validation loss: 101.838\n",
      " 120 (60.00%) Train loss: 87.928 \t Validation loss: 101.386\n",
      " 130 (65.00%) Train loss: 87.501 \t Validation loss: 100.958\n",
      " 140 (70.00%) Train loss: 87.102 \t Validation loss: 100.552\n",
      " 150 (75.00%) Train loss: 86.728 \t Validation loss: 100.169\n",
      " 160 (80.00%) Train loss: 86.377 \t Validation loss: 99.804\n",
      " 170 (85.00%) Train loss: 86.047 \t Validation loss: 99.458\n",
      " 180 (90.00%) Train loss: 85.737 \t Validation loss: 99.129\n",
      " 190 (95.00%) Train loss: 85.443 \t Validation loss: 98.816\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "     \n",
    "    # Forward pass and loss computation\n",
    "    Loss = squared_loss(y_train, forward(x_train, NN))\n",
    "\n",
    "    # Backward pass\n",
    "    Loss.backward()\n",
    "    \n",
    "    # gradient descent update\n",
    "    update_parameters(parameters(NN), LEARN_R)\n",
    "    zero_gradients(parameters(NN))\n",
    "    \n",
    "    # Training loss\n",
    "    train_loss.append(Loss.v)\n",
    "    \n",
    "    # Validation\n",
    "    Loss_validation = squared_loss(y_validation, forward(x_validation, NN))\n",
    "    val_loss.append(Loss_validation.v)\n",
    "    \n",
    "    if e%10==0:\n",
    "        print(\"{:4d}\".format(e),\n",
    "              \"({:5.2f}%)\".format(e/EPOCHS*100), \n",
    "              \"Train loss: {:4.3f} \\t Validation loss: {:4.3f}\".format(train_loss[-1], val_loss[-1]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "VetyRWFwFtIY",
    "outputId": "344e490d-6d7d-455a-fa6f-88dd11eb957e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_loss)), train_loss);\n",
    "plt.plot(range(len(val_loss)), val_loss);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OgmIrM9FtIb"
   },
   "source": [
    "# Testing\n",
    "\n",
    "We have kept the calculation of the test error separate in order to emphasize that you should not use the test set in optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "HmNi7S-vFtIc"
   },
   "outputs": [],
   "source": [
    "output_test = forward(x_test, NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "7mmJOTSEFtIf",
    "outputId": "e3264095-cefe-4aee-893d-bf152438e332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  87.970\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_np = Var_to_nparray(y_test)\n",
    "plt.scatter(y_test_np, Var_to_nparray(output_test));\n",
    "plt.plot([np.min(y_test_np), np.max(y_test_np)], [np.min(y_test_np), np.max(y_test_np)], color='k');\n",
    "plt.xlabel(\"y\");\n",
    "plt.ylabel(\"$\\hat{y}$\");\n",
    "plt.title(\"Model prediction vs real in the test set, the close to the line the better\")\n",
    "plt.grid(True);\n",
    "plt.axis('equal');\n",
    "plt.tight_layout();\n",
    "\n",
    "Loss_test = squared_loss(y_test, forward(x_test, NN))\n",
    "\n",
    "print(\"Test loss:  {:4.3f}\".format(Loss_test.v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "ODi0WlmQFtIh",
    "outputId": "d1ab874f-0717-4987-87bf-1f0c7c8e7148"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test_np = Var_to_nparray(x_test)\n",
    "x_train_np = Var_to_nparray(x_train)\n",
    "y_train_np = Var_to_nparray(y_train)\n",
    "if D1:\n",
    "    plt.scatter(x_train_np, y_train_np, label=\"train data\");\n",
    "    plt.scatter(x_test_np, Var_to_nparray(output_test), label=\"test prediction\");\n",
    "    plt.scatter(x_test_np, y_test_np, label=\"test data\");\n",
    "    plt.legend();\n",
    "    plt.xlabel(\"x\");\n",
    "    plt.ylabel(\"y\");\n",
    "else:\n",
    "    plt.scatter(x_train_np[:,1], y_train, label=\"train data\");\n",
    "    plt.scatter(x_test_np[:,1], Var_to_nparray(output_test), label=\"test data prediction\");\n",
    "    plt.scatter(x_test_np[:,1], y_test_np, label=\"test data\");\n",
    "    plt.legend();\n",
    "    plt.xlabel(\"x\");\n",
    "    plt.ylabel(\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTBAmjsAFtIk"
   },
   "source": [
    "## Exercise l) Show overfitting, underfitting and just right fitting\n",
    "\n",
    "Vary the architecture and other things to show clear signs of overfitting (=training loss significantly lower than test loss) and underfitting (=not fitting enoung to training data so that test performance is also hurt).\n",
    "\n",
    "See also if you can get a good compromise which leads to a low validation loss. \n",
    "\n",
    "For this problem do you see any big difference between validation and test loss? The answer here will probably be no. Discuss cases where it is important to keep the two separate.\n",
    "\n",
    "_Insert written answer here._\n",
    "\n",
    "### Answer suggestion\n",
    "\n",
    "I have some error, in my code, which I did not have time to find, so my model trains weirdely (the gradient seems to be the problem). But decreasing the number of parameters would lead to underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "tQZCn2dxFtIl"
   },
   "outputs": [],
   "source": [
    "# Insert your code for getting overfitting, underfitting and just right fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYPZP-eTFtIo"
   },
   "source": [
    "# Next steps - classification\n",
    "\n",
    "It is straight forward to extend what we have done to classification. \n",
    "\n",
    "For numerical stability it is better to make softmax and cross-entropy as one function so we write the cross entropy loss as a function of the logits we talked about last week. \n",
    "\n",
    "Next week we will see how to perform classification in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsVPul3QFtIo"
   },
   "source": [
    "## Exercise m) optional - Implement backpropagation for classification\n",
    "\n",
    "Should be possible with very few lines of code. :-)\n",
    "\n",
    "### Answer suggestion:\n",
    "\n",
    "Sorry, no time to implement:\n",
    "Use the cross entropy loss as criterion and define a network with three output neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "oC8QrI2tFtIp"
   },
   "outputs": [],
   "source": [
    "# Just add code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APqhJv3tta1O"
   },
   "source": [
    "## Exercise n) optional - Introduce a NeuralNetwork class\n",
    "\n",
    "The functions we applied on the neural network (parameters, update_parameters and zero_gradients) can more naturally be included as methods in a NeuralNetwork class. Make such a class and modify the code to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Dqfnor1ouMLq"
   },
   "outputs": [],
   "source": [
    "# just add some code"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "U4057_ljNvWB",
    "p_8n_SKnIW2F",
    "oLrGJytZFtGm",
    "jpIZPBpNI0pO",
    "_79HOAXrFtHK",
    "mqeyab9qFtGs",
    "-XyXBD37FtHk",
    "SrwSJ2UWFtHu",
    "zTBAmjsAFtIk",
    "qsVPul3QFtIo",
    "APqhJv3tta1O"
   ],
   "name": "2.1-EXE-FNN-AutoDif-Nanograd.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
